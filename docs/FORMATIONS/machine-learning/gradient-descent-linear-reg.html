<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Djamal TOE">
<meta name="dcterms.date" content="2025-06-08">

<title>DJAMAL WEBSITE - Mise en ≈ìuvre de l‚Äôalgorithme de la descente de gradient : Cas de la r√©gression lin√©aire</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="index.qmd" class="navbar-brand navbar-brand-logo">
    <img src="../../images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="index.qmd">
    <span class="navbar-title">DJAMAL WEBSITE</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-statistics--machine-learning" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Statistics &amp; Machine Learning</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-statistics--machine-learning">    
        <li>
    <a class="dropdown-item" href="../../projet-traitement-donnees/report_writing/synthese-des-travaux.html" rel="" target="">
 <span class="dropdown-text">Pr√©dire la dur√©e de carri√®re des joueurs NBA</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../FORMATIONS/logistic_regression_diabetes.html" rel="" target="">
 <span class="dropdown-text">Mod√©lisation des donn√©es √† variables d√©pendantes binaires</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../FORMATIONS/poisson_paludisme.html" rel="" target="">
 <span class="dropdown-text">Mod√©lisation des donn√©es de comptage</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../INFO_MINI_PROJETS/brain-tumor-classification-effcientnet.html" rel="" target="">
 <span class="dropdown-text">Diagnostic tumeurs c√©r√©brales - Reseau de neurones</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ANALYSES_FACTORIELLES/acp-kmeans.html" rel="" target="">
 <span class="dropdown-text">Reduction de dimensionnalit√© et clustering non supervis√©</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../INFO_MINI_PROJETS/classi_bin_acp_kmeans_knn_logit/work.html" rel="" target="">
 <span class="dropdown-text">ACP, Kmeans, KNN et Logistique au service des donn√©es m√©dicales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../INFO_MINI_PROJETS/shifumi-cnn-yolov8.html" rel="" target="">
 <span class="dropdown-text">Classification des gestes de la main avec Yolo et CNN</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-programming" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Programming</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-programming">    
        <li>
    <a class="dropdown-item" href="../../INFO_MINI_PROJETS/assistant_virtuel.html" rel="" target="">
 <span class="dropdown-text">Cr√©e ton assistant virtuel avec pyhton</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../INFO_MINI_PROJETS/JavaApp/desktop-app-java-mysql.html" rel="" target="">
 <span class="dropdown-text">Application desktop avec Java et Mysql</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-various" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Various</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-various">    
        <li>
    <a class="dropdown-item" href="../../FORMATIONS/machine-learning/gradient-descent-linear-reg.html" rel="" target="">
 <span class="dropdown-text">R√©gression lin√©aire par descente de gradient - th√©orie et application</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About me</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://www.linkedin.com/in/djamal-toe-7a18432b0" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text">LinkedIn</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#r√©sum√©" id="toc-r√©sum√©" class="nav-link active" data-scroll-target="#r√©sum√©">R√©sum√©</a></li>
  <li><a href="#abstract" id="toc-abstract" class="nav-link" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#un-peu-de-formalisme" id="toc-un-peu-de-formalisme" class="nav-link" data-scroll-target="#un-peu-de-formalisme">Un peu de formalisme</a></li>
  <li><a href="#algorithme-de-la-descente-de-gradient-cas-de-la-regression-lin√©aire" id="toc-algorithme-de-la-descente-de-gradient-cas-de-la-regression-lin√©aire" class="nav-link" data-scroll-target="#algorithme-de-la-descente-de-gradient-cas-de-la-regression-lin√©aire">Algorithme de la descente de gradient : cas de la regression lin√©aire</a></li>
  <li><a href="#v√©rification-de-la-convergence" id="toc-v√©rification-de-la-convergence" class="nav-link" data-scroll-target="#v√©rification-de-la-convergence">üîé V√©rification de la convergence</a></li>
  <li><a href="#mise-√†-jour-des-param√®tres" id="toc-mise-√†-jour-des-param√®tres" class="nav-link" data-scroll-target="#mise-√†-jour-des-param√®tres">‚öôÔ∏è Mise √† jour des param√®tres</a></li>
  <li><a href="#remarques-pratiques" id="toc-remarques-pratiques" class="nav-link" data-scroll-target="#remarques-pratiques">üß™ Remarques pratiques</a></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications">Applications</a></li>
  <li><a href="#analyse-exploratoire-rapide" id="toc-analyse-exploratoire-rapide" class="nav-link" data-scroll-target="#analyse-exploratoire-rapide">Analyse exploratoire (rapide)</a></li>
  <li><a href="#data-preprocessing" id="toc-data-preprocessing" class="nav-link" data-scroll-target="#data-preprocessing">Data preprocessing</a></li>
  <li><a href="#application-de-lalgorithme-de-la-descente-de-gradient" id="toc-application-de-lalgorithme-de-la-descente-de-gradient" class="nav-link" data-scroll-target="#application-de-lalgorithme-de-la-descente-de-gradient">Application de l‚Äôalgorithme de la descente de gradient</a></li>
  <li><a href="#evaluation-du-mod√®le" id="toc-evaluation-du-mod√®le" class="nav-link" data-scroll-target="#evaluation-du-mod√®le">Evaluation du mod√®le</a>
  <ul class="collapse">
  <li><a href="#r√©sultats-par-pli" id="toc-r√©sultats-par-pli" class="nav-link" data-scroll-target="#r√©sultats-par-pli">R√©sultats par pli</a></li>
  <li><a href="#interpr√©tation" id="toc-interpr√©tation" class="nav-link" data-scroll-target="#interpr√©tation">Interpr√©tation</a></li>
  <li><a href="#visualisation-des-erreurs-par-pli" id="toc-visualisation-des-erreurs-par-pli" class="nav-link" data-scroll-target="#visualisation-des-erreurs-par-pli">Visualisation des erreurs par pli</a></li>
  </ul></li>
  <li><a href="#evaluation-du-mod√®le-final-sur-les-donn√©es-de-test" id="toc-evaluation-du-mod√®le-final-sur-les-donn√©es-de-test" class="nav-link" data-scroll-target="#evaluation-du-mod√®le-final-sur-les-donn√©es-de-test">Evaluation du mod√®le final sur les donn√©es de test</a></li>
  <li><a href="#conclusion-g√©n√©rale" id="toc-conclusion-g√©n√©rale" class="nav-link" data-scroll-target="#conclusion-g√©n√©rale">Conclusion g√©n√©rale</a>
  <ul class="collapse">
  <li><a href="#points-cl√©s-√†-retenir" id="toc-points-cl√©s-√†-retenir" class="nav-link" data-scroll-target="#points-cl√©s-√†-retenir">Points cl√©s √† retenir</a></li>
  <li><a href="#perspectives" id="toc-perspectives" class="nav-link" data-scroll-target="#perspectives">Perspectives</a></li>
  <li><a href="#finalement" id="toc-finalement" class="nav-link" data-scroll-target="#finalement">Finalement</a></li>
  </ul></li>
  <li><a href="#remerciements-et-retour-dexp√©rience" id="toc-remerciements-et-retour-dexp√©rience" class="nav-link" data-scroll-target="#remerciements-et-retour-dexp√©rience">Remerciements et retour d‚Äôexp√©rience</a></li>
  <li><a href="#annexes" id="toc-annexes" class="nav-link" data-scroll-target="#annexes">Annexes</a>
  <ul class="collapse">
  <li><a href="#standardisation-des-variables" id="toc-standardisation-des-variables" class="nav-link" data-scroll-target="#standardisation-des-variables">1. Standardisation des variables</a></li>
  <li><a href="#codage-one-hot" id="toc-codage-one-hot" class="nav-link" data-scroll-target="#codage-one-hot">2. Codage One-Hot</a></li>
  <li><a href="#calcul-de-la-rmse" id="toc-calcul-de-la-rmse" class="nav-link" data-scroll-target="#calcul-de-la-rmse">3. Calcul de la RMSE</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Mise en ≈ìuvre de l‚Äôalgorithme de la descente de gradient : Cas de la r√©gression lin√©aire</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Djamal TOE </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 8, 2025</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, OneHotEncoder</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'deeplearning.mplstyle'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="r√©sum√©" class="level2">
<h2 class="anchored" data-anchor-id="r√©sum√©">R√©sum√©</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;√Ä la suite de mes cours d‚Äôoptimisation et de calcul num√©rique, j‚Äôai souhait√© impl√©menter moi-m√™me l‚Äôalgorithme de la descente de gradient. J‚Äôai choisi comme premier cas d‚Äôapplication la <strong><code>r√©gression lin√©aire</code></strong>, dans le but d‚Äôestimer les param√®tres optimaux (<code>w</code>, <code>b</code>) qui minimisent la fonction de co√ªt (g√©n√©ralement l‚Äôerreur quadratique moyenne).</p>
<p>M√™me si, dans le cas de la r√©gression lin√©aire, il existe une solution analytique explicite par la m√©thode des moindres carr√©s, cette situation est id√©ale pour comprendre et tester l‚Äôefficacit√© de la descente de gradient. En revanche, pour des mod√®les plus complexes comme la r√©gression logistique, une solution analytique n‚Äôest plus disponible. Dans ces cas, on utilise syst√©matiquement des <strong><code>m√©thodes num√©riques</code></strong> comme la descente de gradient.</p>
<hr>
</section>
<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Following my coursework in optimization and numerical methods, I implemented the <strong><code>gradient descent algorithm</code></strong> from scratch, starting with the case of <strong><code>linear regression</code></strong>. While a closed-form solution exists for linear models, using gradient descent allows for a deeper understanding of iterative optimization. This approach becomes essential when working with more complex models, such as <strong><code>logistic regression</code></strong>, where no explicit analytical solution is available.</p>
<hr>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L‚Äôobjectif de ce document est de pr√©senter l‚Äôimpl√©mentation de l‚Äôalgorithme de descente de gradient dans le cas de la r√©gression lin√©aire multiple, afin de mieux comprendre le principe d‚Äôoptimisation it√©rative. On commence par un rappel de la r√©gression lin√©aire classique, avant de d√©river la fonction de co√ªt et ses gradients par rapport aux param√®tres. Ensuite, l‚Äôalgorithme est appliqu√© √† un jeu de donn√©es simul√© pour illustrer sa convergence et les effets du taux d‚Äôapprentissage.</p>
<p>Dans une deuxi√®me partie, nous discuterons des limites de l‚Äôapproche analytique, notamment dans des contextes o√π la descente de gradient devient incontournable (r√©gression logistique, r√©seaux de neurones, etc.).</p>
<hr>
</section>
<section id="un-peu-de-formalisme" class="level2">
<h2 class="anchored" data-anchor-id="un-peu-de-formalisme">Un peu de formalisme</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Nous souhaitons minimiser une fonction objective, appel√©e √©galement <strong><code>fonction de co√ªt</code></strong>. Avant de chercher une m√©thode num√©rique pour effectuer cette minimisation, il est essentiel de s‚Äôassurer que la fonction admet bien un minimum, et que celui-ci est <strong><code>unique</code></strong>.</p>
<p>En effet, une fonction peut pr√©senter <strong><code>plusieurs minima locaux</code></strong>, et l‚Äôobjectif est g√©n√©ralement d‚Äôatteindre le <strong><code>minimum global</code></strong>. Pour garantir l‚Äôexistence d‚Äôun minimum global, on fait appel au <strong><code>th√©or√®me de Weierstrass</code></strong>, qui stipule qu‚Äôune fonction continue sur un ensemble compact atteint un minimum (et un maximum).</p>
<p>Mais pour garantir l‚Äôunicit√© du minimum, on utilise la notion de <strong><code>convexit√©</code></strong>. Une fonction strictement convexe sur un domaine convexe poss√®de un unique minimum qui est donc le minimum global.</p>
<blockquote class="blockquote">
<p>üí° Si votre fonction de co√ªt est <strong><code>concave</code></strong> (au lieu d‚Äô√™tre convexe), il suffit d‚Äôen prendre l‚Äôoppos√©. La maximisation d‚Äôune fonction concave revient √† minimiser son oppos√©e, qui sera convexe.</p>
</blockquote>
<p>Ainsi, <strong>la stricte convexit√©</strong> de la fonction objective est une propri√©t√© cruciale : elle permet de garantir l‚Äôunicit√© du minimum et donc la convergence de l‚Äôalgorithme vers une solution bien d√©finie.</p>
<p>Je n‚Äôentrerai pas dans trop de details math√©matiques. Si vous voulez en savoir plus (condition d‚Äôapplication du th√©or√®me de weierstrass -&gt; s√©mi-continuit√© + espace de contraintes born√© ou semi-continuit√© + coercivit√© + espace de contraintes ferm√©) consultez cette page : &lt;<a href="https://en.wikipedia.org/wiki/Extreme_value_theorem" class="uri">https://en.wikipedia.org/wiki/Extreme_value_theorem</a>&gt; et faites des recherches suppl√©mentaires.</p>
<hr>
</section>
<section id="algorithme-de-la-descente-de-gradient-cas-de-la-regression-lin√©aire" class="level2">
<h2 class="anchored" data-anchor-id="algorithme-de-la-descente-de-gradient-cas-de-la-regression-lin√©aire">Algorithme de la descente de gradient : cas de la regression lin√©aire</h2>
<ul>
<li><strong>Fonction de co√ªt de la regression lin√©aire</strong></li>
</ul>
<p>La fonction de co√ªt utilis√©e pour la r√©gression lin√©aire est la (ou <code>Mean Squared Error</code>, MSE). Elle s‚Äô√©crit comme suit :</p>
<p><span class="math display">\[
\begin{equation}
    J(w, b) = \frac{1}{2m} \sum_{i=1}^{m} \left( \hat{y}^{(i)} - y^{(i)} \right)^2
\end{equation}
\]</span></p>
<p>o√π :</p>
<p>En <strong><em>notation vectorielle</em></strong>, on peut r√©√©crire la fonction de co√ªt sous la forme :</p>
<p><span class="math display">\[
\begin{equation}
    J(w, b) = \frac{1}{2m} (\hat{Y} - Y)^T (\hat{Y} - Y)
\end{equation}
\]</span></p>
<p>o√π :</p>
<p><span class="math display">\[
\begin{equation}
    J(w, b) = \frac{1}{2m} \left\| \hat{Y} - Y \right\|^2
\end{equation}
\]</span></p>
<ul>
<li>üîª <strong>Descente de Gradient</strong></li>
</ul>
<p>L‚Äôobjectif de la descente de gradient est de d√©terminer les param√®tres optimaux <span class="math inline">\(w\)</span> et <span class="math inline">\(b\)</span> qui minimisent la fonction de co√ªt. Pour cela, on utilise un algorithme <strong>it√©ratif</strong> qui met progressivement √† jour ces param√®tres <strong>dans le sens oppos√© au gradient</strong>.</p>
<p>√Ä chaque it√©ration, les nouvelles valeurs de <span class="math inline">\(w\)</span> et <span class="math inline">\(b\)</span> doivent id√©alement conduire √† une <strong>diminution de la fonction de co√ªt</strong>. Si la fonction <strong>augmente</strong>, cela peut √™tre d√ª √† :</p>
<ul>
<li>un <strong>taux d‚Äôapprentissage</strong> (<span class="math inline">\(\alpha\)</span>) trop <strong>√©lev√©</strong>, provoquant une <strong>divergence</strong> ;</li>
<li>une <strong>erreur de code</strong>, par exemple un mauvais calcul du gradient.</li>
</ul>
<p>En revanche, si la fonction de co√ªt diminue <strong>trop lentement</strong>, cela peut signifier :</p>
<ul>
<li>un taux d‚Äôapprentissage trop <strong>faible</strong>, causant une <strong>convergence lente</strong> ou incompl√®te.</li>
</ul>
<blockquote class="blockquote">
<p>‚ö†Ô∏è Dans certains cas, la fonction de co√ªt peut <strong>onduler</strong> √† chaque it√©ration (oscillations), souvent √† cause d‚Äôune mauvaise normalisation ou d‚Äôun <span class="math inline">\(\alpha\)</span> mal ajust√©.</p>
</blockquote>
<hr>
</section>
<section id="v√©rification-de-la-convergence" class="level2">
<h2 class="anchored" data-anchor-id="v√©rification-de-la-convergence">üîé V√©rification de la convergence</h2>
<p>Pour s‚Äôassurer que l‚Äôalgorithme converge correctement, on peut :</p>
<ul>
<li><strong>Tracer graphiquement</strong> la valeur de la fonction de co√ªt √† chaque it√©ration.</li>
<li>Fixer un <strong>seuil de tol√©rance</strong> :</li>
</ul>
<p><span class="math display">\[
\text{Si } \|\nabla J(w, b)\| &lt; \varepsilon, \text{ alors on arr√™te l'algorithme.}
\]</span></p>
<hr>
</section>
<section id="mise-√†-jour-des-param√®tres" class="level2">
<h2 class="anchored" data-anchor-id="mise-√†-jour-des-param√®tres">‚öôÔ∏è Mise √† jour des param√®tres</h2>
<p>La descente de gradient met √† jour <strong>simultan√©ment</strong> les poids et le biais selon la r√®gle :</p>
<p><span class="math display">\[
w := w - \alpha \cdot \frac{\partial J(w, b)}{\partial w}
\]</span></p>
<p><span class="math display">\[
b := b - \alpha \cdot \frac{\partial J(w, b)}{\partial b}
\]</span></p>
<p>o√π :</p>
<ul>
<li><span class="math inline">\(J(w, b)\)</span> est la fonction de co√ªt,</li>
<li><span class="math inline">\(\alpha\)</span> est le <strong>learning rate</strong>.</li>
</ul>
<hr>
</section>
<section id="remarques-pratiques" class="level2">
<h2 class="anchored" data-anchor-id="remarques-pratiques">üß™ Remarques pratiques</h2>
<ul>
<li>Un <strong>taux d‚Äôapprentissage dynamique</strong> (adaptatif) peut am√©liorer la convergence.</li>
<li>Des techniques comme <strong>momentum</strong>, <strong>RMSprop</strong> ou <strong>Adam</strong> sont des variantes plus stables.</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># G√©n√©ration des it√©rations</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>iterations <span class="op">=</span> np.arange(<span class="dv">0</span>, <span class="dv">100</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulations de comportements de co√ªt</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>convergence_bonne <span class="op">=</span> np.exp(<span class="op">-</span><span class="fl">0.05</span> <span class="op">*</span> iterations) <span class="op">+</span> <span class="fl">0.05</span> <span class="op">*</span> np.random.randn(<span class="dv">100</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>divergence <span class="op">=</span> <span class="fl">0.1</span> <span class="op">*</span> iterations <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> np.random.rand(<span class="dv">100</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Trac√©</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>plt.plot(iterations, convergence_bonne, label<span class="op">=</span><span class="st">'Bonne convergence'</span>, color<span class="op">=</span><span class="st">'green'</span>, linewidth<span class="op">=</span><span class="fl">1.2</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>plt.plot(iterations, divergence, label<span class="op">=</span><span class="st">'Divergence'</span>, color<span class="op">=</span><span class="st">'red'</span>, linewidth<span class="op">=</span><span class="fl">1.2</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"It√©rations"</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Co√ªt simul√©"</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Diff√©rents comportements de la fonction de co√ªt"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-fiting" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="gradient-descent-linear-reg_files/figure-html/fig-fiting-1.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Exemple d‚Äôapprentissage</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Descente de Gradient et R√©gularisation">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Descente de Gradient et R√©gularisation
</div>
</div>
<div class="callout-body-container callout-body">
<p>L‚Äô<strong>algorithme de descente de gradient</strong> est une m√©thode d‚Äôoptimisation utilis√©e pour ajuster les param√®tres d‚Äôun mod√®le en minimisant une fonction de co√ªt. Il repose sur le calcul du gradient (ou pente) de cette fonction par rapport aux param√®tres, et sur une mise √† jour it√©rative jusqu‚Äô√† convergence.</p>
<p>Cependant, en pratique, on rencontre souvent le <strong>probl√®me de surapprentissage (overfitting)</strong>, notamment lorsque :</p>
<ul>
<li>Le nombre de variables est √©lev√© par rapport au nombre d‚Äôobservations.</li>
<li>Certaines variables explicatives n‚Äôapportent que peu ou pas d‚Äôinformation utile.</li>
<li>Le mod√®le devient trop complexe, capturant le bruit au lieu du signal.</li>
</ul>
<p>Pour pallier cela, plusieurs strat√©gies existent :</p>
<ul>
<li>üîÑ <strong>Augmenter la taille du jeu de donn√©es</strong> : plus de donn√©es permet de mieux g√©n√©raliser.</li>
<li>üß† <strong>S√©lectionner judicieusement les variables</strong> : par des techniques comme le <em>feature selection</em>, on garde seulement les plus pertinentes.</li>
<li>üõ°Ô∏è <strong>Appliquer une r√©gularisation</strong> (comme Lasso ou Ridge) : on p√©nalise la complexit√© du mod√®le pour √©viter l‚Äôajustement excessif.</li>
</ul>
<p>üëâ Ces aspects seront peut-√™tre explor√©s plus en d√©tail dans une prochaine publication √† travers un <strong>mod√®le de r√©gression logistique appliqu√© √† des donn√©es r√©elles</strong>, o√π la s√©lection de variables et la r√©gularisation joueront un r√¥le central.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="La R√©gression Polynomiale">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
La R√©gression Polynomiale
</div>
</div>
<div class="callout-body-container callout-body">
<p>La <strong>r√©gression polynomiale</strong> est une extension de la r√©gression lin√©aire o√π l‚Äôon introduit des puissances suppl√©mentaires des variables explicatives pour capturer des relations <strong>non lin√©aires</strong> entre les variables.</p>
<p>Exemple :</p>
<p><span class="math display">\[
y = w_0 + w_1 x + w_2 x^2 + w_3 x^3 + \dots + w_d x^d + \varepsilon
\]</span></p>
<p>Cela permet au mod√®le de s‚Äôadapter √† des courbes complexes, mais augmente √©galement le <strong>risque de surapprentissage</strong>. Plus le degr√© ( d ) est √©lev√©, plus le mod√®le est flexible, mais moins il g√©n√©ralise bien si les donn√©es ne sont pas suffisantes.</p>
<p>‚û°Ô∏è Il est donc <strong>essentiel de combiner cette approche avec des techniques de validation crois√©e et de r√©gularisation</strong>, pour trouver le bon compromis entre biais et variance.</p>
</div>
</div>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">Applications</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dans cette section, nous coommen√ßons d‚Äôabord par simuler un jeu de donn√©es synth√©tiques repr√©sentant des individus caract√©ris√©s par leur √¢ge, leur niveau d‚Äô√©ducation, leur sexe, ainsi que leur salaire annuel. Le salaire est g√©n√©r√© √† partir d‚Äôun mod√®le probabiliste bas√© sur des salaires de base associ√©s √† chaque niveau d‚Äô√©ducation, auxquels s‚Äôajoute un effet lin√©aire de l‚Äô√¢ge, et une part d‚Äôal√©a simul√©e √† l‚Äôaide d‚Äôune distribution normale.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># generating data</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># fixing generator seed</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># number of observation</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>size <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># creating age variable</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>ages <span class="op">=</span> np.random.randint(low<span class="op">=</span><span class="dv">21</span>, high<span class="op">=</span><span class="dv">66</span>, size<span class="op">=</span>size)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># creating education level variable</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>levels <span class="op">=</span> [<span class="st">'BAC'</span>, <span class="st">'Bachelor degree'</span>, <span class="st">'Msc'</span>, <span class="st">'PhD'</span>]</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>educ_level <span class="op">=</span> np.random.choice(levels, size<span class="op">=</span>size, p<span class="op">=</span>[<span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.4</span>])</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># creating sexe variable</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>sexes <span class="op">=</span> [<span class="st">'M'</span>, <span class="st">'F'</span>]</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>sexe <span class="op">=</span> np.random.choice(sexes, size<span class="op">=</span>size)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co"># creating annual salary (Euro) based on the different informations above</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>base_salary <span class="op">=</span> {</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'BAC'</span>: <span class="dv">25000</span>,</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Bachelor degree'</span>: <span class="dv">30000</span>,</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Msc'</span>: <span class="dv">45000</span>,</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">'PhD'</span>: <span class="dv">75000</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>salary <span class="op">=</span> np.asarray([</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>  <span class="bu">round</span>(np.random.normal(base_salary[edu_lvl] <span class="op">+</span> (age<span class="op">*</span><span class="dv">2</span>), <span class="dv">100</span>)) </span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> edu_lvl, age <span class="kw">in</span> <span class="bu">zip</span>(educ_level, ages)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>        <span class="st">'salary'</span>: salary,</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ages'</span>: ages,</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>        <span class="st">'sex'</span>: sexe,</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>        <span class="st">'education'</span>: educ_level</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><strong>Algorithme du calcul de la fonction de co√ªt</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_cost_fn(x:np.ndarray, y:np.ndarray, w:np.array, b:<span class="bu">float</span>) <span class="op">-&gt;</span> <span class="bu">float</span>:</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">        Calculates the cost function (MSE divided by 2)</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">        for multivariate linear regression.</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">            x (np.ndarray): Matrix of explanatory variables (shape: [m, n])</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">            y (np.ndarray): Vector of target values (shape: [m,])</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">            w (np.ndarray): Weight vector (shape: [n,])</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">            b (float): Bias (scalar)</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co">            float: Value of the cost function</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> x<span class="op">@</span>w <span class="op">+</span> b</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    square_error <span class="op">=</span> np.<span class="bu">sum</span>((y <span class="op">-</span> y_hat)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    cost_fn <span class="op">=</span> square_error<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>m)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost_fn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><strong>Algorithme du calcul du gradient de la fonction de co√ªt</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_gradient(x:np.ndarray, y:np.ndarray, w:np.array, b:<span class="bu">float</span>) <span class="op">-&gt;</span> <span class="bu">tuple</span>:</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""_summary_</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">        x (np.ndarray): _description_</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">        y (np.ndarray): _description_</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">        w (np.array): _description_</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">        b (float): _description_</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">        tuple: _description_</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> x <span class="op">@</span> w <span class="op">+</span> b</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    square_error <span class="op">=</span> y_hat <span class="op">-</span> y</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    fw_prime <span class="op">=</span> (x.T <span class="op">@</span> square_error)<span class="op">/</span>m</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    fb_prime <span class="op">=</span> np.<span class="bu">sum</span>(square_error)<span class="op">/</span>m</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> fw_prime, fb_prime</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><strong>Algorithme de la descente de gradient</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Callable</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> copy <span class="im">import</span> deepcopy</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_descent(</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    x: np.ndarray,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    y: np.ndarray,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    alpha: <span class="bu">float</span>,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    w_in: np.array,</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    b_in: <span class="bu">float</span>,</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    max_iter: <span class="bu">int</span>,</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    tolerance: <span class="bu">float</span>,</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    cost_fn: Callable,</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    gradient_compute_fn: Callable) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Performs gradient descent to adjust</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co">    the parameters w and b.</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co">        x (np.ndarray): Input data (m, n)</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co">        y (np.ndarray): Target (m,)</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co">        w_in (np.ndarray): Initial weight (n,)</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co">        b_in (float): Initial bias</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="co">        alpha (float): Learning rate</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="co">        max_iter (int): Maximum number of iterations</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co">        tolerance (float): Convergence threshold</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="co">        cost_fn (Callable): Cost function</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="co">        gradient_compute_fn (Callable): Gradient calculation function</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="co">        dict: History of parameters and cost at each iteration</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> deepcopy(w_in)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> b_in</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    cost_fn_and_params_hist <span class="op">=</span> {}</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_iter):</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>        fw_i, fb_i <span class="op">=</span> gradient_compute_fn(x, y, w, b)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>        w <span class="op">=</span> w <span class="op">-</span> alpha<span class="op">*</span>fw_i</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> b <span class="op">-</span> alpha<span class="op">*</span>fb_i</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>        cost_fn_i <span class="op">=</span> cost_fn(x, y, w, b)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>        cost_fn_and_params_hist[i] <span class="op">=</span> {</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>            <span class="st">'w'</span>: w.copy(),</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">'b'</span>: b,</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>            <span class="st">'cost_fn'</span>: cost_fn_i</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">%</span> <span class="dv">15000</span> <span class="op">==</span> <span class="dv">0</span>: <span class="co"># vous pouvez ajuster: moi je ne veux pas afficher toutes les it√©rations</span></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'Iteraion </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> : </span><span class="ch">\n</span><span class="ss">|(w, b) = (</span><span class="sc">{</span>w<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>b<span class="sc">:4f}</span><span class="ss">) | cost_fn = </span><span class="sc">{</span>cost_fn_i<span class="sc">:4f}</span><span class="ss">|'</span></span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.linalg.norm(fw_i) <span class="op">&lt;</span> tolerance <span class="kw">and</span> <span class="bu">abs</span>(fb_i) <span class="op">&lt;</span> tolerance:</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'The algorithm converges at the </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">-th iteration'</span></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'</span><span class="ch">\n</span><span class="ss">Then we have (w, b) = (</span><span class="sc">{</span>w<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>b<span class="sc">:4f}</span><span class="ss">) &amp; cost_fn = </span><span class="sc">{</span>cost_fn_i<span class="sc">:4f}</span><span class="ss">'</span></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost_fn_and_params_hist</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
</section>
<section id="analyse-exploratoire-rapide" class="level2">
<h2 class="anchored" data-anchor-id="analyse-exploratoire-rapide">Analyse exploratoire (rapide)</h2>
<p>Ici on veut predire le salaire d‚Äôun individu en fonction de son niveau d‚Äô√©ducation, de son √¢ge et de son sexe.</p>
<ul>
<li><strong>Premi√®res lignes de la table</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>df_5 <span class="op">=</span> df.loc[:<span class="dv">5</span>, :]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df_5_r <span class="ot">=</span> py<span class="sc">$</span>df_5</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">display_table</span>(df_5_r, <span class="st">"Les premi√®res lignes de notre base de donn√©es"</span>, <span class="at">nrow_ =</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="tbl-first" class="cell tbl-cap-location-top tbl-parent quarto-layout-panel anchored">
<div class="panel-caption table-caption">
<p>Table&nbsp;1: <strong>?(caption)</strong></p>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div id="tbl-first-1" class="quarto-layout-cell quarto-layout-cell-subref anchored" data-ref-parent="tbl-first" style="flex-basis: 100.0%;justify-content: center;">
<table class="table table-sm table-striped small">
<caption>(a) Les premi√®res lignes de notre base de donn√©es</caption>
<thead>
<tr class="header">
<th style="text-align: left;">salary</th>
<th style="text-align: right;">ages</th>
<th style="text-align: right;">sex</th>
<th style="text-align: right;">education</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">75213</td>
<td style="text-align: right;">59</td>
<td style="text-align: right;">F</td>
<td style="text-align: right;">PhD</td>
</tr>
<tr class="even">
<td style="text-align: left;">45269</td>
<td style="text-align: right;">49</td>
<td style="text-align: right;">F</td>
<td style="text-align: right;">Msc</td>
</tr>
<tr class="odd">
<td style="text-align: left;">45060</td>
<td style="text-align: right;">35</td>
<td style="text-align: right;">M</td>
<td style="text-align: right;">Msc</td>
</tr>
<tr class="even">
<td style="text-align: left;">75109</td>
<td style="text-align: right;">63</td>
<td style="text-align: right;">F</td>
<td style="text-align: right;">PhD</td>
</tr>
<tr class="odd">
<td style="text-align: left;">45063</td>
<td style="text-align: right;">28</td>
<td style="text-align: right;">M</td>
<td style="text-align: right;">Msc</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<ul>
<li><strong>R√©sum√© statistique de la table</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>df.describe() <span class="co"># affcihe le r√©sum√© statistique des variables num√©riques</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             salary         ages
count   1000.000000  1000.000000
mean   52498.163000    43.000000
std    20121.852889    12.945562
min    24882.000000    21.000000
25%    30139.000000    32.000000
50%    45133.000000    44.000000
75%    75065.000000    54.000000
max    75441.000000    65.000000</code></pre>
</div>
</div>
<ul>
<li><strong>Distribution du salaire en fonction des features</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>X_features <span class="op">=</span> df.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>).columns.to_list()</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>X_features</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['ages', 'sex', 'education']</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize <span class="op">=</span> (<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(axes)):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    axes[i].scatter(y<span class="op">=</span>df[<span class="st">'salary'</span>], x<span class="op">=</span>df[df.columns.to_list()[i <span class="op">+</span> <span class="dv">1</span>]])</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(X_features[i].capitalize(), fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylabel(<span class="st">'Salary'</span>, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(X_features[i].capitalize(), size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    axes[i].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="ss">f'Relation between salary and </span><span class="sc">{</span>X_features[i]<span class="sc">.</span>capitalize()<span class="sc">}</span><span class="ss">'</span>, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-dist-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="gradient-descent-linear-reg_files/figure-html/fig-dist-plot-1.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Distribution des variables en fonction du salaire</figcaption>
</figure>
</div>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;De prime abord on pour se dire qu‚Äôil existe un lien non lin√©aire entre les variables, ce qui n‚Äôest pas totalement juste car ‚Ä¶</p>
<hr>
</section>
<section id="data-preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="data-preprocessing">Data preprocessing</h2>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Code pour partitionner les donn√©es
</div>
</div>
<div class="callout-body-container callout-body">
<p>La fonction suivante permet de diviser vos donn√©es en ensembles d‚Äôentra√Ænement et de test pour la validation du mod√®le. Il est important de s‚Äôassurer que les deux ensembles contiennent toutes les cat√©gories ou modalit√©s des variables cat√©gorielles (<strong><em>indice : stratification</em></strong>). La fonction ci-dessous ne prend pas cela en charge automatiquement. Cependant, gr√¢ce √† la taille de notre jeu de donn√©es et √† l‚Äôutilisation de la graine al√©atoire fix√©e √† 42, nous pouvons garantir que ces caract√©ristiques sont bien pr√©sentes dans les deux ensembles.</p>
</div>
</div>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> train[<span class="st">'education'</span>].unique()</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>array([<span class="st">'Bachelor degree'</span>, <span class="st">'PhD'</span>, <span class="st">'Msc'</span>, <span class="st">'BAC'</span>], dtype<span class="op">=</span><span class="bu">object</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> test[<span class="st">'education'</span>].unique()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>array([<span class="st">'Msc'</span>, <span class="st">'PhD'</span>, <span class="st">'BAC'</span>, <span class="st">'Bachelor degree'</span>], dtype<span class="op">=</span><span class="bu">object</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_data_partition(df, train_ratio):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co">        Creates a random partition of the DataFrame into training and test sets.</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co">            df (pd.DataFrame): the complete DataFrame</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co">            train_ratio (float): the proportion of rows to be used for training (ex: 0.8)</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co">            tuple: (train_df, test_df)</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    nrow_df <span class="op">=</span> df.shape[<span class="dv">0</span>]</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    nrow_train <span class="op">=</span> <span class="bu">round</span>(nrow_df<span class="op">*</span>train_ratio)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    train_idx <span class="op">=</span> np.random.choice(df.index, size<span class="op">=</span>nrow_train, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    test_idx <span class="op">=</span> df.index.difference(train_idx)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    train_df <span class="op">=</span> df.iloc[train_idx]</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    test_df <span class="op">=</span> df.iloc[test_idx]</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (train_df, test_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Une fois les donn√©es simul√©es, nous proc√©dons √† leur s√©paration en deux sous-ensembles distincts : un ensemble d‚Äôentra√Ænement, utilis√© pour ajuster le mod√®le, et un ensemble de test, destin√© √† l‚Äô√©valuer. La fonction <code>create_data_partition</code> r√©alise une partition al√©atoire selon un ratio d√©fini (ici 80% pour l‚Äôentra√Ænement, 20% pour le test). Ensuite, les variables explicatives (<code>ages</code>, <code>education</code>, <code>sex</code>) sont trait√©es via une pipeline de pr√©traitement : les variables num√©riques sont standardis√©es (centr√©es-r√©duites) tandis que les variables cat√©gorielles sont transform√©es en indicatrices (encodage one-hot, sans la premi√®re modalit√©). Enfin, la variable cible (<code>salary</code>) est √©galement standardis√©e pour assurer une convergence efficace de l‚Äôalgorithme de descente de gradient.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># data preprocessing</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># geting train and test datasets</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>train, test <span class="op">=</span> create_data_partition(df, <span class="fl">0.8</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting features</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> train.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting target variable</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> train[<span class="st">'salary'</span>]</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co"># standardization of the target variable</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>scaler_y <span class="op">=</span> StandardScaler()</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>onehot_encoder_educ <span class="op">=</span> OneHotEncoder()</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>y_scaled <span class="op">=</span> scaler_y.fit_transform(y.values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)).flatten()</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="co"># one-hot encodings &amp; standardization : pipeline treatment</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>numeric_features <span class="op">=</span> [<span class="st">'ages'</span>]</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>categorical_features <span class="op">=</span> [<span class="st">'education'</span>, <span class="st">'sex'</span>]</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>preprocessor <span class="op">=</span> ColumnTransformer(transformers<span class="op">=</span>[</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'num'</span>, StandardScaler(), numeric_features),</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'cat'</span>, OneHotEncoder(drop<span class="op">=</span><span class="st">'first'</span>), categorical_features)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="co"># transform numerical values by standardize them and categorical one by dummy them</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>X_processed <span class="op">=</span> preprocessor.fit_transform(X<span class="op">=</span>X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
‚ö†Ô∏è Important : <code>fit_transform()</code> vs <code>transform()</code>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Toujours utiliser <code>fit_transform()</code> <strong>uniquement sur les donn√©es d‚Äôentra√Ænement</strong>, et <code>transform()</code> sur les donn√©es de validation ou de test.</p>
<p>Cela s‚Äôapplique √† <strong>tous les types de preprocessing</strong>, notamment :</p>
<ul>
<li>üü¶ <strong>StandardScaler</strong> : la moyenne et l‚Äô√©cart-type doivent √™tre appris sur le <em>train</em> uniquement.</li>
<li>üüß <strong>OneHotEncoder</strong> : les cat√©gories doivent √™tre identifi√©es √† partir du <em>train</em> et appliqu√©es de mani√®re coh√©rente au <em>test</em>.</li>
</ul>
<p>‚ùå Ne jamais faire <code>fit_transform()</code> sur le test, car cela introduit du <strong>data leakage</strong> (les donn√©es de test influencent le mod√®le).</p>
</div>
</div>
<hr>
</section>
<section id="application-de-lalgorithme-de-la-descente-de-gradient" class="level2">
<h2 class="anchored" data-anchor-id="application-de-lalgorithme-de-la-descente-de-gradient">Application de l‚Äôalgorithme de la descente de gradient</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Comme mentionn√© pr√©c√©demment, le choix du <code>learning rate</code> (ou taux d‚Äôapprentissage) est un param√®tre crucial dans l‚Äôalgorithme de descente de gradient. Un taux trop √©lev√© peut emp√™cher la convergence du mod√®le, tandis qu‚Äôun taux trop faible peut rendre l‚Äôapprentissage extr√™mement lent. Afin d‚Äôidentifier un taux optimal, plusieurs valeurs sont test√©es, et celle qui permet de minimiser au mieux la fonction de co√ªt est retenue.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>alphas <span class="op">=</span> [<span class="fl">1e-1</span>, <span class="fl">1e-2</span>] <span class="co"># , 1e-3, 1e-4, 1e-5 √† ajouter si vous voulez, je veux juste reduire l'affichage</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>n_features <span class="op">=</span> X_processed.shape[<span class="dv">1</span>]</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> np.zeros(n_features)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.random.randint(<span class="dv">100</span>, size<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="bu">int</span>(b)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>tolerance <span class="op">=</span> <span class="fl">1e-3</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>max_iters <span class="op">=</span> <span class="dv">50000</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>cost_fn <span class="op">=</span> compute_cost_fn</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>gradient_fn <span class="op">=</span> compute_gradient</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>all_histories <span class="op">=</span> {}</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha <span class="kw">in</span> alphas:</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Runing the algorithm for alpha : </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ch">\n</span><span class="ss">'</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> np.zeros(n_features)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> <span class="bu">int</span>(np.random.randint(<span class="dv">100</span>, size<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>])</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> gradient_descent(</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        X_processed,</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>        y_scaled,</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>        alpha<span class="op">=</span>alpha,</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>        w_in<span class="op">=</span>w,</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        b_in<span class="op">=</span>b,</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        max_iter<span class="op">=</span>max_iters,</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>        tolerance<span class="op">=</span>tolerance,</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>        cost_fn<span class="op">=</span>cost_fn,</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>        gradient_compute_fn<span class="op">=</span>gradient_fn)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>    all_histories[<span class="bu">str</span>(alpha)] <span class="op">=</span> history</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Runing the algorithm for alpha : 0.1

Iteraion 0 : 
|(w, b) = ([-0.00367445 -0.04214402 -0.03787291  0.00503207 -0.04740491], 0.900000) | cost_fn = 0.855335|
The algorithm converges at the 1687-th iteration
Then we have (w, b) = ([ 1.30308246e-03  2.22807855e-01  9.66238813e-01  2.45274791e+00
 -5.24625714e-04], -1.332871) &amp; cost_fn = 0.000037


Runing the algorithm for alpha : 0.01

Iteraion 0 : 
|(w, b) = ([-0.00036745 -0.0262144  -0.03431229 -0.04528429 -0.05781549], 11.880000) | cost_fn = 70.351204|
Iteraion 15000 : 
|(w, b) = ([ 2.13935724e-03  1.41295729e-01  8.87862367e-01  2.37691272e+00
 -1.16515913e-03], -1.261175) | cost_fn = 0.000502|
The algorithm converges at the 20966-th iteration
Then we have (w, b) = ([ 1.30383689e-03  2.22734320e-01  9.66168107e-01  2.45267950e+00
 -5.25203562e-04], -1.332807) &amp; cost_fn = 0.000037</code></pre>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Ici, on constate directement que notre algorithme a converg√© (crit√®re de <em>tol√©rance</em>) pour chacun des taux d‚Äôapprentissage (<code>learning rate</code>) test√©s.</p>
<p>Apr√®s cet entra√Ænement, il est int√©ressant de d√©terminer quel <code>learning rate</code> a permis d‚Äôobtenir le meilleur r√©sultat. Le code suivant est particuli√®rement utile lorsqu‚Äôon teste plusieurs valeurs de <code>learning rate</code> (plus de deux).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>best_alpha <span class="op">=</span> <span class="va">None</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>min_cost <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha, hist <span class="kw">in</span> all_histories.items():</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    costs <span class="op">=</span> [v[<span class="st">'cost_fn'</span>] <span class="cf">for</span> v <span class="kw">in</span> hist.values()]</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    min_cost_alpha <span class="op">=</span> <span class="bu">min</span>(costs)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Alpha </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss"> ‚û§ Min cost: </span><span class="sc">{</span>min_cost_alpha<span class="sc">:.5f}</span><span class="ss">"</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> min_cost_alpha <span class="op">&lt;</span> min_cost:</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        min_cost <span class="op">=</span> min_cost_alpha</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        best_alpha <span class="op">=</span> alpha</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Alpha 0.1 ‚û§ Min cost: 0.00004
Alpha 0.01 ‚û§ Min cost: 0.00004</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">‚úÖ Best alpha: </span><span class="sc">{</span>best_alpha<span class="sc">}</span><span class="ss"> with min cost: </span><span class="sc">{</span>min_cost<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
‚úÖ Best alpha: 0.1 with min cost: 0.00</code></pre>
</div>
</div>
<p>Avec ces deux <code>learning rates</code>, la fonction de co√ªt atteint 0, ce qui signifie que l‚Äôalgorithme a bien converg√© puisque la fonction de co√ªt est toujours positive.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_best_w_b(cost_fn_and_params_hist: <span class="bu">dict</span>):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    hist_len <span class="op">=</span> <span class="bu">len</span>(cost_fn_and_params_hist)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    best_of_hist <span class="op">=</span> cost_fn_and_params_hist[hist_len<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_of_hist</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(w, b, X):</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X <span class="op">@</span> w <span class="op">+</span> b</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> all_histories[<span class="st">'0.01'</span>]</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>best <span class="op">=</span> get_best_w_b(hist)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;On peut maintenant calculer nos pr√©dictions et v√©rifier leur qualit√© par rapport aux donn√©es r√©elles. Rappelons que les donn√©es ont √©t√© standardis√©es, il faudra donc ramener les pr√©dictions √† leur √©chelle d‚Äôorigine pour une interpr√©tation correcte.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># predictions standardis√©</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>ypred_scaled <span class="op">=</span> predict(best[<span class="st">'w'</span>], best[<span class="st">'b'</span>], X_processed).reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Donn√©es standardis√©es (3 premi√®res valeurs): </span><span class="sc">{</span>ypred_scaled[:<span class="dv">4</span>]<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Donn√©es standardis√©es (3 premi√®res valeurs): [[-1.11148687]
 [ 1.12097355]
 [ 1.11835771]
 [-1.1107826 ]]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># echelle normale</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> scaler_y.inverse_transform(ypred_scaled)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Donn√©es avec leur √©chelle normale (3 premi√®res valeurs): </span><span class="sc">{</span>y_pred[:<span class="dv">4</span>]<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Donn√©es avec leur √©chelle normale (3 premi√®res valeurs): [[30000.2280983 ]
 [75092.97779228]
 [75040.14127095]
 [30014.45331559]]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># affichange des parametres optimaux</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Param√®tres optimaux : </span><span class="sc">{</span>best<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Param√®tres optimaux : {'w': array([ 1.30383689e-03,  2.22734320e-01,  9.66168107e-01,  2.45267950e+00,
       -5.25203562e-04]), 'b': -1.332806620067705, 'cost_fn': 3.722342588474543e-05}</code></pre>
</div>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>best</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'w': array([ 1.30383689e-03,  2.22734320e-01,  9.66168107e-01,  2.45267950e+00,
       -5.25203562e-04]), 'b': -1.332806620067705, 'cost_fn': 3.722342588474543e-05}</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize <span class="op">=</span> (<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(axes)):</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    axes[i].scatter(train[X_features[i]], train[<span class="st">'salary'</span>], label<span class="op">=</span><span class="st">'target'</span>)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    axes[i].scatter(train[X_features[i]], y_pred, c<span class="op">=</span><span class="st">'orange'</span>, label<span class="op">=</span><span class="st">'predicted'</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylabel(<span class="st">'Salary'</span>, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(X_features[i].capitalize(), size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    axes[i].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="ss">f'Relation between salary and </span><span class="sc">{</span>X_features[i]<span class="sc">.</span>capitalize()<span class="sc">}</span><span class="ss">'</span>, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-plot-prediction" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="gradient-descent-linear-reg_files/figure-html/fig-plot-prediction-3.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Predcitions vs Real data</figcaption>
</figure>
</div>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;On peut voir que l‚Äôajustement est tr√®s satisfaisant, mais il reste √† d√©terminer s‚Äôil ne s‚Äôagit pas d‚Äôun <code>surapprentissage</code>. Pour cela nous allons utiliser les donn√©es de test, pour √©valuer le mod√®le entrain√©.</p>
</section>
<section id="evaluation-du-mod√®le" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-du-mod√®le">Evaluation du mod√®le</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pour √©valuer le mod√®le nous utilisons la <strong>validation crois√©e</strong> car elle est robuste en terme d‚Äô√©valuation de performance d‚Äôun mod√®le.</p>
<ul>
<li><p><strong>But principal</strong> : √âvaluer la performance d‚Äôun mod√®le de mani√®re fiable et robuste, en r√©duisant le biais d√ª √† une simple s√©paration train/test.</p></li>
<li><p><strong>√âtape 1 : Partition des donn√©es</strong><br>
Diviser l‚Äôensemble des donn√©es en <em>k</em> sous-ensembles (ou ¬´ folds ¬ª) de taille √† peu pr√®s √©gale.</p></li>
<li><p><strong>√âtape 2 : Boucle sur les folds</strong><br>
Pour chaque fold (de 1 √† k) :</p>
<ul>
<li>Utiliser ce fold comme ensemble de test (validation).<br>
</li>
<li>Utiliser les <em>k-1</em> autres folds comme ensemble d‚Äôentra√Ænement.</li>
</ul></li>
<li><p><strong>√âtape 3 : Entra√Ænement</strong><br>
Entra√Æner le mod√®le uniquement sur les donn√©es d‚Äôentra√Ænement (les <em>k-1</em> folds).</p></li>
<li><p><strong>√âtape 4 : √âvaluation</strong><br>
Tester le mod√®le entra√Æn√© sur le fold de test (le fold laiss√© de c√¥t√©), calculer une m√©trique de performance (ex : erreur quadratique moyenne).</p></li>
<li><p><strong>√âtape 5 : Agr√©gation</strong><br>
R√©p√©ter les √©tapes 2 √† 4 pour chaque fold, puis calculer la moyenne (et √©ventuellement l‚Äô√©cart-type) des performances obtenues sur chaque fold.</p></li>
<li><p><strong>Avantages</strong> :</p>
<ul>
<li>Meilleure estimation de la g√©n√©ralisation du mod√®le sur des donn√©es nouvelles.<br>
</li>
<li>R√©duit le sur-apprentissage li√© √† un seul d√©coupage train/test.<br>
</li>
<li>Utilise efficacement toutes les donn√©es pour entra√Ænement et validation.</li>
</ul></li>
<li><p><strong>Inconv√©nients</strong> :</p>
<ul>
<li>Co√ªt computationnel plus √©lev√©, car le mod√®le est entra√Æn√© <em>k</em> fois.<br>
</li>
<li>Peut √™tre sensible au choix de <em>k</em> (souvent 5 ou 10).</li>
</ul></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-kfold-illustration" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="k_fold.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Illustration du processus de la validation crois√©e</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> k_fold_cross_validation(df, k, alpha, max_iters, tolerance, cost_fn, gradient_fn):</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Perform k-fold cross-validation using gradient descent.</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co">        df (pd.DataFrame): full dataset (training set)</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co">        k (int): number of folds</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co">        alpha (float): learning rate</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co">        max_iters (int): maximum number of iterations for gradient descent</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co">        tolerance (float): convergence threshold</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co">        cost_fn (Callable): cost function</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co">        gradient_fn (Callable): gradient computation function</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="co">        list: list of cost values on each fold's test set</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Shuffle the DataFrame index</span></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df.sample(frac<span class="op">=</span><span class="dv">1</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>    fold_size <span class="op">=</span> <span class="bu">len</span>(df) <span class="op">//</span> k</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    sqrt_costs <span class="op">=</span> []</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define start and end indices for the test fold</span></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>        start <span class="op">=</span> fold <span class="op">*</span> fold_size</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> fold <span class="op">!=</span> k <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>            end <span class="op">=</span> (fold <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> fold_size</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:  <span class="co"># last fold takes the remaining data</span></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>            end <span class="op">=</span> <span class="bu">len</span>(df)</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Split the data into test and train folds</span></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>        test_df <span class="op">=</span> df.iloc[start:end]</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>        train_df <span class="op">=</span> pd.concat([df.iloc[:start], df.iloc[end:]], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prepare features and target for train and test</span></span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>        X_train <span class="op">=</span> train_df.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>        y_train <span class="op">=</span> train_df[<span class="st">'salary'</span>]</span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>        X_test <span class="op">=</span> test_df.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>        y_test <span class="op">=</span> test_df[<span class="st">'salary'</span>]</span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">10</span>)</span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Fold </span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Train unique education:"</span>, train_df[<span class="st">'education'</span>].unique())</span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Test unique education:"</span>, test_df[<span class="st">'education'</span>].unique())</span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Train unique sex:"</span>, train_df[<span class="st">'sex'</span>].unique())</span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Test unique sex:"</span>, test_df[<span class="st">'sex'</span>].unique())</span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>()</span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a>        numeric_features <span class="op">=</span> [<span class="st">'ages'</span>]</span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a>        categorical_features <span class="op">=</span> [<span class="st">'education'</span>, <span class="st">'sex'</span>]</span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a>        preprocessor <span class="op">=</span> ColumnTransformer(transformers<span class="op">=</span>[</span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a>            (<span class="st">'num'</span>, StandardScaler(), numeric_features),</span>
<span id="cb33-55"><a href="#cb33-55" aria-hidden="true" tabindex="-1"></a>            (<span class="st">'cat'</span>, OneHotEncoder(drop<span class="op">=</span><span class="st">'first'</span>), categorical_features)</span>
<span id="cb33-56"><a href="#cb33-56" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb33-57"><a href="#cb33-57" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-58"><a href="#cb33-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Preprocess the data using our pipeline</span></span>
<span id="cb33-59"><a href="#cb33-59" aria-hidden="true" tabindex="-1"></a>        X_train_processed <span class="op">=</span> preprocessor.fit_transform(X_train)</span>
<span id="cb33-60"><a href="#cb33-60" aria-hidden="true" tabindex="-1"></a>        y_train_scaled <span class="op">=</span> scaler_y.fit_transform(y_train.values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)).flatten()</span>
<span id="cb33-61"><a href="#cb33-61" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-62"><a href="#cb33-62" aria-hidden="true" tabindex="-1"></a>        X_test_processed <span class="op">=</span> preprocessor.transform(X_test)</span>
<span id="cb33-63"><a href="#cb33-63" aria-hidden="true" tabindex="-1"></a>        y_test_scaled <span class="op">=</span> scaler_y.transform(y_test.values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)).flatten()</span>
<span id="cb33-64"><a href="#cb33-64" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-65"><a href="#cb33-65" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize parameters</span></span>
<span id="cb33-66"><a href="#cb33-66" aria-hidden="true" tabindex="-1"></a>        n_features <span class="op">=</span> X_train_processed.shape[<span class="dv">1</span>]</span>
<span id="cb33-67"><a href="#cb33-67" aria-hidden="true" tabindex="-1"></a>        w <span class="op">=</span> np.zeros(n_features)</span>
<span id="cb33-68"><a href="#cb33-68" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-69"><a href="#cb33-69" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-70"><a href="#cb33-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Run gradient descent on training data</span></span>
<span id="cb33-71"><a href="#cb33-71" aria-hidden="true" tabindex="-1"></a>        history <span class="op">=</span> gradient_descent(</span>
<span id="cb33-72"><a href="#cb33-72" aria-hidden="true" tabindex="-1"></a>            X_train_processed,</span>
<span id="cb33-73"><a href="#cb33-73" aria-hidden="true" tabindex="-1"></a>            y_train_scaled,</span>
<span id="cb33-74"><a href="#cb33-74" aria-hidden="true" tabindex="-1"></a>            alpha<span class="op">=</span>alpha,</span>
<span id="cb33-75"><a href="#cb33-75" aria-hidden="true" tabindex="-1"></a>            w_in<span class="op">=</span>w,</span>
<span id="cb33-76"><a href="#cb33-76" aria-hidden="true" tabindex="-1"></a>            b_in<span class="op">=</span>b,</span>
<span id="cb33-77"><a href="#cb33-77" aria-hidden="true" tabindex="-1"></a>            max_iter<span class="op">=</span>max_iters,</span>
<span id="cb33-78"><a href="#cb33-78" aria-hidden="true" tabindex="-1"></a>            tolerance<span class="op">=</span>tolerance,</span>
<span id="cb33-79"><a href="#cb33-79" aria-hidden="true" tabindex="-1"></a>            cost_fn<span class="op">=</span>cost_fn,</span>
<span id="cb33-80"><a href="#cb33-80" aria-hidden="true" tabindex="-1"></a>            gradient_compute_fn<span class="op">=</span>gradient_fn</span>
<span id="cb33-81"><a href="#cb33-81" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb33-82"><a href="#cb33-82" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-83"><a href="#cb33-83" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Retrieve best parameters from last iteration</span></span>
<span id="cb33-84"><a href="#cb33-84" aria-hidden="true" tabindex="-1"></a>        last_iter <span class="op">=</span> <span class="bu">max</span>(history.keys())</span>
<span id="cb33-85"><a href="#cb33-85" aria-hidden="true" tabindex="-1"></a>        w_best <span class="op">=</span> history[last_iter][<span class="st">'w'</span>]</span>
<span id="cb33-86"><a href="#cb33-86" aria-hidden="true" tabindex="-1"></a>        b_best <span class="op">=</span> history[last_iter][<span class="st">'b'</span>]</span>
<span id="cb33-87"><a href="#cb33-87" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-88"><a href="#cb33-88" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute root mean square cost on the test fold</span></span>
<span id="cb33-89"><a href="#cb33-89" aria-hidden="true" tabindex="-1"></a>        cost_test <span class="op">=</span> np.sqrt(cost_fn(X_test_processed, y_test_scaled, w_best, b_best))</span>
<span id="cb33-90"><a href="#cb33-90" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Fold </span><span class="sc">{</span>fold <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> - Test fold square root cost: </span><span class="sc">{</span>np<span class="sc">.</span>sqrt(cost_test)<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb33-91"><a href="#cb33-91" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">10</span>)</span>
<span id="cb33-92"><a href="#cb33-92" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span><span class="op">*</span><span class="dv">3</span>)</span>
<span id="cb33-93"><a href="#cb33-93" aria-hidden="true" tabindex="-1"></a>        sqrt_costs.append(np.sqrt(cost_test))</span>
<span id="cb33-94"><a href="#cb33-94" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-95"><a href="#cb33-95" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Average root mean square of the cost func over </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> folds: </span><span class="sc">{</span>np<span class="sc">.</span>mean(sqrt_costs)<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb33-96"><a href="#cb33-96" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-97"><a href="#cb33-97" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sqrt_costs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>max_iters <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>tolerance <span class="op">=</span> <span class="fl">1e-4</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>costs <span class="op">=</span> k_fold_cross_validation(train, k, alpha, max_iters, tolerance, compute_cost_fn, compute_gradient)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>----------

Fold 1:
Train unique education: ['Bachelor degree' 'Msc' 'PhD' 'BAC']
Test unique education: ['PhD' 'Msc' 'Bachelor degree' 'BAC']
Train unique sex: ['F' 'M']
Test unique sex: ['F' 'M']

Fold 1/5 - Test fold square root cost: 0.15381
----------




----------

Fold 2:
Train unique education: ['PhD' 'Msc' 'Bachelor degree' 'BAC']
Test unique education: ['Bachelor degree' 'Msc' 'PhD' 'BAC']
Train unique sex: ['F' 'M']
Test unique sex: ['F' 'M']

Fold 2/5 - Test fold square root cost: 0.14906
----------




----------

Fold 3:
Train unique education: ['PhD' 'Msc' 'Bachelor degree' 'BAC']
Test unique education: ['Bachelor degree' 'PhD' 'Msc' 'BAC']
Train unique sex: ['F' 'M']
Test unique sex: ['F' 'M']

Fold 3/5 - Test fold square root cost: 0.13553
----------




----------

Fold 4:
Train unique education: ['PhD' 'Msc' 'Bachelor degree' 'BAC']
Test unique education: ['PhD' 'Bachelor degree' 'BAC' 'Msc']
Train unique sex: ['F' 'M']
Test unique sex: ['F' 'M']

Fold 4/5 - Test fold square root cost: 0.18426
----------




----------

Fold 5:
Train unique education: ['PhD' 'Msc' 'Bachelor degree' 'BAC']
Test unique education: ['Msc' 'PhD' 'BAC' 'Bachelor degree']
Train unique sex: ['F' 'M']
Test unique sex: ['F' 'M']

Fold 5/5 - Test fold square root cost: 0.14942
----------





Average root mean square of the cost func over 5 folds: 0.15442</code></pre>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;On peut remaquer qu‚Äô√† chaque fold nos modalit√©s sont pr√©sentes et dans les donn√©es de test et dans celles de l‚Äôapprentissage.</p>
<p>La validation crois√©e en 5 plis (K-Fold Cross-Validation) a √©t√© utilis√©e pour √©valuer la performance du mod√®le. Les valeurs ci-dessous correspondent √† la racine carr√©e de la fonction de co√ªt (Root Mean Square Error, RMSE), <strong>calcul√©e sur des donn√©es de sortie standardis√©es</strong>.</p>
<section id="r√©sultats-par-pli" class="level3">
<h3 class="anchored" data-anchor-id="r√©sultats-par-pli">R√©sultats par pli</h3>
<ul>
<li>‚úÖ Fold 1 : RMSE = 0.15381<br>
</li>
<li>‚úÖ Fold 2 : RMSE = 0.13553<br>
</li>
<li>‚úÖ Fold 3 : RMSE = 0.13553<br>
</li>
<li>‚úÖ Fold 4 : RMSE = 0.18426<br>
</li>
<li>‚úÖ Fold 5 : RMSE = 0.14942</li>
</ul>
<p><strong>Moyenne des RMSE sur les 5 plis</strong> : <code>0.15442</code></p>
</section>
<section id="interpr√©tation" class="level3">
<h3 class="anchored" data-anchor-id="interpr√©tation">Interpr√©tation</h3>
<ul>
<li><p>Le mod√®le a √©t√© test√© sur 5 sous-ensembles diff√©rents, ce qui donne une estimation plus robuste de sa performance.</p></li>
<li><p>La <strong>RMSE moyenne de 0.15442</strong> signifie que, <strong>en moyenne, les pr√©dictions s‚Äô√©cartent de la v√©rit√© d‚Äôenviron 0.15 unit√© sur l‚Äô√©chelle standardis√©e</strong>.</p></li>
<li><p>La <strong>faible variabilit√©</strong> des scores sugg√®re que le mod√®le reste globalement stable.</p></li>
</ul>
</section>
<section id="visualisation-des-erreurs-par-pli" class="level3">
<h3 class="anchored" data-anchor-id="visualisation-des-erreurs-par-pli">Visualisation des erreurs par pli</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSE values</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>rmse_values <span class="op">=</span> [<span class="fl">0.15381</span>, <span class="fl">0.14906</span>, <span class="fl">0.13553</span>, <span class="fl">0.18426</span>, <span class="fl">0.14942</span>]</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>folds <span class="op">=</span> [<span class="ss">f'Fold </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>)]</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>rmse_mean <span class="op">=</span> <span class="bu">sum</span>(rmse_values) <span class="op">/</span> <span class="bu">len</span>(rmse_values)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> plt.bar(folds, rmse_values, color<span class="op">=</span><span class="st">'#3182bd'</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span>rmse_mean, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, label<span class="op">=</span><span class="ss">f'Mean RMSE = </span><span class="sc">{</span>rmse_mean<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'RMSE by fold (crossed validation 5-fold)'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'RMSE (standardized)'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Fold number'</span>,fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>, <span class="bu">max</span>(rmse_values) <span class="op">*</span> <span class="fl">1.15</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(0.0, 0.211899)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajouter les valeurs au-dessus de chaque barre</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bar <span class="kw">in</span> bars:</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    yval <span class="op">=</span> bar.get_height()</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    plt.text(bar.get_x() <span class="op">+</span> bar.get_width() <span class="op">/</span> <span class="dv">2</span>, yval <span class="op">+</span> <span class="fl">0.005</span>, <span class="ss">f'</span><span class="sc">{</span>yval<span class="sc">:.3f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-rmse-value-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="gradient-descent-linear-reg_files/figure-html/fig-rmse-value-plot-1.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;5: RMSE par pli (validation crois√©e 5-fold)</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="evaluation-du-mod√®le-final-sur-les-donn√©es-de-test" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-du-mod√®le-final-sur-les-donn√©es-de-test">Evaluation du mod√®le final sur les donn√©es de test</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting test features</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> test.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co"># transforming test features (one hot encodings and standardization)</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>X_test_processed <span class="op">=</span> preprocessor.transform(X<span class="op">=</span>X_test)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># predictions on standardized test features</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>y_pred_test_scaled <span class="op">=</span> predict(best[<span class="st">'w'</span>], best[<span class="st">'b'</span>], X_test_processed).reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co"># reverse scaling</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>y_pred_test <span class="op">=</span> scaler_y.inverse_transform(y_pred_test_scaled).reshape(<span class="dv">200</span>,)</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="co"># getting real y and changing the shape</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>y_true_test <span class="op">=</span> test[<span class="st">'salary'</span>].values.reshape(<span class="dv">200</span>,)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Maintenant calculons le <code>RMSE</code> des erreurs commises en pr√©disant. D‚Äôabord essayons de visualiser cela. D‚Äôabord de mani√®re s√©par√©e car il me vient √† l‚Äôid√©e d‚Äôordonner les diff√©rents arrays obtenus, mais avant faut que je sois s√ªre que les salaires r√©els (pas dans le sens √©conomique du terme mais pour dire salaire observ√©) et ceux pr√©dits ont la m√™me allure.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>abs_ <span class="op">=</span> np.arange(<span class="dv">1</span>, <span class="dv">201</span>, <span class="dv">1</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(abs_, y_true_test, c<span class="op">=</span><span class="st">'g'</span>, label<span class="op">=</span><span class="st">'Observed salaries'</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Observed Salaries'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Data points'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Salary'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(abs_, y_pred_test, c<span class="op">=</span><span class="st">'b'</span>, label<span class="op">=</span><span class="st">'Predicted salaries'</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Predicted Salaries'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Data points'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Salary'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-testing-final-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="gradient-descent-linear-reg_files/figure-html/fig-testing-final-plot-3.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;6: Observed Slaries and Predicted Salaries visualisation</figcaption>
</figure>
</div>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;En effet les deux courbe ont pratiquement la m√™me allure, essayons de voir ce que √ßa donne quand on les arrange de mani√®re croissante.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>y_pred_test_sorted <span class="op">=</span> np.sort(y_pred_test)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>y_true_test_sorted <span class="op">=</span> np.sort(y_true_test)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>abs_ <span class="op">=</span> np.arange(<span class="dv">1</span>, <span class="dv">201</span>, <span class="dv">1</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>plt.plot(abs_,y_true_test_sorted , c<span class="op">=</span><span class="st">'g'</span>, label<span class="op">=</span><span class="st">'Observed values of the salary'</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>plt.plot(abs_, y_pred_test_sorted, c<span class="op">=</span><span class="st">'b'</span>,label<span class="op">=</span><span class="st">'Predicted values of the salary'</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Salary'</span>)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Data points'</span>)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-testing-final-sorted-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="gradient-descent-linear-reg_files/figure-html/fig-testing-final-sorted-plot-5.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;7: Observed Slaries VS Predicted Salaries</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Analyse graphique des salaires pr√©dits vs observ√©s
</div>
</div>
<div class="callout-body-container callout-body">
<p>Les courbes des salaires pr√©dits et observ√©s montrent une forte similarit√©.<br>
Cela sugg√®re que le mod√®le est capable de bien capturer la relation entre les variables explicatives et le salaire, indiquant ainsi une <strong>bonne capacit√© de g√©n√©ralisation</strong> sur les donn√©es de test.</p>
</div>
</div>
<ul>
<li><strong>Calcul de la racine de l‚Äôerreur quadratique moyenne</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSE sur les salaires standardis√©s</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSE sur les salaires r√©els</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>rmse_original <span class="op">=</span> np.sqrt(np.mean((y_pred_test <span class="op">-</span> y_true_test)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"original RMSE : </span><span class="sc">{</span>rmse_original<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>original RMSE : 283.96</code></pre>
</div>
</div>
<ul>
<li><strong>Interpr√©tation de la RMSE en valeur r√©elle</strong></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Les salaires dans notre dataset varient entre environ <strong>24 933 ‚Ç¨</strong> et <strong>75 318 ‚Ç¨</strong>, ce qui explique qu‚Äôune <code>RMSE</code> d‚Äôenviron 284 ‚Ç¨ soit coh√©rente.</p>
<p>Pour mieux comprendre ce que signifie cette erreur moyenne, consid√©rons l‚Äô√©chelle des salaires :<br>
la diff√©rence entre le minimum et le maximum est d‚Äôenviron 60 000 ‚Ç¨.</p>
<p>Ainsi, une <code>RMSE</code> de <code>284 ‚Ç¨</code> correspond √† une erreur moyenne relative d‚Äôenviron :</p>
<p><span class="math display">\[
\frac{284}{50 385} \approx 0.0056 \quad \text{soit} \quad 0{,}56\%
\]</span></p>
<hr>
</section>
<section id="conclusion-g√©n√©rale" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-g√©n√©rale">Conclusion g√©n√©rale</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;En r√©sum√©, la <strong>descente de gradient</strong> s‚Äôest r√©v√©l√©e √™tre un algorithme simple, intuitif et pourtant puissant pour la <strong>minimisation de la fonction de co√ªt</strong> dans le cadre de la r√©gression lin√©aire. En parcourant de mani√®re it√©rative la direction oppos√©e au gradient, l‚Äôalgorithme permet une r√©duction monotone du co√ªt √† chaque it√©ration.</p>
<p>Nous avons vu que ce proc√©d√© consiste √† ajuster les coefficients du mod√®le √† partir d‚Äôun point initial, en effectuant des pas proportionnels au n√©gatif du gradient et calibr√©s par le <strong>taux d‚Äôapprentissage</strong>. Tant que celui-ci est bien choisi (pas trop grand, pas trop petit), la proc√©dure converge vers un minimum local de la fonction de co√ªt. Toutefois, nous avons aussi montr√© que certains cas (comme des ravins √©troits ou des matrices Hessiennes mal conditionn√©es) peuvent ralentir la convergence ou provoquer des oscillations.</p>
<section id="points-cl√©s-√†-retenir" class="level3">
<h3 class="anchored" data-anchor-id="points-cl√©s-√†-retenir">Points cl√©s √† retenir</h3>
<ol type="1">
<li><p><strong>Principe de fonctionnement</strong><br>
Le param√®tre () est mis √† jour selon <span class="math inline">\(\theta \leftarrow \theta - \alpha \nabla_\theta J(\theta)\)</span>, avec <span class="math inline">\(J\)</span> la fonction de co√ªt et <span class="math inline">\(\alpha\)</span> le pas d‚Äôapprentissage.</p></li>
<li><p><strong>Monotonie et convergence</strong><br>
√Ä chaque √©tape, la valeur du co√ªt d√©cro√Æt (tant que <span class="math inline">\(\alpha\)</span> est convenablement choisie), garantissant la progression vers un minimum local.</p></li>
<li><p><strong>Limites de la m√©thode</strong><br>
La descente de gradient peut rencontrer des difficult√©s de convergence lorsqu‚Äôon affine le minimum dans des zones √©troites ou avec des gradients tr√®s pontuels. D‚Äôautres m√©thodes, comme le gradient conjugu√© ou Newton, peuvent alors offrir un gain en performance.</p></li>
</ol>
</section>
<section id="perspectives" class="level3">
<h3 class="anchored" data-anchor-id="perspectives">Perspectives</h3>
<ul>
<li><p><strong>Am√©lioration du pas ($$)</strong> : l‚Äôusage d‚Äôun pas adaptatif ou de sch√©mas comme l‚Äôapprentissage d√©croissant peut am√©liorer la rapidit√© et la robustesse de la convergence.</p></li>
<li><p><strong>Extensions avanc√©es</strong> : l‚Äôajout de r√©gularisation (comme Ridge ou Lasso) ou le passage √† des variantes stochastiques (SGD) ou mini-batch permet de g√©n√©raliser la m√©thode √† des ensembles plus volumineux et √† la mod√©lisation en profondeur.</p></li>
<li><p><strong>Combinaison avec d‚Äôautres algorithmes</strong> : pour pallier les inefficacit√©s, on peut int√©grer des techniques comme le momentum, AdaGrad, RMSprop ou Adam, qui corr√©lent le gradient pour acc√©l√©rer la convergence et stabiliser l‚Äôapprentissage.</p></li>
</ul>
</section>
<section id="finalement" class="level3">
<h3 class="anchored" data-anchor-id="finalement">Finalement</h3>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;La descente de gradient traduit √©l√©gamment les principes fondamentaux de l‚Äô<strong>optimisation it√©rative</strong> : √† chaque √©tape, un petit ajustement calcul√© √©loigne le mod√®le de l‚Äôerreur, jusqu‚Äô√† atteindre la valeur optimale des param√®tres (). M√™me si elle n‚Äôest pas sans d√©fauts, cette m√©thode demeure une <strong>brique essentielle</strong> en apprentissage automatique, particuli√®rement en r√©gression lin√©aire, et sert de base √† des m√©thodes plus sophistiqu√©es.</p>
<hr>
</section>
</section>
<section id="remerciements-et-retour-dexp√©rience" class="level2">
<h2 class="anchored" data-anchor-id="remerciements-et-retour-dexp√©rience">Remerciements et retour d‚Äôexp√©rience</h2>
<p>J‚Äôai √©t√© ravi d‚Äôavoir consacr√© pr√®s de <strong>20 heures</strong> √† la pr√©paration et √† la r√©daction de cette publication.</p>
<p>Cet effort m‚Äôa permis de :</p>
<ul>
<li>consolider mes acquis en <strong>Python</strong>,<br>
</li>
<li>approfondir mes connaissances en <strong>Machine Learning</strong>, tant sur le plan <strong>th√©orique que pratique</strong>,<br>
</li>
<li>renforcer ma <strong>rigueur m√©thodologique</strong> dans le traitement des donn√©es, l‚Äôexp√©rimentation et l‚Äôanalyse des r√©sultats.</li>
</ul>
<p>Ce projet m‚Äôa √©galement offert une excellente opportunit√© de structurer une d√©marche compl√®te de mod√©lisation, depuis la g√©n√©ration des donn√©es jusqu‚Äô√† l‚Äôinterpr√©tation finale des performances du mod√®le.</p>
<p>Je suis enthousiaste √† l‚Äôid√©e de poursuivre cette exploration dans de futures publications de ce genre (travailler √† la mano), notamment sur des cas r√©els avec des mod√®les plus avanc√©s comme la <strong>r√©gression logistique</strong> ou des approches <strong>r√©gularis√©es</strong>.</p>
<p>Mon cours d‚Äôoptimisation et de m√©thode de calcul num√©riques m‚Äôa √©t√© d‚Äôune grande utilit√© en 1A √† l‚ÄôENSAI.</p>
<hr>
</section>
<section id="annexes" class="level2">
<h2 class="anchored" data-anchor-id="annexes">Annexes</h2>
<section id="standardisation-des-variables" class="level3">
<h3 class="anchored" data-anchor-id="standardisation-des-variables">1. Standardisation des variables</h3>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;La <strong>standardisation</strong> permet de centrer et r√©duire les variables num√©riques pour qu‚Äôelles aient une moyenne nulle et un √©cart-type unitaire.</p>
<p>Pour une variable continue <span class="math inline">\(x\)</span>, la standardisation est donn√©e par :</p>
<p><span class="math display">\[
x_{\text{std}} = \frac{x - \mu_x}{\sigma_x}
\]</span></p>
<p>o√π :</p>
<ul>
<li><span class="math inline">\(\mu_x = \dfrac{1}{n} \sum_{i=1}^n x_i\)</span> est la moyenne,</li>
<li><span class="math inline">\(\sigma_x = \sqrt{\dfrac{1}{n} \sum_{i=1}^n (x_i - \mu_x)^2}\)</span> est l‚Äô√©cart-type.</li>
</ul>
<p>Apr√®s avoir entra√Æn√© le mod√®le sur les donn√©es standardis√©es, on peut revenir √† l‚Äô√©chelle r√©elle avec :</p>
<p><span class="math display">\[
\hat{y} = \hat{y}_{\text{std}} \cdot \sigma_y + \mu_y
\]</span></p>
<p>o√π <span class="math inline">\(\mu_y\)</span> et <span class="math inline">\(\sigma_y\)</span> sont la moyenne et l‚Äô√©cart-type de la variable cible <span class="math inline">\(y\)</span>.</p>
<hr>
</section>
<section id="codage-one-hot" class="level3">
<h3 class="anchored" data-anchor-id="codage-one-hot">2. Codage One-Hot</h3>
<p>Le <strong>One-Hot Encoding</strong> transforme une variable cat√©gorielle √† <span class="math inline">\(k\)</span> modalit√©s en <span class="math inline">\(k\)</span> colonnes binaires.</p>
<p>Soit une variable cat√©gorielle :</p>
<p><span class="math display">\[
\text{cat} \in \{c_1, c_2, \ldots, c_k\}
\]</span></p>
<p>On cr√©e un vecteur :</p>
<p><span class="math display">\[
\mathbf{v} = (v_1, v_2, \ldots, v_k) \quad \text{o√π} \quad
v_j =
\begin{cases}
1 &amp; \text{si } \text{cat} = c_j \\
0 &amp; \text{sinon}
\end{cases}
\]</span></p>
<p>Afin d‚Äô√©viter la redondance, on supprime une modalit√© (ex. via <code>drop='first'</code>) pour √©viter le pi√®ge des variables muettes (dummy variable trap).</p>
<hr>
</section>
<section id="calcul-de-la-rmse" class="level3">
<h3 class="anchored" data-anchor-id="calcul-de-la-rmse">3. Calcul de la RMSE</h3>
<p>La <strong>Root Mean Square Error</strong> (RMSE) mesure l‚Äô√©cart quadratique moyen entre les valeurs pr√©dites <span class="math inline">\(\hat{y}_i\)</span> et observ√©es <span class="math inline">\(y_i\)</span> :</p>
<p><span class="math display">\[
\text{RMSE} = \sqrt{ \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2 }
\]</span></p>
<p>En notation vectorielle, si <span class="math inline">\(\mathbf{y}\)</span> est le vecteur des valeurs observ√©es et <span class="math inline">\(\hat{\mathbf{y}}\)</span> celui des valeurs pr√©dites :</p>
<p><span class="math display">\[
\text{RMSE} = \sqrt{ \frac{1}{n} (\mathbf{y} - \hat{\mathbf{y}})^T (\mathbf{y} - \hat{\mathbf{y}}) }
\]</span></p>
<p>Cette m√©trique est exprim√©e dans l‚Äôunit√© de la variable cible (ici, les euros), ce qui la rend facile √† interpr√©ter dans un contexte r√©el.</p>
<hr>
<p>Ces op√©rations sont fondamentales dans toute pipeline de traitement pour la r√©gression ou tout autre algorithme supervis√©.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>