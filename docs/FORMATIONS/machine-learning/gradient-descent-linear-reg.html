<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Djamal TOE">
<meta name="dcterms.date" content="2025-06-08">

<title>DJAMAL WEBSITE - Mise en ≈ìuvre de l‚Äôalgorithme de la descente de gradient : Cas de la r√©gression lin√©aire</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="index.qmd" class="navbar-brand navbar-brand-logo">
    <img src="../../images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="index.qmd">
    <span class="navbar-title">DJAMAL WEBSITE</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-statistics--machine-learning" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Statistics &amp; Machine Learning</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-statistics--machine-learning">    
        <li>
    <a class="dropdown-item" href="../../INFO_MINI_PROJETS/classi_bin_acp_kmeans_knn_logit/Breast-Tumor-Article.html" rel="" target="">
 <span class="dropdown-text">Diagnostic assist√© par ACP et r√©gression logistique</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../INFO_MINI_PROJETS/brain-tumor-classification-effcientnet.html" rel="" target="">
 <span class="dropdown-text">Diagnostic tumeurs c√©r√©brales - Reseau de neurones</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../ANALYSES_FACTORIELLES/acp-kmeans.html" rel="" target="">
 <span class="dropdown-text">Reduction de dimensionnalit√© et clustering non supervis√©</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../FORMATIONS/logistic_regression_diabetes.html" rel="" target="">
 <span class="dropdown-text">Mod√©lisation des donn√©es √† variables d√©pendantes binaires</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../projet-traitement-donnees/report_writing/synthese-des-travaux.html" rel="" target="">
 <span class="dropdown-text">Pr√©dire la dur√©e de carri√®re des joueurs NBA</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../FORMATIONS/poisson_paludisme.html" rel="" target="">
 <span class="dropdown-text">Mod√©lisation des donn√©es de comptage</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../INFO_MINI_PROJETS/shifumi-cnn-yolov8.html" rel="" target="">
 <span class="dropdown-text">Classification des gestes de la main avec Yolo et CNN</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-programming" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Programming</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-programming">    
        <li>
    <a class="dropdown-item" href="../../INFO_MINI_PROJETS/assistant_virtuel.html" rel="" target="">
 <span class="dropdown-text">Cr√©e ton assistant virtuel avec pyhton</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../INFO_MINI_PROJETS/JavaApp/desktop-app-java-mysql.html" rel="" target="">
 <span class="dropdown-text">Application desktop avec Java et Mysql</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-various" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Various</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-various">    
        <li>
    <a class="dropdown-item" href="../../FORMATIONS/machine-learning/gradient-descent-linear-reg.html" rel="" target="">
 <span class="dropdown-text">R√©gression lin√©aire par descente de gradient - th√©orie et application</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About me</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://www.linkedin.com/in/djamal-toe-7a18432b0" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text">LinkedIn</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#r√©sum√©" id="toc-r√©sum√©" class="nav-link active" data-scroll-target="#r√©sum√©">R√©sum√©</a></li>
  <li><a href="#abstract" id="toc-abstract" class="nav-link" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#un-peu-de-formalisme" id="toc-un-peu-de-formalisme" class="nav-link" data-scroll-target="#un-peu-de-formalisme">Un peu de formalisme</a></li>
  <li><a href="#algorithme-de-la-descente-de-gradient-cas-de-la-regression-lin√©aire" id="toc-algorithme-de-la-descente-de-gradient-cas-de-la-regression-lin√©aire" class="nav-link" data-scroll-target="#algorithme-de-la-descente-de-gradient-cas-de-la-regression-lin√©aire">Algorithme de la descente de gradient : cas de la regression lin√©aire</a></li>
  <li><a href="#v√©rification-de-la-convergence" id="toc-v√©rification-de-la-convergence" class="nav-link" data-scroll-target="#v√©rification-de-la-convergence">üîé V√©rification de la convergence</a></li>
  <li><a href="#mise-√†-jour-des-param√®tres" id="toc-mise-√†-jour-des-param√®tres" class="nav-link" data-scroll-target="#mise-√†-jour-des-param√®tres">‚öôÔ∏è Mise √† jour des param√®tres</a></li>
  <li><a href="#remarques-pratiques" id="toc-remarques-pratiques" class="nav-link" data-scroll-target="#remarques-pratiques">üß™ Remarques pratiques</a></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications">Applications</a></li>
  <li><a href="#analyse-exploratoire-relation-entre-salaire-et-variables-explicatives" id="toc-analyse-exploratoire-relation-entre-salaire-et-variables-explicatives" class="nav-link" data-scroll-target="#analyse-exploratoire-relation-entre-salaire-et-variables-explicatives">üìä Analyse exploratoire : Relation entre salaire et variables explicatives</a>
  <ul class="collapse">
  <li><a href="#relation-entre-le-salaire-et-l√¢ge" id="toc-relation-entre-le-salaire-et-l√¢ge" class="nav-link" data-scroll-target="#relation-entre-le-salaire-et-l√¢ge">üë¥ Relation entre le salaire et l‚Äô√¢ge</a></li>
  <li><a href="#relation-entre-le-salaire-et-le-sexe" id="toc-relation-entre-le-salaire-et-le-sexe" class="nav-link" data-scroll-target="#relation-entre-le-salaire-et-le-sexe">üöª Relation entre le salaire et le sexe</a></li>
  <li><a href="#relation-entre-le-salaire-et-le-niveau-d√©ducation" id="toc-relation-entre-le-salaire-et-le-niveau-d√©ducation" class="nav-link" data-scroll-target="#relation-entre-le-salaire-et-le-niveau-d√©ducation">üéì Relation entre le salaire et le niveau d‚Äô√©ducation</a></li>
  <li><a href="#conclusion-de-lanalyse-exploratoire-rapide" id="toc-conclusion-de-lanalyse-exploratoire-rapide" class="nav-link" data-scroll-target="#conclusion-de-lanalyse-exploratoire-rapide">‚úÖ Conclusion de l‚Äôanalyse exploratoire rapide</a></li>
  </ul></li>
  <li><a href="#data-preprocessing" id="toc-data-preprocessing" class="nav-link" data-scroll-target="#data-preprocessing">Data preprocessing</a></li>
  <li><a href="#application-de-lalgorithme-de-la-descente-de-gradient" id="toc-application-de-lalgorithme-de-la-descente-de-gradient" class="nav-link" data-scroll-target="#application-de-lalgorithme-de-la-descente-de-gradient">Application de l‚Äôalgorithme de la descente de gradient</a></li>
  <li><a href="#evaluation-du-mod√®le" id="toc-evaluation-du-mod√®le" class="nav-link" data-scroll-target="#evaluation-du-mod√®le">Evaluation du mod√®le</a>
  <ul class="collapse">
  <li><a href="#r√©sultats-par-pli-rmse-train-vs-test" id="toc-r√©sultats-par-pli-rmse-train-vs-test" class="nav-link" data-scroll-target="#r√©sultats-par-pli-rmse-train-vs-test">R√©sultats par pli (RMSE Train vs Test)</a></li>
  <li><a href="#visualisation-de-la-somme-erreurs-quadratiques-par-pli" id="toc-visualisation-de-la-somme-erreurs-quadratiques-par-pli" class="nav-link" data-scroll-target="#visualisation-de-la-somme-erreurs-quadratiques-par-pli">Visualisation de la somme erreurs quadratiques par pli</a></li>
  <li><a href="#mse-par-pli" id="toc-mse-par-pli" class="nav-link" data-scroll-target="#mse-par-pli">üìâ MSE par pli</a></li>
  <li><a href="#r¬≤-par-pli" id="toc-r¬≤-par-pli" class="nav-link" data-scroll-target="#r¬≤-par-pli">üìà R¬≤ par pli</a></li>
  </ul></li>
  <li><a href="#evaluation-du-mod√®le-final-sur-les-donn√©es-de-test" id="toc-evaluation-du-mod√®le-final-sur-les-donn√©es-de-test" class="nav-link" data-scroll-target="#evaluation-du-mod√®le-final-sur-les-donn√©es-de-test">Evaluation du mod√®le final sur les donn√©es de test</a></li>
  <li><a href="#conclusion-g√©n√©rale" id="toc-conclusion-g√©n√©rale" class="nav-link" data-scroll-target="#conclusion-g√©n√©rale">Conclusion g√©n√©rale</a>
  <ul class="collapse">
  <li><a href="#points-cl√©s-√†-retenir" id="toc-points-cl√©s-√†-retenir" class="nav-link" data-scroll-target="#points-cl√©s-√†-retenir">Points cl√©s √† retenir</a></li>
  <li><a href="#perspectives" id="toc-perspectives" class="nav-link" data-scroll-target="#perspectives">Perspectives</a></li>
  <li><a href="#finalement" id="toc-finalement" class="nav-link" data-scroll-target="#finalement">Finalement</a></li>
  </ul></li>
  <li><a href="#remerciements-et-retour-dexp√©rience" id="toc-remerciements-et-retour-dexp√©rience" class="nav-link" data-scroll-target="#remerciements-et-retour-dexp√©rience">Remerciements et retour d‚Äôexp√©rience</a></li>
  <li><a href="#annexes" id="toc-annexes" class="nav-link" data-scroll-target="#annexes">Annexes</a>
  <ul class="collapse">
  <li><a href="#standardisation-des-variables" id="toc-standardisation-des-variables" class="nav-link" data-scroll-target="#standardisation-des-variables">1. Standardisation des variables</a></li>
  <li><a href="#codage-one-hot" id="toc-codage-one-hot" class="nav-link" data-scroll-target="#codage-one-hot">2. Codage One-Hot</a></li>
  <li><a href="#calcul-de-la-rmse" id="toc-calcul-de-la-rmse" class="nav-link" data-scroll-target="#calcul-de-la-rmse">3. Calcul de la RMSE</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Mise en ≈ìuvre de l‚Äôalgorithme de la descente de gradient : Cas de la r√©gression lin√©aire</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Djamal TOE </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 8, 2025</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, OneHotEncoder</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'deeplearning.mplstyle'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="r√©sum√©" class="level2">
<h2 class="anchored" data-anchor-id="r√©sum√©">R√©sum√©</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;√Ä la suite de mes cours d‚Äôoptimisation et de calcul num√©rique, j‚Äôai souhait√© impl√©menter moi-m√™me l‚Äôalgorithme de la descente de gradient. J‚Äôai choisi comme premier cas d‚Äôapplication la <strong><code>r√©gression lin√©aire</code></strong>, dans le but d‚Äôestimer les param√®tres optimaux (<code>w</code>, <code>b</code>) qui minimisent la fonction de co√ªt (g√©n√©ralement l‚Äôerreur quadratique moyenne).</p>
<p>M√™me si, dans le cas de la r√©gression lin√©aire, il existe une solution analytique explicite par la m√©thode des moindres carr√©s, cette situation est id√©ale pour comprendre et tester l‚Äôefficacit√© de la descente de gradient. En revanche, pour des mod√®les plus complexes comme la r√©gression logistique, une solution analytique n‚Äôest plus disponible. Dans ces cas, on utilise syst√©matiquement des <strong><code>m√©thodes num√©riques</code></strong> comme la descente de gradient. En pratique, il faut s‚Äôassurer que les donn√©es soient r√©parties de mani√®re √©quilibr√©e selon des crit√®res comme le sexe ou l‚Äô√©ducation entre les jeux d‚Äôapprentissage, de validation (avec la validation crois√©e) et de test, pour √©viter que l‚Äô√©valuation du mod√®le soit fauss√©e.</p>
<hr>
</section>
<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Following my courses in optimisation and numerical computation, I wanted to implement the gradient descent algorithm myself. My first application was to linear regression, with the aim of estimating the optimal parameters (<code>w</code>, <code>b</code>) that minimise the cost function (generally the mean square error).</p>
<p>Even though, in the case of linear regression, there is an explicit analytical solution using the method of least squares, this situation is ideal for understanding and testing the effectiveness of gradient descent. However, for more complex models such as logistic regression, an analytical solution is no longer available. In these cases, numerical methods such as gradient descent are systematically used. In practice, care must be taken to ensure that the data is distributed evenly according to criteria such as gender or education between the training, validation (with cross-validation) and test sets, to avoid distorting the evaluation of the model.</p>
<hr>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L‚Äôobjectif de ce document est de pr√©senter l‚Äôimpl√©mentation de l‚Äôalgorithme de descente de gradient dans le cas de la r√©gression lin√©aire multiple, afin de mieux comprendre le principe d‚Äôoptimisation it√©rative. On commence par un rappel de la r√©gression lin√©aire classique, avant de d√©river la fonction de co√ªt et ses gradients par rapport aux param√®tres. Ensuite, l‚Äôalgorithme est appliqu√© √† un jeu de donn√©es simul√© pour illustrer sa convergence et les effets du taux d‚Äôapprentissage.</p>
<p>Dans une deuxi√®me partie, nous discuterons des limites de l‚Äôapproche analytique, notamment dans des contextes o√π la descente de gradient devient incontournable (r√©gression logistique, r√©seaux de neurones, etc.).</p>
<hr>
</section>
<section id="un-peu-de-formalisme" class="level2">
<h2 class="anchored" data-anchor-id="un-peu-de-formalisme">Un peu de formalisme</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Nous souhaitons minimiser une fonction objective, appel√©e √©galement <strong><code>fonction de co√ªt</code></strong>. Avant de chercher une m√©thode num√©rique pour effectuer cette minimisation, il est essentiel de s‚Äôassurer que la fonction admet bien un minimum, et que celui-ci est <strong><code>unique</code></strong>.</p>
<p>En effet, une fonction peut pr√©senter <strong><code>plusieurs minima locaux</code></strong>, et l‚Äôobjectif est g√©n√©ralement d‚Äôatteindre le <strong><code>minimum global</code></strong>. Pour garantir l‚Äôexistence d‚Äôun minimum global, on fait appel au <strong><code>th√©or√®me de Weierstrass</code></strong>, qui stipule qu‚Äôune fonction continue sur un ensemble compact atteint un minimum (et un maximum).</p>
<p>Mais pour garantir l‚Äôunicit√© du minimum, on utilise la notion de <strong><code>convexit√©</code></strong>. Une fonction strictement convexe sur un domaine convexe poss√®de un unique minimum qui est donc le minimum global.</p>
<blockquote class="blockquote">
<p>üí° Si votre fonction de co√ªt est <strong><code>concave</code></strong> (au lieu d‚Äô√™tre convexe), il suffit d‚Äôen prendre l‚Äôoppos√©. La maximisation d‚Äôune fonction concave revient √† minimiser son oppos√©e, qui sera convexe.</p>
</blockquote>
<p>Ainsi, <strong>la stricte convexit√©</strong> de la fonction objective est une propri√©t√© cruciale : elle permet de garantir l‚Äôunicit√© du minimum et donc la convergence de l‚Äôalgorithme vers une solution bien d√©finie.</p>
<p>Je n‚Äôentrerai pas dans trop de details math√©matiques. Si vous voulez en savoir plus (condition d‚Äôapplication du th√©or√®me de weierstrass -&gt; s√©mi-continuit√© + espace de contraintes born√© ou semi-continuit√© + coercivit√© + espace de contraintes ferm√©) consultez cette page : &lt;<a href="https://en.wikipedia.org/wiki/Extreme_value_theorem" class="uri">https://en.wikipedia.org/wiki/Extreme_value_theorem</a>&gt; et faites des recherches suppl√©mentaires.</p>
<hr>
</section>
<section id="algorithme-de-la-descente-de-gradient-cas-de-la-regression-lin√©aire" class="level2">
<h2 class="anchored" data-anchor-id="algorithme-de-la-descente-de-gradient-cas-de-la-regression-lin√©aire">Algorithme de la descente de gradient : cas de la regression lin√©aire</h2>
<ul>
<li><strong>Fonction de co√ªt de la regression lin√©aire</strong></li>
</ul>
<p>La fonction de co√ªt utilis√©e pour la r√©gression lin√©aire est la (ou <code>Mean Squared Error</code>, MSE). Elle s‚Äô√©crit comme suit :</p>
<p><span class="math display">\[
\begin{equation}
    J(w, b) = \frac{1}{2m} \sum_{i=1}^{m} \left( \hat{y}^{(i)} - y^{(i)} \right)^2
\end{equation}
\]</span></p>
<p>o√π :</p>
<p>En <strong><em>notation vectorielle</em></strong>, on peut r√©√©crire la fonction de co√ªt sous la forme :</p>
<p><span class="math display">\[
\begin{equation}
    J(w, b) = \frac{1}{2m} (\hat{Y} - Y)^T (\hat{Y} - Y)
\end{equation}
\]</span></p>
<p>o√π :</p>
<p><span class="math display">\[
\begin{equation}
    J(w, b) = \frac{1}{2m} \left\| \hat{Y} - Y \right\|^2
\end{equation}
\]</span></p>
<ul>
<li>üîª <strong>Descente de Gradient</strong></li>
</ul>
<p>L‚Äôobjectif de la descente de gradient est de d√©terminer les param√®tres optimaux <span class="math inline">\(w\)</span> et <span class="math inline">\(b\)</span> qui minimisent la fonction de co√ªt. Pour cela, on utilise un algorithme <strong>it√©ratif</strong> qui met progressivement √† jour ces param√®tres <strong>dans le sens oppos√© au gradient</strong>.</p>
<p>√Ä chaque it√©ration, les nouvelles valeurs de <span class="math inline">\(w\)</span> et <span class="math inline">\(b\)</span> doivent id√©alement conduire √† une <strong>diminution de la fonction de co√ªt</strong>. Si la fonction <strong>augmente</strong>, cela peut √™tre d√ª √† :</p>
<ul>
<li>un <strong>taux d‚Äôapprentissage</strong> (<span class="math inline">\(\alpha\)</span>) trop <strong>√©lev√©</strong>, provoquant une <strong>divergence</strong> ;</li>
<li>une <strong>erreur de code</strong>, par exemple un mauvais calcul du gradient.</li>
</ul>
<p>En revanche, si la fonction de co√ªt diminue <strong>trop lentement</strong>, cela peut signifier :</p>
<ul>
<li>un taux d‚Äôapprentissage trop <strong>faible</strong>, causant une <strong>convergence lente</strong> ou incompl√®te.</li>
</ul>
<blockquote class="blockquote">
<p>‚ö†Ô∏è Dans certains cas, la fonction de co√ªt peut <strong>onduler</strong> √† chaque it√©ration (oscillations), souvent √† cause d‚Äôune mauvaise normalisation ou d‚Äôun <span class="math inline">\(\alpha\)</span> mal ajust√©.</p>
</blockquote>
<hr>
</section>
<section id="v√©rification-de-la-convergence" class="level2">
<h2 class="anchored" data-anchor-id="v√©rification-de-la-convergence">üîé V√©rification de la convergence</h2>
<p>Pour s‚Äôassurer que l‚Äôalgorithme converge correctement, on peut :</p>
<ul>
<li><strong>Tracer graphiquement</strong> la valeur de la fonction de co√ªt √† chaque it√©ration.</li>
<li>Fixer un <strong>seuil de tol√©rance</strong> :</li>
</ul>
<p><span class="math display">\[
\text{Si } \|\nabla J(w, b)\| &lt; \varepsilon, \text{ alors on arr√™te l'algorithme.}
\]</span></p>
<hr>
</section>
<section id="mise-√†-jour-des-param√®tres" class="level2">
<h2 class="anchored" data-anchor-id="mise-√†-jour-des-param√®tres">‚öôÔ∏è Mise √† jour des param√®tres</h2>
<p>La descente de gradient met √† jour <strong>simultan√©ment</strong> les poids et le biais selon la r√®gle :</p>
<p><span class="math display">\[
w := w - \alpha \cdot \frac{\partial J(w, b)}{\partial w}
\]</span></p>
<p><span class="math display">\[
b := b - \alpha \cdot \frac{\partial J(w, b)}{\partial b}
\]</span></p>
<p>o√π :</p>
<ul>
<li><span class="math inline">\(J(w, b)\)</span> est la fonction de co√ªt,</li>
<li><span class="math inline">\(\alpha\)</span> est le <strong>learning rate</strong>.</li>
</ul>
<hr>
</section>
<section id="remarques-pratiques" class="level2">
<h2 class="anchored" data-anchor-id="remarques-pratiques">üß™ Remarques pratiques</h2>
<ul>
<li>Un <strong>taux d‚Äôapprentissage dynamique</strong> (adaptatif) peut am√©liorer la convergence.</li>
<li>Des techniques comme <strong>momentum</strong>, <strong>RMSprop</strong> ou <strong>Adam</strong> sont des variantes plus stables.</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-fiting" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="gradient-descent-linear-reg_files/figure-html/fig-fiting-1.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Learning example</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Descente de Gradient et R√©gularisation">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Descente de Gradient et R√©gularisation
</div>
</div>
<div class="callout-body-container callout-body">
<p>L‚Äô<strong>algorithme de descente de gradient</strong> est une m√©thode d‚Äôoptimisation utilis√©e pour ajuster les param√®tres d‚Äôun mod√®le en minimisant une fonction de co√ªt. Il repose sur le calcul du gradient (ou pente) de cette fonction par rapport aux param√®tres, et sur une mise √† jour it√©rative jusqu‚Äô√† convergence.</p>
<p>Cependant, en pratique, on rencontre souvent le <strong>probl√®me de surapprentissage (overfitting)</strong>, notamment lorsque :</p>
<ul>
<li>Le nombre de variables est √©lev√© par rapport au nombre d‚Äôobservations.</li>
<li>Certaines variables explicatives n‚Äôapportent que peu ou pas d‚Äôinformation utile.</li>
<li>Le mod√®le devient trop complexe, capturant le bruit au lieu du signal.</li>
</ul>
<p>Pour pallier cela, plusieurs strat√©gies existent :</p>
<ul>
<li>üîÑ <strong>Augmenter la taille du jeu de donn√©es</strong> : plus de donn√©es permet de mieux g√©n√©raliser.</li>
<li>üß† <strong>S√©lectionner judicieusement les variables</strong> : par des techniques comme le <em>feature selection</em>, on garde seulement les plus pertinentes.</li>
<li>üõ°Ô∏è <strong>Appliquer une r√©gularisation</strong> (comme Lasso ou Ridge) : on p√©nalise la complexit√© du mod√®le pour √©viter l‚Äôajustement excessif.</li>
</ul>
<p>üëâ Ces aspects seront peut-√™tre explor√©s plus en d√©tail dans une prochaine publication √† travers un <strong>mod√®le de r√©gression logistique appliqu√© √† des donn√©es r√©elles</strong>, o√π la s√©lection de variables et la r√©gularisation joueront un r√¥le central.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="La R√©gression Polynomiale">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
La R√©gression Polynomiale
</div>
</div>
<div class="callout-body-container callout-body">
<p>La <strong>r√©gression polynomiale</strong> est une extension de la r√©gression lin√©aire o√π l‚Äôon introduit des puissances suppl√©mentaires des variables explicatives pour capturer des relations <strong>non lin√©aires</strong> entre les variables.</p>
<p>Exemple :</p>
<p><span class="math display">\[
y = w_0 + w_1 x + w_2 x^2 + w_3 x^3 + \dots + w_d x^d + \varepsilon
\]</span></p>
<p>Cela permet au mod√®le de s‚Äôadapter √† des courbes complexes, mais augmente √©galement le <strong>risque de surapprentissage</strong>. Plus le degr√© ( d ) est √©lev√©, plus le mod√®le est flexible, mais moins il g√©n√©ralise bien si les donn√©es ne sont pas suffisantes.</p>
<p>‚û°Ô∏è Il est donc <strong>essentiel de combiner cette approche avec des techniques de validation crois√©e et de r√©gularisation</strong>, pour trouver le bon compromis entre biais et variance.</p>
</div>
</div>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">Applications</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dans cette section, nous coommen√ßons d‚Äôabord par simuler un jeu de donn√©es synth√©tiques repr√©sentant des individus caract√©ris√©s par leur √¢ge, leur niveau d‚Äô√©ducation, leur sexe, ainsi que leur salaire annuel. Le salaire est g√©n√©r√© √† partir d‚Äôun mod√®le probabiliste bas√© sur des salaires de base associ√©s √† chaque niveau d‚Äô√©ducation, auxquels s‚Äôajoute un effet lin√©aire de l‚Äô√¢ge, et une part d‚Äôal√©a simul√©e √† l‚Äôaide d‚Äôune distribution normale.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># generating data</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># fixing generator seed</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># number of observation</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>size <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># creating age variable</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>ages <span class="op">=</span> np.random.randint(low<span class="op">=</span><span class="dv">21</span>, high<span class="op">=</span><span class="dv">66</span>, size<span class="op">=</span>size)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># creating education level variable</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>levels <span class="op">=</span> [<span class="st">'BAC'</span>, <span class="st">'Bachelor degree'</span>, <span class="st">'Msc'</span>, <span class="st">'PhD'</span>]</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>educ_level <span class="op">=</span> np.random.choice(levels, size<span class="op">=</span>size, p<span class="op">=</span>[<span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.4</span>])</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co"># creating sexe variable</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>sexes <span class="op">=</span> [<span class="st">'M'</span>, <span class="st">'F'</span>]</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>sexe <span class="op">=</span> np.random.choice(sexes, size<span class="op">=</span>size)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co"># creating annual salary (Euro) based on the different informations above</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>base_salary <span class="op">=</span> {</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'BAC'</span>: <span class="dv">25000</span>,</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Bachelor degree'</span>: <span class="dv">30000</span>,</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Msc'</span>: <span class="dv">45000</span>,</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">'PhD'</span>: <span class="dv">75000</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>salary <span class="op">=</span> np.asarray([</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>  <span class="bu">round</span>(np.random.normal(base_salary[edu_lvl] <span class="op">+</span> (age<span class="op">*</span><span class="dv">2</span>), <span class="dv">100</span>)) </span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> edu_lvl, age <span class="kw">in</span> <span class="bu">zip</span>(educ_level, ages)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>        <span class="st">'salary'</span>: salary,</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ages'</span>: ages,</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>        <span class="st">'sex'</span>: sexe,</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>        <span class="st">'education'</span>: educ_level</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><strong>Algorithme du calcul de la fonction de co√ªt</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_cost_fn(x:np.ndarray, y:np.ndarray, w:np.array, b:<span class="bu">float</span>) <span class="op">-&gt;</span> <span class="bu">float</span>:</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">        Calculates the cost function (MSE divided by 2)</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">        for multivariate linear regression.</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">            x (np.ndarray): Matrix of explanatory variables (shape: [m, n])</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">            y (np.ndarray): Vector of target values (shape: [m,])</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">            w (np.ndarray): Weight vector (shape: [n,])</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">            b (float): Bias (scalar)</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co">            float: Value of the cost function</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> x<span class="op">@</span>w <span class="op">+</span> b</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    squared_error <span class="op">=</span> np.<span class="bu">sum</span>((y <span class="op">-</span> y_hat)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    cost_fn <span class="op">=</span> squared_error<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>m)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost_fn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><strong>Algorithme du calcul du gradient de la fonction de co√ªt</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_gradient(x:np.ndarray, y:np.ndarray, w:np.array, b:<span class="bu">float</span>) <span class="op">-&gt;</span> <span class="bu">tuple</span>:</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Calculates the gradient of the cost function (MSE) with respect to weights w and bias b.</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">        x (np.ndarray): Matrix of input features of form (m, n),</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">        where m is the number of observations</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">                        and n is the number of explanatory variables.</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">        y (np.ndarray): Vector of target values (m, ).</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">        w (np.ndarray): Weight vector (n, ).</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">        b (float): Scalar bias.</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co">        tuple: A pair (fw_prime, fb_prime) containing :</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co">            - fw_prime (np.ndarray): The gradient of the cost function with respect to w, </span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co">            of the form (n, ).</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co">            - fb_prime (float): The gradient of the cost function with respect to b.</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> x <span class="op">@</span> w <span class="op">+</span> b</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    error <span class="op">=</span> y_hat <span class="op">-</span> y</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    fw_prime <span class="op">=</span> (x.T <span class="op">@</span> error)<span class="op">/</span>m</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    fb_prime <span class="op">=</span> np.<span class="bu">sum</span>(error)<span class="op">/</span>m</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> fw_prime, fb_prime</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><strong>Algorithme de la descente de gradient</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Callable</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> copy <span class="im">import</span> deepcopy</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_descent(</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    x: np.ndarray,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    y: np.ndarray,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    alpha: <span class="bu">float</span>,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    w_in: np.array,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    b_in: <span class="bu">float</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    max_iter: <span class="bu">int</span>,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    tolerance: <span class="bu">float</span>,</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    cost_fn: Callable,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    gradient_compute_fn: Callable) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Performs gradient descent to adjust</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co">    the parameters w and b.</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co">        x (np.ndarray): Input data (m, n)</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co">        y (np.ndarray): Target (m,)</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co">        w_in (np.ndarray): Initial weight (n,)</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="co">        b_in (float): Initial bias</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="co">        alpha (float): Learning rate</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="co">        max_iter (int): Maximum number of iterations</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="co">        tolerance (float): Convergence threshold</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="co">        cost_fn (Callable): Cost function</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="co">        gradient_compute_fn (Callable): Gradient calculation function</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="co">        dict: History of parameters and cost at each iteration</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> deepcopy(w_in)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> b_in</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    cost_fn_and_params_hist <span class="op">=</span> {}</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_iter):</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        fw_i, fb_i <span class="op">=</span> gradient_compute_fn(x, y, w, b)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        w <span class="op">=</span> w <span class="op">-</span> alpha<span class="op">*</span>fw_i</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> b <span class="op">-</span> alpha<span class="op">*</span>fb_i</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>        cost_fn_i <span class="op">=</span> cost_fn(x, y, w, b)</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>        cost_fn_and_params_hist[i] <span class="op">=</span> {</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>            <span class="st">'w'</span>: w.copy(),</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">'b'</span>: b,</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>            <span class="st">'cost_fn'</span>: cost_fn_i</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">%</span> <span class="dv">15000</span> <span class="op">==</span> <span class="dv">0</span>: <span class="co"># you can adjust: I don't want to display all the iterations</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'Iteraion </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> : </span><span class="ch">\n</span><span class="ss">|(w, b) = (</span><span class="sc">{</span>w<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>b<span class="sc">:4f}</span><span class="ss">) | cost_fn = </span><span class="sc">{</span>cost_fn_i<span class="sc">:4f}</span><span class="ss">|'</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.linalg.norm(fw_i) <span class="op">&lt;</span> tolerance <span class="kw">and</span> <span class="bu">abs</span>(fb_i) <span class="op">&lt;</span> tolerance:</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'The algorithm converges at the </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">-th iteration'</span></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'</span><span class="ch">\n</span><span class="ss">Then we have (w, b) = (</span><span class="sc">{</span>w<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>b<span class="sc">:4f}</span><span class="ss">) &amp; cost_fn = </span><span class="sc">{</span>cost_fn_i<span class="sc">:4f}</span><span class="ss">'</span></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost_fn_and_params_hist</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
</section>
<section id="analyse-exploratoire-relation-entre-salaire-et-variables-explicatives" class="level2">
<h2 class="anchored" data-anchor-id="analyse-exploratoire-relation-entre-salaire-et-variables-explicatives">üìä Analyse exploratoire : Relation entre salaire et variables explicatives</h2>
<p>Ici on veut predire le salaire d‚Äôun individu en fonction de son niveau d‚Äô√©ducation, de son √¢ge et de son sexe.</p>
<ul>
<li><strong>Premi√®res lignes de la table</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>df_5 <span class="op">=</span> df.loc[:<span class="dv">5</span>, :]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell tbl-cap-location-top">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>df_5_r <span class="ot">=</span> py<span class="sc">$</span>df_5</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">display_table</span>(df_5_r, <span class="st">""</span>, <span class="at">nrow_ =</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="tbl-first" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;1: The first lines of our database</caption>
<thead>
<tr class="header">
<th style="text-align: left;">salary</th>
<th style="text-align: right;">ages</th>
<th style="text-align: right;">sex</th>
<th style="text-align: right;">education</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">75213</td>
<td style="text-align: right;">59</td>
<td style="text-align: right;">F</td>
<td style="text-align: right;">PhD</td>
</tr>
<tr class="even">
<td style="text-align: left;">45269</td>
<td style="text-align: right;">49</td>
<td style="text-align: right;">F</td>
<td style="text-align: right;">Msc</td>
</tr>
<tr class="odd">
<td style="text-align: left;">45060</td>
<td style="text-align: right;">35</td>
<td style="text-align: right;">M</td>
<td style="text-align: right;">Msc</td>
</tr>
<tr class="even">
<td style="text-align: left;">75109</td>
<td style="text-align: right;">63</td>
<td style="text-align: right;">F</td>
<td style="text-align: right;">PhD</td>
</tr>
<tr class="odd">
<td style="text-align: left;">45063</td>
<td style="text-align: right;">28</td>
<td style="text-align: right;">M</td>
<td style="text-align: right;">Msc</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<ul>
<li><strong>R√©sum√© statistique de la table</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df.describe() <span class="co"># displays the statistical summary of numerical variables</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             salary         ages
count   1000.000000  1000.000000
mean   52498.163000    43.000000
std    20121.852889    12.945562
min    24882.000000    21.000000
25%    30139.000000    32.000000
50%    45133.000000    44.000000
75%    75065.000000    54.000000
max    75441.000000    65.000000</code></pre>
</div>
</div>
<ul>
<li><strong>Distribution du salaire en fonction des features</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>X_features <span class="op">=</span> df.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>).columns.to_list()</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>X_features</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['ages', 'sex', 'education']</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize <span class="op">=</span> (<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(axes)):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    axes[i].scatter(y<span class="op">=</span>df[<span class="st">'salary'</span>], x<span class="op">=</span>df[df.columns.to_list()[i <span class="op">+</span> <span class="dv">1</span>]])</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(X_features[i].capitalize(), fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylabel(<span class="st">'Salary'</span>, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(X_features[i].capitalize(), size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    axes[i].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="ss">f'Relation between salary and </span><span class="sc">{</span>X_features[i]<span class="sc">.</span>capitalize()<span class="sc">}</span><span class="ss">'</span>, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-dist-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="gradient-descent-linear-reg_files/figure-html/fig-dist-plot-1.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Distribution of variables as a function of salary</figcaption>
</figure>
</div>
</div>
</div>
<section id="relation-entre-le-salaire-et-l√¢ge" class="level3">
<h3 class="anchored" data-anchor-id="relation-entre-le-salaire-et-l√¢ge">üë¥ Relation entre le salaire et l‚Äô√¢ge</h3>
<ul>
<li><strong>üîç Observation :</strong>
<ul>
<li>Les salaires sont regroup√©s autour de quelques valeurs fixes (25k, 30k, 45k, 75k), ind√©pendamment de l‚Äô√¢ge.</li>
<li>La distribution semble en <strong>paliers</strong>, pas de tendance lin√©aire visible.</li>
</ul></li>
<li><strong>üí° Interpr√©tation :</strong>
<ul>
<li>Il <strong>n‚Äôexiste pas de relation lin√©aire claire</strong> entre l‚Äô√¢ge et le salaire.</li>
<li>L‚Äô√¢ge <strong>n‚Äôest pas un facteur explicatif majeur</strong> du salaire dans cet √©chantillon.</li>
<li>üëâ Il faudrait explorer d‚Äôautres variables comme l‚Äô<code>√©ducation</code>, ect..</li>
</ul></li>
</ul>
<hr>
</section>
<section id="relation-entre-le-salaire-et-le-sexe" class="level3">
<h3 class="anchored" data-anchor-id="relation-entre-le-salaire-et-le-sexe">üöª Relation entre le salaire et le sexe</h3>
<ul>
<li><strong>üîç Observation :</strong>
<ul>
<li>Les salaires des femmes (<code>F</code>) et des hommes (<code>M</code>) sont r√©partis de mani√®re similaire.</li>
<li>Aucune <strong>diff√©rence salariale flagrante</strong> n‚Äôappara√Æt sur ce graphique.</li>
</ul></li>
<li><strong>üí° Interpr√©tation :</strong>
<ul>
<li>Le <strong>sexe ne semble pas avoir d‚Äôinfluence directe</strong> sur le salaire ici.</li>
<li>üìå Une analyse plus fine (ex. tests statistiques) serait n√©cessaire pour confirmer l‚Äôabsence d‚Äô√©cart significatif (mais ce n‚Äôest pas le but ici, <a href="https://djamal2905.github.io/djamal_website/INFO_MINI_PROJETS/classi_bin_acp_kmeans_knn_logit/work.html">Cliquez ici pour voir une publication dans laquelle je r√©alise des tests statistiques afin de selectionner les variables essentielles pour la sp√©cification de mon mod√®le</a>).</li>
</ul></li>
</ul>
<hr>
</section>
<section id="relation-entre-le-salaire-et-le-niveau-d√©ducation" class="level3">
<h3 class="anchored" data-anchor-id="relation-entre-le-salaire-et-le-niveau-d√©ducation">üéì Relation entre le salaire et le niveau d‚Äô√©ducation</h3>
<ul>
<li><strong>üîç Observation :</strong>
<ul>
<li>Le salaire <strong>augmente avec le niveau de dipl√¥me</strong> :
<ul>
<li>PhD üßëüî¨ &gt; MSc üë®üéì &gt; Bachelor üë®üè´ &gt; BAC üéí</li>
</ul></li>
<li>Cette progression est claire et <strong>ordonn√©e</strong>.</li>
</ul></li>
<li><strong>üí° Interpr√©tation :</strong>
<ul>
<li>Le <strong>niveau d‚Äô√©ducation est un facteur pr√©dictif fort</strong> du salaire.</li>
<li>Il existe une <strong>relation croissante et logique</strong> entre dipl√¥me obtenu et r√©mun√©ration.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="conclusion-de-lanalyse-exploratoire-rapide" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-de-lanalyse-exploratoire-rapide">‚úÖ Conclusion de l‚Äôanalyse exploratoire rapide</h3>
<blockquote class="blockquote">
<p>üß† <strong>De prime abord</strong>, on pourrait penser qu‚Äôil existe une relation non lin√©aire entre les variables explicatives et le salaire.<br>
En r√©alit√©, seule la variable <strong>üéì niveau d‚Äô√©ducation</strong> montre une <strong>relation coh√©rente et croissante</strong>.<br>
Ni <strong>üë¥ l‚Äô√¢ge</strong>, ni <strong>üöª le sexe</strong> ne pr√©sentent d‚Äôinfluence claire sur le salaire.<br>
Cette analyse souligne l‚Äôimportance d‚Äôune <strong>exploration visuelle et statistique</strong> avant toute mod√©lisation.</p>
</blockquote>
<hr>
</section>
</section>
<section id="data-preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="data-preprocessing">Data preprocessing</h2>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Code pour partitionner les donn√©es
</div>
</div>
<div class="callout-body-container callout-body">
<p>La fonction suivante permet de diviser vos donn√©es en ensembles d‚Äôentra√Ænement et de test pour la validation du mod√®le. Il est important de s‚Äôassurer que les deux ensembles contiennent toutes les cat√©gories ou modalit√©s des variables cat√©gorielles (<strong><em>indice : stratification</em></strong>). La fonction ci-dessous ne prend pas cela en charge automatiquement. Cependant, gr√¢ce √† la taille de notre jeu de donn√©es et √† l‚Äôutilisation de la graine al√©atoire fix√©e √† 42, nous pouvons garantir que ces caract√©ristiques sont bien pr√©sentes dans les deux ensembles.</p>
</div>
</div>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> train[<span class="st">'education'</span>].unique()</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>array([<span class="st">'Bachelor degree'</span>, <span class="st">'PhD'</span>, <span class="st">'Msc'</span>, <span class="st">'BAC'</span>], dtype<span class="op">=</span><span class="bu">object</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> test[<span class="st">'education'</span>].unique()</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>array([<span class="st">'Msc'</span>, <span class="st">'PhD'</span>, <span class="st">'BAC'</span>, <span class="st">'Bachelor degree'</span>], dtype<span class="op">=</span><span class="bu">object</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_data_partition(df, train_ratio):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">        Creates a random partition of the DataFrame into training and test sets.</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">            df (pd.DataFrame): the complete DataFrame</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">            train_ratio (float): the proportion of rows to be used for training (ex: 0.8)</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co">            tuple: (train_df, test_df)</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    nrow_df <span class="op">=</span> df.shape[<span class="dv">0</span>]</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    nrow_train <span class="op">=</span> <span class="bu">round</span>(nrow_df<span class="op">*</span>train_ratio)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    train_idx <span class="op">=</span> np.random.choice(df.index, size<span class="op">=</span>nrow_train, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    test_idx <span class="op">=</span> df.index.difference(train_idx)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    train_df <span class="op">=</span> df.iloc[train_idx]</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    test_df <span class="op">=</span> df.iloc[test_idx]</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (train_df, test_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Une fois les donn√©es simul√©es, nous proc√©dons √† leur s√©paration en deux sous-ensembles distincts : un ensemble d‚Äôentra√Ænement, utilis√© pour ajuster le mod√®le, et un ensemble de test, destin√© √† l‚Äô√©valuer. La fonction <code>create_data_partition</code> r√©alise une partition al√©atoire selon un ratio d√©fini (ici 80% pour l‚Äôentra√Ænement, 20% pour le test). Ensuite, les variables explicatives (<code>ages</code>, <code>education</code>, <code>sex</code>) sont trait√©es via une pipeline de pr√©traitement : les variables num√©riques sont standardis√©es (centr√©es-r√©duites) tandis que les variables cat√©gorielles sont transform√©es en indicatrices (encodage one-hot, sans la premi√®re modalit√©). Enfin, la variable cible (<code>salary</code>) est √©galement standardis√©e pour assurer une convergence efficace de l‚Äôalgorithme de descente de gradient.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># data preprocessing</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># geting train and test datasets</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>train, test <span class="op">=</span> create_data_partition(df, <span class="fl">0.8</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting features</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> train.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting target variable</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> train[<span class="st">'salary'</span>]</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="co"># standardization of the target variable</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>scaler_y <span class="op">=</span> StandardScaler()</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>onehot_encoder_educ <span class="op">=</span> OneHotEncoder()</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>y_scaled <span class="op">=</span> scaler_y.fit_transform(y.values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)).flatten()</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="co"># one-hot encodings &amp; standardization : pipeline treatment</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>numeric_features <span class="op">=</span> [<span class="st">'ages'</span>]</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>categorical_features <span class="op">=</span> [<span class="st">'education'</span>, <span class="st">'sex'</span>]</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>preprocessor <span class="op">=</span> ColumnTransformer(transformers<span class="op">=</span>[</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'num'</span>, StandardScaler(), numeric_features),</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'cat'</span>, OneHotEncoder(drop<span class="op">=</span><span class="st">'first'</span>), categorical_features)</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a><span class="co"># transform numerical values by standardize them and categorical one by dummy them</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>X_processed <span class="op">=</span> preprocessor.fit_transform(X<span class="op">=</span>X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
‚ö†Ô∏è Important : <code>fit_transform()</code> vs <code>transform()</code>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Toujours utiliser <code>fit_transform()</code> <strong>uniquement sur les donn√©es d‚Äôentra√Ænement</strong>, et <code>transform()</code> sur les donn√©es de validation ou de test.</p>
<p>Cela s‚Äôapplique √† <strong>tous les types de preprocessing</strong>, notamment :</p>
<ul>
<li>üü¶ <strong>StandardScaler</strong> : la moyenne et l‚Äô√©cart-type doivent √™tre appris sur le <em>train</em> uniquement.</li>
<li>üüß <strong>OneHotEncoder</strong> : les cat√©gories doivent √™tre identifi√©es √† partir du <em>train</em> et appliqu√©es de mani√®re coh√©rente au <em>test</em>.</li>
</ul>
<p>‚ùå Ne jamais faire <code>fit_transform()</code> sur le test, car cela introduit du <strong>data leakage</strong> (les donn√©es de test influencent le mod√®le).</p>
</div>
</div>
<hr>
</section>
<section id="application-de-lalgorithme-de-la-descente-de-gradient" class="level2">
<h2 class="anchored" data-anchor-id="application-de-lalgorithme-de-la-descente-de-gradient">Application de l‚Äôalgorithme de la descente de gradient</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Comme mentionn√© pr√©c√©demment, le choix du <code>learning rate</code> (ou taux d‚Äôapprentissage) est un param√®tre crucial dans l‚Äôalgorithme de descente de gradient. Un taux trop √©lev√© peut emp√™cher la convergence du mod√®le, tandis qu‚Äôun taux trop faible peut rendre l‚Äôapprentissage extr√™mement lent. Afin d‚Äôidentifier un taux optimal, plusieurs valeurs sont test√©es, et celle qui permet de minimiser au mieux la fonction de co√ªt est retenue.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>alphas <span class="op">=</span> [<span class="fl">1e-1</span>, <span class="fl">1e-2</span>] <span class="co"># , 1e-3, 1e-4, 1e-5 √† ajouter si vous voulez, je veux juste reduire l'affichage</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>n_features <span class="op">=</span> X_processed.shape[<span class="dv">1</span>]</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> np.zeros(n_features)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.random.randint(<span class="dv">100</span>, size<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="bu">int</span>(b)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>tolerance <span class="op">=</span> <span class="fl">1e-3</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>max_iters <span class="op">=</span> <span class="dv">50000</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>cost_fn <span class="op">=</span> compute_cost_fn</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>gradient_fn <span class="op">=</span> compute_gradient</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>all_histories <span class="op">=</span> {}</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha <span class="kw">in</span> alphas:</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Runing the algorithm for alpha : </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ch">\n</span><span class="ss">'</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> np.zeros(n_features)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> <span class="bu">int</span>(np.random.randint(<span class="dv">100</span>, size<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>])</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> gradient_descent(</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>        X_processed,</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        y_scaled,</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>        alpha<span class="op">=</span>alpha,</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>        w_in<span class="op">=</span>w,</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>        b_in<span class="op">=</span>b,</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>        max_iter<span class="op">=</span>max_iters,</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>        tolerance<span class="op">=</span>tolerance,</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>        cost_fn<span class="op">=</span>cost_fn,</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        gradient_compute_fn<span class="op">=</span>gradient_fn)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    all_histories[<span class="bu">str</span>(alpha)] <span class="op">=</span> history</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Runing the algorithm for alpha : 0.1

Iteraion 0 : 
|(w, b) = ([-0.00367445 -0.04214402 -0.03787291  0.00503207 -0.04740491], 0.900000) | cost_fn = 0.855335|
The algorithm converges at the 1687-th iteration
Then we have (w, b) = ([ 1.30308246e-03  2.22807855e-01  9.66238813e-01  2.45274791e+00
 -5.24625714e-04], -1.332871) &amp; cost_fn = 0.000037


Runing the algorithm for alpha : 0.01

Iteraion 0 : 
|(w, b) = ([-0.00036745 -0.0262144  -0.03431229 -0.04528429 -0.05781549], 11.880000) | cost_fn = 70.351204|
Iteraion 15000 : 
|(w, b) = ([ 2.13935724e-03  1.41295729e-01  8.87862367e-01  2.37691272e+00
 -1.16515913e-03], -1.261175) | cost_fn = 0.000502|
The algorithm converges at the 20966-th iteration
Then we have (w, b) = ([ 1.30383689e-03  2.22734320e-01  9.66168107e-01  2.45267950e+00
 -5.25203562e-04], -1.332807) &amp; cost_fn = 0.000037</code></pre>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Ici, on constate directement que notre algorithme a converg√© (crit√®re de <em>tol√©rance</em>) pour chacun des taux d‚Äôapprentissage (<code>learning rate</code>) test√©s.</p>
<p>Apr√®s cet entra√Ænement, il est int√©ressant de d√©terminer quel <code>learning rate</code> a permis d‚Äôobtenir le meilleur r√©sultat. Le code suivant est particuli√®rement utile lorsqu‚Äôon teste plusieurs valeurs de <code>learning rate</code> (plus de deux).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>best_alpha <span class="op">=</span> <span class="va">None</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>min_cost <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha, hist <span class="kw">in</span> all_histories.items():</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    costs <span class="op">=</span> [v[<span class="st">'cost_fn'</span>] <span class="cf">for</span> v <span class="kw">in</span> hist.values()]</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    min_cost_alpha <span class="op">=</span> <span class="bu">min</span>(costs)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Alpha </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss"> ‚û§ Min cost: </span><span class="sc">{</span>min_cost_alpha<span class="sc">:.5f}</span><span class="ss">"</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> min_cost_alpha <span class="op">&lt;</span> min_cost:</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>        min_cost <span class="op">=</span> min_cost_alpha</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>        best_alpha <span class="op">=</span> alpha</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Alpha 0.1 ‚û§ Min cost: 0.00004
Alpha 0.01 ‚û§ Min cost: 0.00004</code></pre>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">‚úÖ Best alpha: </span><span class="sc">{</span>best_alpha<span class="sc">}</span><span class="ss"> with min cost: </span><span class="sc">{</span>min_cost<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
‚úÖ Best alpha: 0.1 with min cost: 0.00</code></pre>
</div>
</div>
<p>Avec ces deux <code>learning rates</code>, la fonction de co√ªt atteint 0, ce qui signifie que l‚Äôalgorithme a bien converg√© puisque la fonction de co√ªt est toujours positive.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_best_w_b(cost_fn_and_params_hist: <span class="bu">dict</span>):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    hist_len <span class="op">=</span> <span class="bu">len</span>(cost_fn_and_params_hist)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    best_of_hist <span class="op">=</span> cost_fn_and_params_hist[hist_len<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_of_hist</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(w, b, X):</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X <span class="op">@</span> w <span class="op">+</span> b</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> all_histories[<span class="st">'0.01'</span>]</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>best <span class="op">=</span> get_best_w_b(hist)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;On peut maintenant calculer nos pr√©dictions et v√©rifier leur qualit√© par rapport aux donn√©es r√©elles. Rappelons que les donn√©es ont √©t√© standardis√©es, il faudra donc ramener les pr√©dictions √† leur √©chelle d‚Äôorigine pour une interpr√©tation correcte.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># standardised predictions</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>ypred_scaled <span class="op">=</span> predict(best[<span class="st">'w'</span>], best[<span class="st">'b'</span>], X_processed).reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Standardised data (first 4 values): </span><span class="sc">{</span>ypred_scaled[:<span class="dv">4</span>]<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Standardised data (first 4 values): [[-1.11148687]
 [ 1.12097355]
 [ 1.11835771]
 [-1.1107826 ]]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># normal scale</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> scaler_y.inverse_transform(ypred_scaled)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Data on normal scale (first 4 values): </span><span class="sc">{</span>y_pred[:<span class="dv">4</span>]<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data on normal scale (first 4 values): [[30000.2280983 ]
 [75092.97779228]
 [75040.14127095]
 [30014.45331559]]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># display of optimal parameters</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Optimum parameters : </span><span class="sc">{</span>best<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimum parameters : {'w': array([ 1.30383689e-03,  2.22734320e-01,  9.66168107e-01,  2.45267950e+00,
       -5.25203562e-04]), 'b': -1.332806620067705, 'cost_fn': 3.722342588474543e-05}</code></pre>
</div>
</div>
<p>L‚Äôerreur quadratique moyenne sur les donn√©es d‚Äôapprentissage est donc <strong>0.00610</strong>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize <span class="op">=</span> (<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(axes)):</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    axes[i].scatter(train[X_features[i]], train[<span class="st">'salary'</span>], label<span class="op">=</span><span class="st">'target'</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    axes[i].scatter(train[X_features[i]], y_pred, c<span class="op">=</span><span class="st">'orange'</span>, label<span class="op">=</span><span class="st">'predicted'</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylabel(<span class="st">'Salary'</span>, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(X_features[i].capitalize(), size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    axes[i].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="ss">f'Relation between salary and </span><span class="sc">{</span>X_features[i]<span class="sc">.</span>capitalize()<span class="sc">}</span><span class="ss">'</span>, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-plot-prediction" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="gradient-descent-linear-reg_files/figure-html/fig-plot-prediction-3.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Predcitions vs Real data</figcaption>
</figure>
</div>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;On peut voir que l‚Äôajustement est tr√®s satisfaisant, mais il reste √† d√©terminer s‚Äôil ne s‚Äôagit pas d‚Äôun <code>surapprentissage</code>. Pour cela nous allons utiliser les donn√©es de test, pour √©valuer le mod√®le entrain√©.</p>
</section>
<section id="evaluation-du-mod√®le" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-du-mod√®le">Evaluation du mod√®le</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pour √©valuer le mod√®le nous utilisons la <strong>validation crois√©e</strong> car elle est robuste en terme d‚Äô√©valuation de performance d‚Äôun mod√®le.</p>
<ul>
<li><p><strong>But principal</strong> : √âvaluer la performance d‚Äôun mod√®le de mani√®re fiable et robuste, en r√©duisant le biais d√ª √† une simple s√©paration train/test.</p></li>
<li><p><strong>√âtape 1 : Partition des donn√©es</strong><br>
Diviser l‚Äôensemble des donn√©es en <em>k</em> sous-ensembles (ou ¬´ folds ¬ª) de taille √† peu pr√®s √©gale.</p></li>
<li><p><strong>√âtape 2 : Boucle sur les folds</strong><br>
Pour chaque fold (de 1 √† k) :</p>
<ul>
<li>Utiliser ce fold comme ensemble de test (validation).<br>
</li>
<li>Utiliser les <em>k-1</em> autres folds comme ensemble d‚Äôentra√Ænement.</li>
</ul></li>
<li><p><strong>√âtape 3 : Entra√Ænement</strong><br>
Entra√Æner le mod√®le uniquement sur les donn√©es d‚Äôentra√Ænement (les <em>k-1</em> folds).</p></li>
<li><p><strong>√âtape 4 : √âvaluation</strong><br>
Tester le mod√®le entra√Æn√© sur le fold de test (le fold laiss√© de c√¥t√©), calculer une m√©trique de performance (ex : erreur quadratique moyenne).</p></li>
<li><p><strong>√âtape 5 : Agr√©gation</strong><br>
R√©p√©ter les √©tapes 2 √† 4 pour chaque fold, puis calculer la moyenne (et √©ventuellement l‚Äô√©cart-type) des performances obtenues sur chaque fold.</p></li>
<li><p><strong>Avantages</strong> :</p>
<ul>
<li>Meilleure estimation de la g√©n√©ralisation du mod√®le sur des donn√©es nouvelles.<br>
</li>
<li>R√©duit le sur-apprentissage li√© √† un seul d√©coupage train/test.<br>
</li>
<li>Utilise efficacement toutes les donn√©es pour entra√Ænement et validation.</li>
</ul></li>
<li><p><strong>Inconv√©nients</strong> :</p>
<ul>
<li>Co√ªt computationnel plus √©lev√©, car le mod√®le est entra√Æn√© <em>k</em> fois.<br>
</li>
<li>Peut √™tre sensible au choix de <em>k</em> (souvent 5 ou 10).</li>
</ul></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-kfold-illustration" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="k_fold.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Illustration of a cross-validation process</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> k_fold_cross_validation(df, k, alpha, max_iters, tolerance, cost_fn, gradient_fn):</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Perform k-fold cross-validation using gradient descent.</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="co">        df (pd.DataFrame): full dataset (training set)</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co">        k (int): number of folds</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co">        alpha (float): learning rate</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="co">        max_iters (int): maximum number of iterations for gradient descent</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="co">        tolerance (float): convergence threshold</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co">        cost_fn (Callable): cost function</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co">        gradient_fn (Callable): gradient computation function</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="co">        dict: dictionnaire avec listes des mse_train, mse_test, r2_train, r2_test</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Shuffle the DataFrame index</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df.sample(frac<span class="op">=</span><span class="dv">1</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    fold_size <span class="op">=</span> <span class="bu">len</span>(df) <span class="op">//</span> k</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    mse_train_list <span class="op">=</span> []</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>    mse_test_list <span class="op">=</span> []</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>    r2_train_list <span class="op">=</span> []</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>    r2_test_list <span class="op">=</span> []</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define start and end indices for the test fold</span></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>        start <span class="op">=</span> fold <span class="op">*</span> fold_size</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>        end <span class="op">=</span> (fold <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> fold_size <span class="cf">if</span> fold <span class="op">!=</span> k <span class="op">-</span> <span class="dv">1</span> <span class="cf">else</span> <span class="bu">len</span>(df)</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Split the data into test and train folds</span></span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>        test_df <span class="op">=</span> df.iloc[start:end]</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>        train_df <span class="op">=</span> pd.concat([df.iloc[:start], df.iloc[end:]], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prepare features and target for train and test</span></span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>        X_train <span class="op">=</span> train_df.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>        y_train <span class="op">=</span> train_df[<span class="st">'salary'</span>]</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>        X_test <span class="op">=</span> test_df.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>        y_test <span class="op">=</span> test_df[<span class="st">'salary'</span>]</span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">10</span>)</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Fold </span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Train unique education:"</span>, train_df[<span class="st">'education'</span>].unique())</span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Test unique education:"</span>, test_df[<span class="st">'education'</span>].unique())</span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Train unique sex:"</span>, train_df[<span class="st">'sex'</span>].unique())</span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Test unique sex:"</span>, test_df[<span class="st">'sex'</span>].unique())</span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>()</span>
<span id="cb30-50"><a href="#cb30-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-51"><a href="#cb30-51" aria-hidden="true" tabindex="-1"></a>        numeric_features <span class="op">=</span> [<span class="st">'ages'</span>]</span>
<span id="cb30-52"><a href="#cb30-52" aria-hidden="true" tabindex="-1"></a>        categorical_features <span class="op">=</span> [<span class="st">'education'</span>, <span class="st">'sex'</span>]</span>
<span id="cb30-53"><a href="#cb30-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-54"><a href="#cb30-54" aria-hidden="true" tabindex="-1"></a>        preprocessor <span class="op">=</span> ColumnTransformer(transformers<span class="op">=</span>[</span>
<span id="cb30-55"><a href="#cb30-55" aria-hidden="true" tabindex="-1"></a>            (<span class="st">'num'</span>, StandardScaler(), numeric_features),</span>
<span id="cb30-56"><a href="#cb30-56" aria-hidden="true" tabindex="-1"></a>            (<span class="st">'cat'</span>, OneHotEncoder(drop<span class="op">=</span><span class="st">'first'</span>), categorical_features)</span>
<span id="cb30-57"><a href="#cb30-57" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb30-58"><a href="#cb30-58" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-59"><a href="#cb30-59" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Preprocess the data using our pipeline</span></span>
<span id="cb30-60"><a href="#cb30-60" aria-hidden="true" tabindex="-1"></a>        X_train_processed <span class="op">=</span> preprocessor.fit_transform(X_train)</span>
<span id="cb30-61"><a href="#cb30-61" aria-hidden="true" tabindex="-1"></a>        y_train_scaled <span class="op">=</span> scaler_y.fit_transform(y_train.values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)).flatten()</span>
<span id="cb30-62"><a href="#cb30-62" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-63"><a href="#cb30-63" aria-hidden="true" tabindex="-1"></a>        X_test_processed <span class="op">=</span> preprocessor.transform(X_test)</span>
<span id="cb30-64"><a href="#cb30-64" aria-hidden="true" tabindex="-1"></a>        y_test_scaled <span class="op">=</span> scaler_y.transform(y_test.values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)).flatten()</span>
<span id="cb30-65"><a href="#cb30-65" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-66"><a href="#cb30-66" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize parameters</span></span>
<span id="cb30-67"><a href="#cb30-67" aria-hidden="true" tabindex="-1"></a>        n_features <span class="op">=</span> X_train_processed.shape[<span class="dv">1</span>]</span>
<span id="cb30-68"><a href="#cb30-68" aria-hidden="true" tabindex="-1"></a>        w <span class="op">=</span> np.zeros(n_features)</span>
<span id="cb30-69"><a href="#cb30-69" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-70"><a href="#cb30-70" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-71"><a href="#cb30-71" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Run gradient descent on training data</span></span>
<span id="cb30-72"><a href="#cb30-72" aria-hidden="true" tabindex="-1"></a>        history <span class="op">=</span> gradient_descent(</span>
<span id="cb30-73"><a href="#cb30-73" aria-hidden="true" tabindex="-1"></a>            X_train_processed,</span>
<span id="cb30-74"><a href="#cb30-74" aria-hidden="true" tabindex="-1"></a>            y_train_scaled,</span>
<span id="cb30-75"><a href="#cb30-75" aria-hidden="true" tabindex="-1"></a>            alpha<span class="op">=</span>alpha,</span>
<span id="cb30-76"><a href="#cb30-76" aria-hidden="true" tabindex="-1"></a>            w_in<span class="op">=</span>w,</span>
<span id="cb30-77"><a href="#cb30-77" aria-hidden="true" tabindex="-1"></a>            b_in<span class="op">=</span>b,</span>
<span id="cb30-78"><a href="#cb30-78" aria-hidden="true" tabindex="-1"></a>            max_iter<span class="op">=</span>max_iters,</span>
<span id="cb30-79"><a href="#cb30-79" aria-hidden="true" tabindex="-1"></a>            tolerance<span class="op">=</span>tolerance,</span>
<span id="cb30-80"><a href="#cb30-80" aria-hidden="true" tabindex="-1"></a>            cost_fn<span class="op">=</span>cost_fn,</span>
<span id="cb30-81"><a href="#cb30-81" aria-hidden="true" tabindex="-1"></a>            gradient_compute_fn<span class="op">=</span>gradient_fn</span>
<span id="cb30-82"><a href="#cb30-82" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb30-83"><a href="#cb30-83" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-84"><a href="#cb30-84" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Retrieve best parameters from last iteration</span></span>
<span id="cb30-85"><a href="#cb30-85" aria-hidden="true" tabindex="-1"></a>        last_iter <span class="op">=</span> <span class="bu">max</span>(history.keys())</span>
<span id="cb30-86"><a href="#cb30-86" aria-hidden="true" tabindex="-1"></a>        w_best <span class="op">=</span> history[last_iter][<span class="st">'w'</span>]</span>
<span id="cb30-87"><a href="#cb30-87" aria-hidden="true" tabindex="-1"></a>        b_best <span class="op">=</span> history[last_iter][<span class="st">'b'</span>]</span>
<span id="cb30-88"><a href="#cb30-88" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-89"><a href="#cb30-89" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predictions</span></span>
<span id="cb30-90"><a href="#cb30-90" aria-hidden="true" tabindex="-1"></a>        y_pred_train <span class="op">=</span> X_train_processed <span class="op">@</span> w_best <span class="op">+</span> b_best</span>
<span id="cb30-91"><a href="#cb30-91" aria-hidden="true" tabindex="-1"></a>        y_pred_test <span class="op">=</span> X_test_processed <span class="op">@</span> w_best <span class="op">+</span> b_best</span>
<span id="cb30-92"><a href="#cb30-92" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-93"><a href="#cb30-93" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute cost function (cost_fn returns half MSE)</span></span>
<span id="cb30-94"><a href="#cb30-94" aria-hidden="true" tabindex="-1"></a>        train_cost_half <span class="op">=</span> cost_fn(X_train_processed, y_train_scaled, w_best, b_best)</span>
<span id="cb30-95"><a href="#cb30-95" aria-hidden="true" tabindex="-1"></a>        test_cost_half <span class="op">=</span> cost_fn(X_test_processed, y_test_scaled, w_best, b_best)</span>
<span id="cb30-96"><a href="#cb30-96" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-97"><a href="#cb30-97" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute full MSE (because Gradient descent divided it by 2)</span></span>
<span id="cb30-98"><a href="#cb30-98" aria-hidden="true" tabindex="-1"></a>        train_mse <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> train_cost_half</span>
<span id="cb30-99"><a href="#cb30-99" aria-hidden="true" tabindex="-1"></a>        test_mse <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> test_cost_half</span>
<span id="cb30-100"><a href="#cb30-100" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-101"><a href="#cb30-101" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute R2 scores</span></span>
<span id="cb30-102"><a href="#cb30-102" aria-hidden="true" tabindex="-1"></a>        train_r2 <span class="op">=</span> r2_score(y_train_scaled, y_pred_train)</span>
<span id="cb30-103"><a href="#cb30-103" aria-hidden="true" tabindex="-1"></a>        test_r2 <span class="op">=</span> r2_score(y_test_scaled, y_pred_test)</span>
<span id="cb30-104"><a href="#cb30-104" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-105"><a href="#cb30-105" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Fold </span><span class="sc">{</span>fold <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> - Train MSE: </span><span class="sc">{</span>train_mse<span class="sc">:.5f}</span><span class="ss"> | Test MSE: </span><span class="sc">{</span>test_mse<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb30-106"><a href="#cb30-106" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Fold </span><span class="sc">{</span>fold <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> - Train RMSE: </span><span class="sc">{</span>np<span class="sc">.</span>sqrt(train_mse)<span class="sc">:.5f}</span><span class="ss"> | Test RMSE: </span><span class="sc">{</span>np<span class="sc">.</span>sqrt(test_mse)<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb30-107"><a href="#cb30-107" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Fold </span><span class="sc">{</span>fold <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> - Train R¬≤: </span><span class="sc">{</span>train_r2<span class="sc">:.5f}</span><span class="ss"> | Test R¬≤: </span><span class="sc">{</span>test_r2<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb30-108"><a href="#cb30-108" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-109"><a href="#cb30-109" aria-hidden="true" tabindex="-1"></a>        mse_train_list.append(train_mse)</span>
<span id="cb30-110"><a href="#cb30-110" aria-hidden="true" tabindex="-1"></a>        mse_test_list.append(test_mse)</span>
<span id="cb30-111"><a href="#cb30-111" aria-hidden="true" tabindex="-1"></a>        r2_train_list.append(train_r2)</span>
<span id="cb30-112"><a href="#cb30-112" aria-hidden="true" tabindex="-1"></a>        r2_test_list.append(test_r2)</span>
<span id="cb30-113"><a href="#cb30-113" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-114"><a href="#cb30-114" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">10</span>)</span>
<span id="cb30-115"><a href="#cb30-115" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span><span class="op">*</span><span class="dv">3</span>)</span>
<span id="cb30-116"><a href="#cb30-116" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-117"><a href="#cb30-117" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Median Train MSE over </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> folds: </span><span class="sc">{</span>np<span class="sc">.</span>median(mse_train_list)<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb30-118"><a href="#cb30-118" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Median Test MSE over </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> folds: </span><span class="sc">{</span>np<span class="sc">.</span>median(mse_test_list)<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb30-119"><a href="#cb30-119" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Median Train R¬≤ over </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> folds: </span><span class="sc">{</span>np<span class="sc">.</span>median(r2_train_list)<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb30-120"><a href="#cb30-120" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Median Test R¬≤ over </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> folds: </span><span class="sc">{</span>np<span class="sc">.</span>median(r2_test_list)<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb30-121"><a href="#cb30-121" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span>  {</span>
<span id="cb30-122"><a href="#cb30-122" aria-hidden="true" tabindex="-1"></a>        <span class="st">"mse_train"</span>: mse_train_list,</span>
<span id="cb30-123"><a href="#cb30-123" aria-hidden="true" tabindex="-1"></a>        <span class="st">"mse_test"</span>: mse_test_list,</span>
<span id="cb30-124"><a href="#cb30-124" aria-hidden="true" tabindex="-1"></a>        <span class="st">"r2_train"</span>: r2_train_list,</span>
<span id="cb30-125"><a href="#cb30-125" aria-hidden="true" tabindex="-1"></a>        <span class="st">"r2_test"</span>: r2_test_list</span>
<span id="cb30-126"><a href="#cb30-126" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb30-127"><a href="#cb30-127" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>max_iters <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>tolerance <span class="op">=</span> <span class="fl">1e-4</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> k_fold_cross_validation(train, k, alpha, max_iters, tolerance, compute_cost_fn, compute_gradient)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>----------

Fold 1:
Train unique education: ['Bachelor degree' 'Msc' 'PhD' 'BAC']
Test unique education: ['PhD' 'Msc' 'Bachelor degree' 'BAC']
Train unique sex: ['F' 'M']
Test unique sex: ['F' 'M']

Fold 1/5 - Train MSE: 0.00113 | Test MSE: 0.00112
Fold 1/5 - Train RMSE: 0.03362 | Test RMSE: 0.03346
Fold 1/5 - Train R¬≤: 0.99887 | Test R¬≤: 0.99889
----------




----------

Fold 2:
Train unique education: ['PhD' 'Msc' 'Bachelor degree' 'BAC']
Test unique education: ['Bachelor degree' 'Msc' 'PhD' 'BAC']
Train unique sex: ['F' 'M']
Test unique sex: ['F' 'M']

Fold 2/5 - Train MSE: 0.00106 | Test MSE: 0.00099
Fold 2/5 - Train RMSE: 0.03263 | Test RMSE: 0.03142
Fold 2/5 - Train R¬≤: 0.99894 | Test R¬≤: 0.99894
----------




----------

Fold 3:
Train unique education: ['PhD' 'Msc' 'Bachelor degree' 'BAC']
Test unique education: ['Bachelor degree' 'PhD' 'Msc' 'BAC']
Train unique sex: ['F' 'M']
Test unique sex: ['F' 'M']

Fold 3/5 - Train MSE: 0.00090 | Test MSE: 0.00067
Fold 3/5 - Train RMSE: 0.03005 | Test RMSE: 0.02598
Fold 3/5 - Train R¬≤: 0.99910 | Test R¬≤: 0.99932
----------




----------

Fold 4:
Train unique education: ['PhD' 'Msc' 'Bachelor degree' 'BAC']
Test unique education: ['PhD' 'Bachelor degree' 'BAC' 'Msc']
Train unique sex: ['F' 'M']
Test unique sex: ['F' 'M']

Fold 4/5 - Train MSE: 0.00155 | Test MSE: 0.00231
Fold 4/5 - Train RMSE: 0.03941 | Test RMSE: 0.04801
Fold 4/5 - Train R¬≤: 0.99845 | Test R¬≤: 0.99786
----------




----------

Fold 5:
Train unique education: ['PhD' 'Msc' 'Bachelor degree' 'BAC']
Test unique education: ['Msc' 'PhD' 'BAC' 'Bachelor degree']
Train unique sex: ['F' 'M']
Test unique sex: ['F' 'M']

Fold 5/5 - Train MSE: 0.00106 | Test MSE: 0.00100
Fold 5/5 - Train RMSE: 0.03251 | Test RMSE: 0.03157
Fold 5/5 - Train R¬≤: 0.99894 | Test R¬≤: 0.99898
----------





Median Train MSE over 5 folds: 0.00106
Median Test MSE over 5 folds: 0.00100
Median Train R¬≤ over 5 folds: 0.99894
Median Test R¬≤ over 5 folds: 0.99894</code></pre>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;On peut remaquer qu‚Äô√† chaque fold nos modalit√©s sont pr√©sentes et dans les donn√©es de test et dans celles de l‚Äôapprentissage.</p>
<p>La validation crois√©e en 5 plis (K-Fold Cross-Validation) a √©t√© utilis√©e pour √©valuer la performance du mod√®le. Les valeurs ci-dessous correspondent √† la racine carr√©e de la fonction de co√ªt (Root Mean Square Error, RMSE), <strong>calcul√©e sur des donn√©es de sortie standardis√©es</strong>.</p>
<section id="r√©sultats-par-pli-rmse-train-vs-test" class="level3">
<h3 class="anchored" data-anchor-id="r√©sultats-par-pli-rmse-train-vs-test">R√©sultats par pli (RMSE Train vs Test)</h3>
<ul>
<li>‚úÖ Fold 1 :<code>0.03362 vs 0.03346</code></li>
<li>‚úÖ Fold 2 :<code>0.03263 vs 0.03142</code></li>
<li>‚úÖ Fold 3 :<code>0.03005 vs 0.02598</code></li>
<li>‚úÖ Fold 4 :<code>0.03941 vs 0.04801</code></li>
<li>‚úÖ Fold 5 :<code>0.03251 vs 0.03157</code></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dans 4 des 5 folds, le MSE_test ‚â§ MSE_train, ce qui est surprenant mais pas impossible si la validation est bien faite et que les donn√©es sont tr√®s r√©guli√®res.</p>
<p>L‚Äô√©cart est faible dans tous les cas sauf pour le fold 4, o√π :</p>
<p><code>MSE_test</code> = <code>0.00231</code> <strong>&gt;</strong> <code>MSE_train</code> = <code>0.00155</code></p>
<p>Cela sugg√®re un <code>l√©g√®re suradaptation</code> (overfitting) pour ce fold, mais l‚Äô<code>√©cart reste raisonnable</code>.</p>
</section>
<section id="visualisation-de-la-somme-erreurs-quadratiques-par-pli" class="level3">
<h3 class="anchored" data-anchor-id="visualisation-de-la-somme-erreurs-quadratiques-par-pli">Visualisation de la somme erreurs quadratiques par pli</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>mse_train_list <span class="op">=</span> results[<span class="st">'mse_train'</span>]</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>mse_test_list <span class="op">=</span> results[<span class="st">'mse_test'</span>]</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>r2_train_list <span class="op">=</span> results[<span class="st">'r2_train'</span>]</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>r2_test_list <span class="op">=</span> results[<span class="st">'r2_test'</span>]</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>mse_median_train <span class="op">=</span> np.median(mse_train_list)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>mse_median_test <span class="op">=</span> np.median(mse_test_list)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>r2_median_train <span class="op">=</span> np.median(r2_train_list)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>r2_median_test <span class="op">=</span> np.median(r2_test_list)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>folds <span class="op">=</span> np.arange(<span class="dv">1</span>, <span class="dv">6</span>)</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="fl">6.5</span>))</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="co"># --MSE--</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(folds, mse_train_list, label<span class="op">=</span><span class="st">'Train MSE'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(folds, mse_test_list, label<span class="op">=</span><span class="st">'Test MSE'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].axhline(y<span class="op">=</span>mse_median_train, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, label<span class="op">=</span><span class="ss">f'Train Median MSE = </span><span class="sc">{</span>mse_median_train<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].axhline(y<span class="op">=</span>mse_median_test, color<span class="op">=</span><span class="st">'g'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, label<span class="op">=</span><span class="ss">f'Test Median MSE = </span><span class="sc">{</span>mse_median_test<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'MSE per fold'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Fold'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'MSE (standardized scale)'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend(fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].tick_params(axis<span class="op">=</span><span class="st">'both'</span>, which<span class="op">=</span><span class="st">'major'</span>, labelsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a><span class="co"># --R2--</span></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(folds, r2_train_list, label<span class="op">=</span><span class="st">'Train R¬≤'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(folds, r2_test_list, label<span class="op">=</span><span class="st">'Test R¬≤'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].axhline(y<span class="op">=</span>r2_median_train, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, label<span class="op">=</span><span class="ss">f'Train Median R¬≤ = </span><span class="sc">{</span>r2_median_train<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].axhline(y<span class="op">=</span>r2_median_test, color<span class="op">=</span><span class="st">'g'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, label<span class="op">=</span><span class="ss">f'Test Median R¬≤ = </span><span class="sc">{</span>r2_median_test<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'R¬≤ per fold'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Fold'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'R¬≤'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend(fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].tick_params(axis<span class="op">=</span><span class="st">'both'</span>, which<span class="op">=</span><span class="st">'major'</span>, labelsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(left<span class="op">=</span><span class="fl">0.1</span>, wspace<span class="op">=</span><span class="fl">0.25</span>)</span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-rmse-value-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="gradient-descent-linear-reg_files/figure-html/fig-rmse-value-plot-1.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Model Performance Metrics per Fold</figcaption>
</figure>
</div>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Ce graphique pr√©sente les performances d‚Äôun mod√®le √† travers une validation crois√©e √† 5 plis (<strong>5-fold cross-validation</strong>), en utilisant deux m√©triques : <strong>MSE (Mean Squared Error)</strong> et <strong>R¬≤ (coefficient de d√©termination)</strong>.</p>
</section>
<section id="mse-par-pli" class="level3">
<h3 class="anchored" data-anchor-id="mse-par-pli">üìâ MSE par pli</h3>
<ul>
<li><strong>Lignes bleues (Train MSE)</strong> et <strong>lignes orange (Test MSE)</strong> montrent la performance sur les donn√©es d‚Äôentra√Ænement et de test respectivement.</li>
<li>Les performances sont tr√®s similaires entre les diff√©rents plis, avec de <strong>faibles valeurs de MSE</strong>, ce qui indique une bonne qualit√© de pr√©diction.</li>
<li>Une exception est observ√©e pour le pli 4, o√π le <strong>Test MSE</strong> est sensiblement plus √©lev√© (~0.0023), sugg√©rant une possible instabilit√© ou une complexit√© locale non bien captur√©e par le mod√®le.</li>
<li><strong>Lignes horizontales</strong> :
<ul>
<li>üî¥ Rouge pointill√©e : m√©diane du MSE d‚Äôentra√Ænement (‚âà 0.00106)</li>
<li>üü¢ Verte pointill√©e : m√©diane du MSE de test (‚âà 0.00100)</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p><strong>Interpr√©tation</strong> : Le mod√®le g√©n√©ralise bien dans l‚Äôensemble, avec un <strong>l√©ger sur-apprentissage</strong> possible sur le pli 4.</p>
</blockquote>
</section>
<section id="r¬≤-par-pli" class="level3">
<h3 class="anchored" data-anchor-id="r¬≤-par-pli">üìà R¬≤ par pli</h3>
<ul>
<li><p>Le <strong>R¬≤ d‚Äôentra√Ænement</strong> et <strong>de test</strong> est tr√®s √©lev√© pour tous les plis, indiquant que le mod√®le explique <strong>plus de 99.88 %</strong> de la variance des donn√©es.</p></li>
<li><p>Une baisse est observ√©e pour le pli 4 avec un <strong>Test R¬≤ ‚âà 0.9978</strong>, ce qui reste n√©anmoins tr√®s performant.</p></li>
<li><p><strong>Lignes horizontales</strong> :</p>
<ul>
<li>üî¥ Rouge pointill√©e : m√©diane du R¬≤ d‚Äôentra√Ænement (‚âà 0.99894)</li>
<li>üü¢ Verte pointill√©e : m√©diane du R¬≤ de test (‚âà 0.99894)</li>
</ul></li>
</ul>
<hr>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;En somme nous pouvons dirre que :</p>
<ul>
<li><p>Le mod√®le est <strong>tr√®s performant</strong>, avec des <strong>erreurs faibles</strong> et un <strong>pouvoir explicatif √©lev√©</strong> sur l‚Äôensemble des plis.</p></li>
<li><p>Le pli 4 montre une <strong>l√©g√®re instabilit√©</strong>, ce qui pourrait justifier une exploration compl√©mentaire sur les donn√©es de ce pli.</p></li>
<li><p>Dans l‚Äôensemble, les r√©sultats montrent un <strong>excellent compromis biais-variance</strong>, avec une <strong>bonne g√©n√©ralisation</strong>.</p></li>
</ul>
</section>
</section>
<section id="evaluation-du-mod√®le-final-sur-les-donn√©es-de-test" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-du-mod√®le-final-sur-les-donn√©es-de-test">Evaluation du mod√®le final sur les donn√©es de test</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting test features</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> test.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># transforming test features (one hot encodings and standardization)</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>X_test_processed <span class="op">=</span> preprocessor.transform(X<span class="op">=</span>X_test)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co"># predictions on standardized test features</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>y_pred_test_scaled <span class="op">=</span> predict(best[<span class="st">'w'</span>], best[<span class="st">'b'</span>], X_test_processed).reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="co"># reverse scaling</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>y_pred_test <span class="op">=</span> scaler_y.inverse_transform(y_pred_test_scaled).reshape(<span class="dv">200</span>,)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="co"># getting real y and changing the shape</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>y_true_test <span class="op">=</span> test[<span class="st">'salary'</span>].values.reshape(<span class="dv">200</span>,)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Maintenant calculons le <code>RMSE</code> des erreurs commises en pr√©disant. D‚Äôabord essayons de visualiser cela de mani√®re s√©par√©e car il me vient √† l‚Äôid√©e d‚Äôordonner les diff√©rents arrays obtenus, mais avant faut que je sois s√ªre que les salaires r√©els (pas dans le sens √©conomique du terme mais pour dire salaire observ√©) et ceux pr√©dits ont la m√™me allure.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>abs_ <span class="op">=</span> np.arange(<span class="dv">1</span>, <span class="dv">201</span>, <span class="dv">1</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(abs_, y_true_test, c<span class="op">=</span><span class="st">'g'</span>, label<span class="op">=</span><span class="st">'Observed salaries'</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Observed Salaries'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Data points'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Salary'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(abs_, y_pred_test, c<span class="op">=</span><span class="st">'b'</span>, label<span class="op">=</span><span class="st">'Predicted salaries'</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Predicted Salaries'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Data points'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Salary'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-testing-final-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="gradient-descent-linear-reg_files/figure-html/fig-testing-final-plot-3.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;6: Observed Slaries and Predicted Salaries visualisation</figcaption>
</figure>
</div>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;En effet les deux courbe ont pratiquement la m√™me allure, essayons de voir ce que √ßa donne quand on les arrange de mani√®re croissante.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>y_pred_test_sorted <span class="op">=</span> np.sort(y_pred_test)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>y_true_test_sorted <span class="op">=</span> np.sort(y_true_test)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>abs_ <span class="op">=</span> np.arange(<span class="dv">1</span>, <span class="dv">201</span>, <span class="dv">1</span>)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>plt.plot(abs_,y_true_test_sorted , c<span class="op">=</span><span class="st">'g'</span>, label<span class="op">=</span><span class="st">'Observed values of the salary'</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>plt.plot(abs_, y_pred_test_sorted, c<span class="op">=</span><span class="st">'b'</span>,label<span class="op">=</span><span class="st">'Predicted values of the salary'</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Salary'</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Data points'</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-testing-final-sorted-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="gradient-descent-linear-reg_files/figure-html/fig-testing-final-sorted-plot-5.png" style="width:90.0%;height:80.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;7: Observed Slaries VS Predicted Salaries</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Analyse graphique des salaires pr√©dits vs observ√©s
</div>
</div>
<div class="callout-body-container callout-body">
<p>Les courbes des salaires pr√©dits et observ√©s montrent une forte similarit√©.<br>
Cela sugg√®re que le mod√®le est capable de bien capturer la relation entre les variables explicatives et le salaire, indiquant ainsi une <strong>bonne capacit√© de g√©n√©ralisation</strong> sur les donn√©es de test.</p>
</div>
</div>
<ul>
<li><strong>Calcul de la racine de l‚Äôerreur quadratique moyenne</strong></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSE on standardised salaries</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>y_true_test_scaled <span class="op">=</span> scaler_y.transform(y_true_test_).reshape(<span class="dv">200</span>, )</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>rmse_scaled <span class="op">=</span> np.sqrt(np.mean((y_pred_test_scaled <span class="op">-</span> y_true_test_scaled)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"standardized RMSE : </span><span class="sc">{</span>rmse_scaled<span class="sc">:.2f}</span><span class="ch">\n</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>standardized RMSE : 1.38</code></pre>
</div>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSE on original wages</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>rmse_original <span class="op">=</span> np.sqrt(</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">1</span><span class="op">/</span><span class="dv">200</span>)<span class="op">*</span>(y_pred_test <span class="op">-</span> y_true_test).T <span class="op">@</span> (y_pred_test <span class="op">-</span> y_true_test)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"original RMSE : </span><span class="sc">{</span>rmse_original<span class="sc">:.2f}</span><span class="ch">\n</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>original RMSE : 283.96</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled" title="‚ö†Ô∏è Attention √† l‚Äôinterpr√©tation : overfitting ou d√©s√©quilibre ?">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
‚ö†Ô∏è Attention √† l‚Äôinterpr√©tation : overfitting ou d√©s√©quilibre ?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Le fait que la <code>RMSE</code> sur le test soit nettement plus √©lev√©e que celle obtenue en validation crois√©e peut provenir de :</p>
<p>üîÅ Overfitting : le mod√®le a trop appris les sp√©cificit√©s du jeu d‚Äôentra√Ænement (m√™me via cross-validation), et g√©n√©ralise mal (ce qui est moins probable).</p>
<p>‚öñÔ∏è D√©s√©quilibre dans les variables cat√©gorielles : il se peut que la r√©partition des niveaux d‚Äô√©ducation ou des sexes soit diff√©rente entre le train et le test, ce qui fausse l‚Äô√©valuation (Ce qui est plus probable car au debut j‚Äôavais mentionn√© ce soucis).</p>
<p>Il est donc essentiel d‚Äôexaminer les distributions des variables dans chaque ensemble pour comprendre la cause exacte.</p>
<p>üßë‚Äçüè´ Mais rappelons que le but ici n‚Äô√©tait pas de construire le meilleur mod√®le, mais de montrer concr√®tement la mise en ≈ìuvre de l‚Äôalgorithme de descente de gradient en contexte r√©el.</p>
<p>Ce genre d‚Äô√©cart illustre parfaitement pourquoi la g√©n√©ralisation est un d√©fi fondamental en machine learning.</p>
</div>
</div>
<ul>
<li><strong>Interpr√©tation de la RMSE en valeur r√©elle</strong></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Les salaires dans notre dataset varient entre environ <strong>24 933 ‚Ç¨</strong> et <strong>75 318 ‚Ç¨</strong>, ce qui explique qu‚Äôune <code>RMSE</code> d‚Äôenviron <code>284 ‚Ç¨</code> soit coh√©rente.</p>
<p>Pour mieux comprendre ce que signifie cette erreur moyenne, consid√©rons l‚Äô√©chelle des salaires :<br>
la diff√©rence entre le minimum et le maximum est d‚Äôenviron <strong>50 385 ‚Ç¨</strong>.</p>
<p>Ainsi, une <code>RMSE</code> de <code>284 ‚Ç¨</code> correspond √† une erreur moyenne relative d‚Äôenviron :</p>
<p><span class="math display">\[
\frac{284}{50 385} \approx 0.0056 \quad \text{soit} \quad 0{,}56\%
\]</span></p>
<hr>
</section>
<section id="conclusion-g√©n√©rale" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-g√©n√©rale">Conclusion g√©n√©rale</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;En r√©sum√©, la <strong>descente de gradient</strong> s‚Äôest r√©v√©l√©e √™tre un algorithme simple, intuitif et pourtant puissant pour la <strong>minimisation de la fonction de co√ªt</strong> dans le cadre de la r√©gression lin√©aire. En parcourant de mani√®re it√©rative la direction oppos√©e au gradient, l‚Äôalgorithme permet une r√©duction monotone du co√ªt √† chaque it√©ration.</p>
<p>Nous avons vu que ce proc√©d√© consiste √† ajuster les coefficients du mod√®le √† partir d‚Äôun point initial, en effectuant des pas proportionnels au n√©gatif du gradient et calibr√©s par le <strong>taux d‚Äôapprentissage</strong>. Tant que celui-ci est bien choisi (pas trop grand, pas trop petit), la proc√©dure converge vers un minimum local de la fonction de co√ªt. Toutefois, nous avons aussi montr√© que certains cas (comme des ravins √©troits ou des matrices Hessiennes mal conditionn√©es) peuvent ralentir la convergence ou provoquer des oscillations.</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>La faible erreur en euros (300 sur des milliers) sur les donn√©es de test, combin√©e √† une RMSE relativement faible en validation crois√©e, sugg√®re que le mod√®le est bien calibr√© et capable de g√©n√©raliser efficacement. Cependant, l‚Äô√©cart entre l‚Äôentra√Ænement et la validation pourrait indiquer un l√©ger surapprentissage, bien que cet √©cart soit mod√©r√©</strong>.</p>
<section id="points-cl√©s-√†-retenir" class="level3">
<h3 class="anchored" data-anchor-id="points-cl√©s-√†-retenir">Points cl√©s √† retenir</h3>
<ol type="1">
<li><p><strong>Principe de fonctionnement</strong><br>
Le param√®tre <span class="math inline">\(\theta\)</span> est mis √† jour selon <span class="math inline">\(\theta \leftarrow \theta - \gamma \nabla_\theta J(\theta)\)</span>, avec <span class="math inline">\(J\)</span> la fonction de co√ªt et <span class="math inline">\(\alpha\)</span> le pas d‚Äôapprentissage.</p></li>
<li><p><strong>Monotonie et convergence</strong></p>
<p>√Ä chaque √©tape, la valeur du co√ªt d√©cro√Æt (tant que <span class="math inline">\(\alpha\)</span> est convenablement choisie), garantissant la progression vers un minimum local.</p></li>
<li><p><strong>Limites de la m√©thode</strong></p>
<p>La descente de gradient peut rencontrer des difficult√©s de convergence lorsqu‚Äôon affine le minimum dans des zones √©troites ou avec des gradients tr√®s pontuels. D‚Äôautres m√©thodes, comme le <code>gradient conjugu√©</code> ou <code>Newton</code>, peuvent alors offrir un gain en performance.</p></li>
</ol>
<div class="callout callout-style-default callout-warning callout-titled" title="‚ö†Ô∏è Attention : Influence de l'√©chelle des variables explicatives">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
‚ö†Ô∏è Attention : Influence de l‚Äô√©chelle des variables explicatives
</div>
</div>
<div class="callout-body-container callout-body">
<p>Lorsque les variables explicatives ont des √©chelles tr√®s diff√©rentes, cela peut provoquer un comportement non optimal de la descente de gradient.</p>
<p>Par exemple : - Une variable <span class="math inline">\(x_1\)</span> variant entre 0 et 1 - Une autre variable <span class="math inline">\(x_2\)</span> variant entre 10 et 50</p>
<p>Un petit poids <span class="math inline">\(w_2\)</span> associ√© √† <span class="math inline">\(x_2\)</span> peut entra√Æner une variation importante de la pr√©diction, tandis qu‚Äôun poids <span class="math inline">\(w_1\)</span> beaucoup plus grand associ√© √† <span class="math inline">\(x_1\)</span> pourrait n‚Äôavoir qu‚Äôun effet marginal.</p>
<p><strong>Cons√©quences :</strong> - La surface de la fonction de co√ªt est tr√®s √©tir√©e dans certaines directions. - La descente de gradient progresse tr√®s lentement, zigzague ou peut ne jamais converger. - Le nombre d‚Äôit√©rations n√©cessaires augmente fortement.</p>
<p>üëâ C‚Äôest pourquoi <strong>la normalisation des variables</strong> (standardisation ou min-max scaling) est une √©tape cruciale avant d‚Äôentra√Æner un mod√®le lin√©aire avec descente de gradient.</p>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
‚ö†Ô∏è Important : <code>fit_transform()</code> vs <code>transform()</code>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Toujours utiliser <code>fit_transform()</code> <strong>uniquement sur les donn√©es d‚Äôentra√Ænement</strong>, et <code>transform()</code> sur les donn√©es de validation ou de test.</p>
<p>Cela s‚Äôapplique √† <strong>tous les types de preprocessing</strong>, notamment :</p>
<ul>
<li>üü¶ <strong>StandardScaler</strong> : la moyenne et l‚Äô√©cart-type doivent √™tre appris sur le <em>train</em> uniquement.</li>
<li>üüß <strong>OneHotEncoder</strong> : les cat√©gories doivent √™tre identifi√©es √† partir du <em>train</em> et appliqu√©es de mani√®re coh√©rente au <em>test</em>.</li>
</ul>
<p>‚ùå Ne jamais faire <code>fit_transform()</code> sur le test, car cela introduit du <strong>data leakage</strong> (les donn√©es de test influencent le mod√®le).</p>
</div>
</div>
</section>
<section id="perspectives" class="level3">
<h3 class="anchored" data-anchor-id="perspectives">Perspectives</h3>
<ul>
<li><p><strong>Am√©lioration du pas (<span class="math inline">\(\gamma\)</span>)</strong> : l‚Äôusage d‚Äôun pas adaptatif ou de sch√©mas comme l‚Äôapprentissage d√©croissant peut am√©liorer la rapidit√© et la robustesse de la convergence.</p></li>
<li><p><strong>Extensions avanc√©es</strong> : l‚Äôajout de r√©gularisation (comme Ridge ou Lasso) ou le passage √† des variantes stochastiques (SGD) ou mini-batch permet de g√©n√©raliser la m√©thode √† des ensembles plus volumineux et √† la mod√©lisation en profondeur.</p></li>
<li><p><strong>Combinaison avec d‚Äôautres algorithmes</strong> : pour pallier les inefficacit√©s, on peut int√©grer des techniques comme le momentum, AdaGrad, RMSprop ou Adam, qui corr√©lent le gradient pour acc√©l√©rer la convergence et stabiliser l‚Äôapprentissage.</p></li>
</ul>
</section>
<section id="finalement" class="level3">
<h3 class="anchored" data-anchor-id="finalement">Finalement</h3>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;La descente de gradient traduit √©l√©gamment les principes fondamentaux de l‚Äô<strong>optimisation it√©rative</strong> : √† chaque √©tape, un petit ajustement calcul√© √©loigne le mod√®le de l‚Äôerreur, jusqu‚Äô√† atteindre la valeur optimale des param√®tres (). M√™me si elle n‚Äôest pas sans d√©fauts, cette m√©thode demeure une <strong>brique essentielle</strong> en apprentissage automatique, particuli√®rement en r√©gression lin√©aire, et sert de base √† des m√©thodes plus sophistiqu√©es.</p>
<hr>
</section>
</section>
<section id="remerciements-et-retour-dexp√©rience" class="level2">
<h2 class="anchored" data-anchor-id="remerciements-et-retour-dexp√©rience">Remerciements et retour d‚Äôexp√©rience</h2>
<p>J‚Äôai √©t√© ravi d‚Äôavoir consacr√© pr√®s de <strong>20 heures</strong> √† la pr√©paration et √† la r√©daction de cette publication.</p>
<p>Cet effort m‚Äôa permis de :</p>
<ul>
<li>consolider mes acquis en <strong>Python</strong>,<br>
</li>
<li>approfondir mes connaissances en <strong>Machine Learning</strong>, tant sur le plan <strong>th√©orique que pratique</strong>,<br>
</li>
<li>renforcer ma <strong>rigueur m√©thodologique</strong> dans le traitement des donn√©es, l‚Äôexp√©rimentation et l‚Äôanalyse des r√©sultats.</li>
</ul>
<p>Ce projet m‚Äôa √©galement offert une excellente opportunit√© de structurer une d√©marche compl√®te de mod√©lisation, depuis la g√©n√©ration des donn√©es jusqu‚Äô√† l‚Äôinterpr√©tation finale des performances du mod√®le.</p>
<p>Je suis enthousiaste √† l‚Äôid√©e de poursuivre cette exploration dans de futures publications de ce genre (travailler √† la mano), notamment sur des cas r√©els avec des mod√®les plus avanc√©s comme la <strong>r√©gression logistique</strong> ou des approches <strong>r√©gularis√©es</strong>.</p>
<p>Mon cours d‚Äôoptimisation et de m√©thode de calcul num√©riques m‚Äôa √©t√© d‚Äôune grande utilit√© en 1A √† l‚ÄôENSAI.</p>
<hr>
</section>
<section id="annexes" class="level2">
<h2 class="anchored" data-anchor-id="annexes">Annexes</h2>
<section id="standardisation-des-variables" class="level3">
<h3 class="anchored" data-anchor-id="standardisation-des-variables">1. Standardisation des variables</h3>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;La <strong>standardisation</strong> permet de centrer et r√©duire les variables num√©riques pour qu‚Äôelles aient une moyenne nulle et un √©cart-type unitaire.</p>
<p>Pour une variable continue <span class="math inline">\(x\)</span>, la standardisation est donn√©e par :</p>
<p><span class="math display">\[
x_{\text{std}} = \frac{x - \mu_x}{\sigma_x}
\]</span></p>
<p>o√π :</p>
<ul>
<li><span class="math inline">\(\mu_x = \dfrac{1}{n} \sum_{i=1}^n x_i\)</span> est la moyenne,</li>
<li><span class="math inline">\(\sigma_x = \sqrt{\dfrac{1}{n} \sum_{i=1}^n (x_i - \mu_x)^2}\)</span> est l‚Äô√©cart-type.</li>
</ul>
<p>Apr√®s avoir entra√Æn√© le mod√®le sur les donn√©es standardis√©es, on peut revenir √† l‚Äô√©chelle r√©elle avec :</p>
<p><span class="math display">\[
\hat{y} = \hat{y}_{\text{std}} \cdot \sigma_y + \mu_y
\]</span></p>
<p>o√π <span class="math inline">\(\mu_y\)</span> et <span class="math inline">\(\sigma_y\)</span> sont la moyenne et l‚Äô√©cart-type de la variable cible <span class="math inline">\(y\)</span>.</p>
<hr>
</section>
<section id="codage-one-hot" class="level3">
<h3 class="anchored" data-anchor-id="codage-one-hot">2. Codage One-Hot</h3>
<p>Le <strong>One-Hot Encoding</strong> transforme une variable cat√©gorielle √† <span class="math inline">\(k\)</span> modalit√©s en <span class="math inline">\(k\)</span> colonnes binaires.</p>
<p>Soit une variable cat√©gorielle :</p>
<p><span class="math display">\[
\text{cat} \in \{c_1, c_2, \ldots, c_k\}
\]</span></p>
<p>On cr√©e un vecteur :</p>
<p><span class="math display">\[
\mathbf{v} = (v_1, v_2, \ldots, v_k) \quad \text{o√π} \quad
v_j =
\begin{cases}
1 &amp; \text{si } \text{cat} = c_j \\
0 &amp; \text{sinon}
\end{cases}
\]</span></p>
<p>Afin d‚Äô√©viter la redondance, on supprime une modalit√© (ex. via <code>drop='first'</code>) pour √©viter le pi√®ge des variables muettes (dummy variable trap).</p>
<hr>
</section>
<section id="calcul-de-la-rmse" class="level3">
<h3 class="anchored" data-anchor-id="calcul-de-la-rmse">3. Calcul de la RMSE</h3>
<p>La <strong>Root Mean Square Error</strong> (RMSE) mesure l‚Äô√©cart quadratique moyen entre les valeurs pr√©dites <span class="math inline">\(\hat{y}_i\)</span> et observ√©es <span class="math inline">\(y_i\)</span> :</p>
<p><span class="math display">\[
\text{RMSE} = \sqrt{ \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2 }
\]</span></p>
<p>En notation vectorielle, si <span class="math inline">\(\mathbf{y}\)</span> est le vecteur des valeurs observ√©es et <span class="math inline">\(\hat{\mathbf{y}}\)</span> celui des valeurs pr√©dites :</p>
<p><span class="math display">\[
\text{RMSE} = \sqrt{ \frac{1}{n} (\mathbf{y} - \hat{\mathbf{y}})^T (\mathbf{y} - \hat{\mathbf{y}}) }
\]</span></p>
<p>Cette m√©trique est exprim√©e dans l‚Äôunit√© de la variable cible (ici, les euros), ce qui la rend facile √† interpr√©ter dans un contexte r√©el.</p>
<hr>
<p>Ces op√©rations sont fondamentales dans toute pipeline de traitement pour la r√©gression ou tout autre algorithme supervis√©.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>