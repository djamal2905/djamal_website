<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Djamal TOE">
<meta name="dcterms.date" content="2025-05-20">

<title>DJAMAL WEBSITE - ShiFuMi IA â€“ Reconnaissance de gestes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../site_libs/quarto-contrib/videojs/video.min.js"></script>
<link href="../site_libs/quarto-contrib/videojs/video-js.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="index.qmd" class="navbar-brand navbar-brand-logo">
    <img src="../images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="index.qmd">
    <span class="navbar-title">DJAMAL WEBSITE</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-statistics--machine-learning" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Statistics &amp; Machine Learning</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-statistics--machine-learning">    
        <li>
    <a class="dropdown-item" href="../projet-traitement-donnees/report_writing/synthese-des-travaux.html" rel="" target="">
 <span class="dropdown-text">PrÃ©dire la durÃ©e de carriÃ¨re des joueurs NBA</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../FORMATIONS/logistic_regression_diabetes.html" rel="" target="">
 <span class="dropdown-text">ModÃ©lisation des donnÃ©es Ã  variables dÃ©pendantes binaires</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../INFO_MINI_PROJETS/brain-tumor-classification-effcientnet.html" rel="" target="">
 <span class="dropdown-text">Classification des tumeurs cÃ©rÃ©brales Ã  partir dâ€™IRM par Apprentissage profond</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../FORMATIONS/poisson_paludisme.html" rel="" target="">
 <span class="dropdown-text">ModÃ©lisation des donnÃ©es de comptage</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ANALYSES_FACTORIELLES/acp-kmeans.html" rel="" target="">
 <span class="dropdown-text">Reduction de dimensionnalitÃ© et clustering non supervisÃ©</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../INFO_MINI_PROJETS/classi_bin_acp_kmeans_knn_logit/work.html" rel="" target="">
 <span class="dropdown-text">ACP, Kmeans, KNN et Logistique au service des donnÃ©es mÃ©dicales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../INFO_MINI_PROJETS/shifumi-cnn-yolov8.html" rel="" target="">
 <span class="dropdown-text">Classification des gestes de la main avec Yolo et CNN</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-programming" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Programming</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-programming">    
        <li>
    <a class="dropdown-item" href="../INFO_MINI_PROJETS/assistant_virtuel.html" rel="" target="">
 <span class="dropdown-text">CrÃ©e ton assistant virtuel avec pyhton</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../INFO_MINI_PROJETS/JavaApp/desktop-app-java-mysql.html" rel="" target="">
 <span class="dropdown-text">Application desktop avec Java et Mysql</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">About me</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://www.linkedin.com/in/djamal-toe-7a18432b0" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text">LinkedIn</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#contexte" id="toc-contexte" class="nav-link active" data-scroll-target="#contexte">ğŸ¯ Contexte</a></li>
  <li><a href="#objectif-technique" id="toc-objectif-technique" class="nav-link" data-scroll-target="#objectif-technique">ğŸ§  Objectif technique</a></li>
  <li><a href="#donnÃ©es-pour-le-cnn" id="toc-donnÃ©es-pour-le-cnn" class="nav-link" data-scroll-target="#donnÃ©es-pour-le-cnn">âš™ï¸ DonnÃ©es pour le CNN</a></li>
  <li><a href="#donnÃ©es-pour-yolov8" id="toc-donnÃ©es-pour-yolov8" class="nav-link" data-scroll-target="#donnÃ©es-pour-yolov8">âš™ï¸ DonnÃ©es pour yolov8</a></li>
  <li><a href="#donnÃ©es-dentraÃ®nement-pour-yolov8" id="toc-donnÃ©es-dentraÃ®nement-pour-yolov8" class="nav-link" data-scroll-target="#donnÃ©es-dentraÃ®nement-pour-yolov8">ğŸ”® DonnÃ©es dâ€™entraÃ®nement pour YOLOv8</a>
  <ul class="collapse">
  <li><a href="#pourquoi-entraÃ®ner-yolov8" id="toc-pourquoi-entraÃ®ner-yolov8" class="nav-link" data-scroll-target="#pourquoi-entraÃ®ner-yolov8">ğŸ¤” Pourquoi entraÃ®ner YOLOv8 ?</a></li>
  <li><a href="#structure-des-donnÃ©es-yolo" id="toc-structure-des-donnÃ©es-yolo" class="nav-link" data-scroll-target="#structure-des-donnÃ©es-yolo">ğŸ“š Structure des donnÃ©es YOLO</a></li>
  <li><a href="#entraÃ®nement-avec-ultralytics-exemple" id="toc-entraÃ®nement-avec-ultralytics-exemple" class="nav-link" data-scroll-target="#entraÃ®nement-avec-ultralytics-exemple">ğŸš€ EntraÃ®nement avec Ultralytics (Exemple)</a></li>
  </ul></li>
  <li><a href="#premiers-rÃ©sultats-entrainement-du-cnn" id="toc-premiers-rÃ©sultats-entrainement-du-cnn" class="nav-link" data-scroll-target="#premiers-rÃ©sultats-entrainement-du-cnn">Premiers rÃ©sultats (entrainement du CNN)</a>
  <ul class="collapse">
  <li><a href="#entraÃ®nement-du-modÃ¨le-yolo-epochs33100" id="toc-entraÃ®nement-du-modÃ¨le-yolo-epochs33100" class="nav-link" data-scroll-target="#entraÃ®nement-du-modÃ¨le-yolo-epochs33100">EntraÃ®nement du modÃ¨le YOLO (Epochs=33/100)</a></li>
  <li><a href="#entraÃ®nement-du-modÃ¨le-cnn" id="toc-entraÃ®nement-du-modÃ¨le-cnn" class="nav-link" data-scroll-target="#entraÃ®nement-du-modÃ¨le-cnn">EntraÃ®nement du modÃ¨le CNN</a></li>
  </ul></li>
  <li><a href="#annexes-1-cnn---entraÃ®nement-et-validation" id="toc-annexes-1-cnn---entraÃ®nement-et-validation" class="nav-link" data-scroll-target="#annexes-1-cnn---entraÃ®nement-et-validation">Annexes 1 : CNN - entraÃ®nement et validation</a></li>
  <li><a href="#annexe-2-map" id="toc-annexe-2-map" class="nav-link" data-scroll-target="#annexe-2-map">Annexe 2 : MAP</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">ShiFuMi IA â€“ Reconnaissance de gestes</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Djamal TOE </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 20, 2025</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="contexte" class="level1">
<h1>ğŸ¯ Contexte</h1>
<p>Ce projet vise Ã  crÃ©er une intelligence artificielle capable de jouer au jeu <strong>ShiFuMi</strong> (<em>pierre-papier-ciseaux</em>) contre un humain. Lâ€™objectif est de reconnaÃ®tre automatiquement les gestes dâ€™une main via une <strong>webcam</strong>, et de rÃ©pondre en temps rÃ©el. Ce prototype est dÃ©veloppÃ© <strong>seul</strong>, en utilisant les outils suivants :</p>
<ul>
<li><strong>CNN prÃ©-entraÃ®nÃ© (MobileNetV2)</strong> pour classifier les images de mains,</li>
<li><strong>TensorFlow/Keras</strong> pour lâ€™entraÃ®nement,</li>
<li><strong>YOLOv8</strong> (en prÃ©paration) pour la dÃ©tection en direct via webcam,</li>
</ul>
<hr>
</section>
<section id="objectif-technique" class="level1">
<h1>ğŸ§  Objectif technique</h1>
<ul>
<li>CrÃ©er un modÃ¨le de <strong>classification dâ€™images</strong> pour reconnaÃ®tre trois gestes : <code>pierre</code>, <code>papier</code>, <code>ciseaux</code>,</li>
<li>Utiliser un modÃ¨le lÃ©ger et rapide adaptÃ© Ã  la webcam : <strong>MobileNetV2</strong>,</li>
<li>PrÃ©parer lâ€™intÃ©gration en live avec <strong>dÃ©tection par YOLOv8</strong> + <strong>reconnaissance par CNN</strong>.</li>
</ul>
<hr>
</section>
<section id="donnÃ©es-pour-le-cnn" class="level1">
<h1>âš™ï¸ DonnÃ©es pour le CNN</h1>
<p>Les images sont triÃ©es dans des dossiers selon leur classe :</p>
<pre class="rmd"><code>dataset/
â”œâ”€â”€ paper
|   â”œâ”€â”€ train
â”‚   â””â”€â”€ val
â”œâ”€â”€ rock/
|   â”œâ”€â”€ train
â”‚   â””â”€â”€ val
â”œâ”€â”€ scissors/
|   â”œâ”€â”€ train
â”‚   â””â”€â”€ val</code></pre>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Ici je ne fais pas de test mais au cours de lâ€™entrainement jâ€™Ã©value le modÃ¨le avec les images du dossier <code>val</code>. NÃ©anmoins il est important de crÃ©er un dossier test qui va servir de test aprÃ¨s lâ€™entraienement du modÃ¨le. Les donnÃ©es Ã©taient disponibles publiquement sur <code>Kaggle</code>, issues de diffÃ©rentes sources ouvertes. Etant volumineuses, je ne pourrai pas les mettre sur le dÃ©pot <code>git public</code>. Parcontre les <code>notebook</code> et les <code>script .py</code> y seront.</p>
</section>
<section id="donnÃ©es-pour-yolov8" class="level1">
<h1>âš™ï¸ DonnÃ©es pour yolov8</h1>
<p>Les donnÃ©es pour lâ€™entrainement du modÃ¨le <code>yolov8</code> proviennent de la plateforme <code>ROBOT FLOW</code>. Lâ€™idÃ©e derriÃ¨re le fait dâ€™entraÃ®ner le modÃ¨le <code>YOLO</code> vient du fait que je veux pouvoir detecter les mains dans une images et ensuite les passer au modÃ¨le <code>CNN</code> pour la classification. | La structure des donnÃ©es <code>YOLO</code> est un peu particuliÃ¨re. En effet, elle a bÃ©soin dâ€™images mais pas que, il faut quâ€™elles soient <strong>annontÃ©es</strong>. De maniÃ¨re claire, il faut en plus des images, les labels qui lui sont associÃ©s (coordonnÃ©es des images).</p>
</section>
<section id="donnÃ©es-dentraÃ®nement-pour-yolov8" class="level1">
<h1>ğŸ”® DonnÃ©es dâ€™entraÃ®nement pour YOLOv8</h1>
<p>Les donnÃ©es utilisÃ©es pour entraÃ®ner le modÃ¨le <strong>YOLOv8</strong> proviennent de la plateforme <strong><a href="https://robotflow.ai">Robot Flow</a></strong>. Cette plateforme propose une interface conviviale pour la collecte et lâ€™annotation de donnÃ©es, ce qui en fait un outil idÃ©al pour les projets de vision par ordinateur.</p>
<section id="pourquoi-entraÃ®ner-yolov8" class="level2">
<h2 class="anchored" data-anchor-id="pourquoi-entraÃ®ner-yolov8">ğŸ¤” Pourquoi entraÃ®ner YOLOv8 ?</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Lâ€™objectif principal de lâ€™entraÃ®nement de ce modÃ¨le est de <strong>dÃ©tecter les mains</strong> dans des images issues dâ€™une webcam ou dâ€™une vidÃ©o. Cette dÃ©tection constitue une premiÃ¨re Ã©tape essentielle avant de transmettre la rÃ©gion dâ€™intÃ©rÃªt (ROI), câ€™est-Ã -dire la main dÃ©tectÃ©eÃ  un modÃ¨le <strong>CNN</strong> pour effectuer la <strong>classification du geste</strong> (pierre, feuille, ciseaux).</p>
<p>Cette stratÃ©gie en deux Ã©tapes permet de :</p>
<ul>
<li>RÃ©duire le bruit visuel autour de la main (fond, visage, objets parasites)</li>
<li>Augmenter la prÃ©cision du classifieur <code>CNN</code> en se concentrant uniquement sur la main</li>
</ul>
</section>
<section id="structure-des-donnÃ©es-yolo" class="level2">
<h2 class="anchored" data-anchor-id="structure-des-donnÃ©es-yolo">ğŸ“š Structure des donnÃ©es YOLO</h2>
<p>Le format dâ€™attente de <code>YOLO</code> est spÃ©cifique : chaque image dâ€™entraÃ®nement doit Ãªtre accompagnÃ©e dâ€™un <strong>fichier dâ€™annotation <code>.txt</code></strong> contenant les informations de localisation des objets (ici, la main).</p>
<p>Lâ€™organisation des donnÃ©es se prÃ©sente gÃ©nÃ©ralement ainsi :</p>
<pre class="rmd"><code>datasets/yolo_hand/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ img_001.jpg
â”‚   â”‚   â”œâ”€â”€ img_002.jpg
â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ img_101.jpg
â”‚       â”œâ”€â”€ img_102.jpg
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ img_001.txt
â”‚   â”‚   â”œâ”€â”€ img_002.txt
â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ img_101.txt
â”‚       â”œâ”€â”€ img_102.txt</code></pre>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Chaque fichier <code>.txt</code> contient une ou plusieurs lignes correspondant aux objets dÃ©tectÃ©s dans lâ€™image, selon le format suivant :</p>
<pre><code>&lt;class_id&gt; &lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</code></pre>
<ul>
<li>Toutes les valeurs sont <strong>normalisÃ©es</strong> entre 0 et 1 relativement Ã  la taille de lâ€™image.</li>
<li><code>class_id</code> correspond ici Ã  la main, donc souvent 0 dans le cadre dâ€™un problÃ¨me mono-classe.</li>
</ul>
</section>
<section id="entraÃ®nement-avec-ultralytics-exemple" class="level2">
<h2 class="anchored" data-anchor-id="entraÃ®nement-avec-ultralytics-exemple">ğŸš€ EntraÃ®nement avec Ultralytics (Exemple)</h2>
<p>Pour entraÃ®ner le modÃ¨le YOLOv8, on utilise la commande suivante :</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">yolo</span> task=detect mode=train <span class="dt">\</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  model=yolov8n.pt <span class="dt">\</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  data=config.yaml <span class="dt">\</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  epochs=50 <span class="dt">\</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  imgsz=640</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>OÃ¹ le fichier <code>config.yaml</code> contient :</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">path</span><span class="kw">:</span><span class="at"> datasets/yolo_hand</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">train</span><span class="kw">:</span><span class="at"> images/train</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">val</span><span class="kw">:</span><span class="at"> images/val</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span><span class="kw">:</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">0</span><span class="kw">:</span><span class="at"> main</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="wolframalfa" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pourquoi le notebook nâ€™est pas publiÃ© ?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Lâ€™outil de dÃ©vÃ©loppement du site ne supporte pas la bibliothÃ¨que <code>tensorflow</code>, du coup cela rend impossible le dÃ©ploiement du site car lâ€™exÃ©cution des code du notebook ne passe pas. Toutefois, une fois les <code>notebooks</code> et <code>scripts</code> entiÃ¨rement mis au propres, je les mettrai Ã  disposition sur un dÃ©pot public <code>github</code>. Neanmoins Ã©tant donnÃ© que les donnÃ©es ne mâ€™appartiennent pas et que je nâ€™ai plus en ma possession certains liens directs vers celles-ci, elle ne seront pas publiÃ©es. Parcontre la structure des repertoires sera donnÃ©e.</p>
</div>
</div>
</section>
</section>
<section id="premiers-rÃ©sultats-entrainement-du-cnn" class="level1">
<h1>Premiers rÃ©sultats (entrainement du CNN)</h1>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Au lieu de partir de zÃ©ro pour lâ€™entraÃ®nement du modÃ¨le, jâ€™ai prÃ©fÃ©rÃ© utiliser un modÃ¨le dÃ©jÃ  prÃ©entraÃ®nÃ© afin dâ€™amÃ©liorer la prÃ©cision et accÃ©lÃ©rer la convergence. A cet effet jâ€™ai lancÃ© lâ€™entrainement avec <code>20 itÃ©rations</code>. Cependant, il est important de souligner que le fait dâ€™utiliser un modÃ¨le prÃ©entraÃ®nÃ© ne signifie pas que celui-ci peut directement classifier correctement les gestes de la main sans un entraÃ®nement spÃ©cifique sur le jeu de donnÃ©es (tÃ©lÃ©chargÃ© sur kaggle).</p>
<p>En effet, le modÃ¨le prÃ©entraÃ®nÃ©, ici <code>MobileNetV2</code>, a Ã©tÃ© initialement entraÃ®nÃ© sur une large base dâ€™images gÃ©nÃ©riques (ImageNet) et connaÃ®t bien les caractÃ©ristiques gÃ©nÃ©rales des images, comme les formes et les textures. Mais pour reconnaÃ®tre prÃ©cisÃ©ment des gestes spÃ©cifiques (pierre, papier, ciseaux), il faut le reformer (<code>fine-tuning</code><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>) avec mes images annotÃ©es.</p>
<p>En dâ€™autres termes, au lieu de dÃ©marrer lâ€™entraÃ®nement dâ€™un rÃ©seau de neurones Ã  partir de zÃ©ro (ce qui nÃ©cessite beaucoup de donnÃ©es et de temps), on part dâ€™un modÃ¨le qui connaÃ®t dÃ©jÃ  des caractÃ©ristiques gÃ©nÃ©rales (par exemple, dÃ©tecter des formes, des textures, des couleurs). Ensuite, on â€œajusteâ€ ou â€œaffineâ€ ce modÃ¨le en lui apprenant Ã  reconnaÃ®tre des classes plus spÃ©cifiques, comme ici les gestes de la main (pierre, feuille, ciseaux).</p>
<blockquote class="blockquote">
<p>RÃ©sultats obtenus</p>
</blockquote>
<ul>
<li><p><strong>PrÃ©cision sur les donnÃ©es dâ€™entraÃ®nement et de validation</strong> : aprÃ¨s quelques epochs, le modÃ¨le atteint une bonne exactitude (<code>accuracy rate</code>) (99%), ce qui indique quâ€™il a bien appris Ã  diffÃ©rencier les classes sur mes images.</p></li>
<li><p><strong>Sur-apprentissage (overfitting) :</strong> grÃ¢ce Ã  lâ€™utilisation de techniques comme la rÃ©gularisation et lâ€™augmentation des donnÃ©es (data augmentation), jâ€™ai limitÃ© le sur-apprentissage, ce qui permet au modÃ¨le de mieux gÃ©nÃ©raliser sur de nouvelles images.</p></li>
<li><p><strong>Limites Ã©ventuelles</strong> : malgrÃ© ces rÃ©sultats encourageants, la classification en conditions rÃ©elles (ex. en direct via webcam) peut Ãªtre plus complexe en raison des variations dâ€™Ã©clairage, de position des mains, et du fond. Etant donnÃ©e quâ€™Ã  ce stade, lâ€™entraÃ®nement du modÃ¨le <code>YOLO</code> nâ€™est pas encore terminÃ© je ne peux pas me prononcer avec certiude sur ces limites.</p></li>
</ul>
<blockquote class="blockquote">
<p>Test des rÃ©sultats obtenus</p>
</blockquote>
<section id="entraÃ®nement-du-modÃ¨le-yolo-epochs33100" class="level2">
<h2 class="anchored" data-anchor-id="entraÃ®nement-du-modÃ¨le-yolo-epochs33100">EntraÃ®nement du modÃ¨le YOLO (Epochs=33/100)</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Etant donnÃ© que le modÃ¨le Ã©tait entrainÃ© local et du fait quâ€™il mettait du temps, jâ€™ai volontairement stoppÃ© lâ€™entraÃ®nement Ã  la 33-iÃ¨me itÃ©ration. Car Ã  ce stade les rÃ©sultats de la dÃ©tections des mains Ã©taient satisfaisants (<strong>MAP</strong><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> environ Ã©gale Ã  0,94). Voici un extrait du rÃ©sultat :</p>
<div class="quarto-video"><video id="video_shortcode_videojs_video1" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="https://djamal2905.github.io/djamal_website/INFO_MINI_PROJETS/results_cnn_shifumi/yolo.mp4"></video></div>
</section>
<section id="entraÃ®nement-du-modÃ¨le-cnn" class="level2">
<h2 class="anchored" data-anchor-id="entraÃ®nement-du-modÃ¨le-cnn">EntraÃ®nement du modÃ¨le CNN</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Une fois le modÃ¨le <code>YOLO</code> prÃªt Ã  detecter les mains dans une image, le <code>boxe</code> (pour dire le cadre/rectangle contenant la main) est envoyÃ© au modÃ¨le <code>CNN</code> afin quâ€™il puisse classer la main parmis les trois gestes : <code>paper</code> pour <strong><em>papier</em></strong>, <code>rock</code> pour <strong><em>pierre</em></strong> et <code>scissors</code> pour <strong><em>ciseau</em></strong>.</p>
<p>La vidÃ©o ci-aprÃ¨s illustre le rÃ©sultat.</p>
<div class="quarto-video"><video id="video_shortcode_videojs_video2" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="https://djamal2905.github.io/djamal_website/INFO_MINI_PROJETS/results_cnn_shifumi/cnn.mp4"></video></div>
</section>
</section>
<section id="annexes-1-cnn---entraÃ®nement-et-validation" class="level1">
<h1>Annexes 1 : CNN - entraÃ®nement et validation</h1>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="shifumi-cnn-yolov8_files/figure-html/hh-1.png" class="img-fluid figure-img" width="960"></p>
<figcaption class="figure-caption">Ã‰volution de la prÃ©cision et de la perte sur les donnÃ©es de validation</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="annexe-2-map" class="level1">
<h1>Annexe 2 : MAP</h1>
<p>La MAP (<strong>Mean Average Precision</strong>) : Câ€™est la mÃ©trique principale utilisÃ©e pour Ã©valuer les performances dâ€™un modÃ¨le de dÃ©tection comme <code>YOLO</code>. <strong>PrÃ©cision (Precision)</strong></p>
<p>La prÃ©cision indique combien de prÃ©dictions faites par le modÃ¨le sont <em>correctes</em>.</p>
<p><span class="math display">\[
\text{PrÃ©cision} = \frac{\text{Vrais positifs}}{\text{Vrais positifs} + \text{Faux positifs}}
\]</span></p>
<ul>
<li><strong>Rappel (Recall)</strong></li>
</ul>
<p>Le rappel indique combien dâ€™objets rÃ©els ont Ã©tÃ© <em>correctement dÃ©tectÃ©s</em>.</p>
<p><span class="math display">\[
\text{Rappel} = \frac{\text{Vrais positifs}}{\text{Vrais positifs} + \text{Faux nÃ©gatifs}}
\]</span></p>
<ul>
<li><strong>AP : Average Precision</strong></li>
</ul>
<p>Lâ€™<em>AP (Average Precision)</em> est la <em>moyenne</em> de la prÃ©cision Ã  diffÃ©rents niveaux de rappel pour <em>une seule classe dâ€™objet</em>.</p>
<ul>
<li><strong>mAP : mean Average Precision</strong></li>
</ul>
<p>Le <em>mAP</em> est la moyenne des <em>AP</em> pour <em>toutes les classes</em>. Si le modÃ¨le dÃ©tecte plusieurs objets (main, poing, doigt pointÃ©), on calcule lâ€™AP pour chacune, puis on fait la moyenne.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Le fine-tuning est une technique dâ€™apprentissage supervisÃ© qui consiste Ã  prendre un modÃ¨le prÃ©entraÃ®nÃ© sur un grand jeu de donnÃ©es gÃ©nÃ©ral (comme <code>ImageNet</code>) et Ã  le rÃ©entraÃ®ner sur un jeu de donnÃ©es spÃ©cifique Ã  un problÃ¨me particulier.<a href="#fnref1" class="footnote-back" role="doc-backlink">â†©ï¸</a></p></li>
<li id="fn2"><p><strong>Mean Average Precision</strong> : Câ€™est la mÃ©trique principale utilisÃ©e pour Ã©valuer les performances dâ€™un modÃ¨le de dÃ©tection comme <code>YOLO</code>. <strong>PrÃ©cision (Precision)</strong><a href="#fnref2" class="footnote-back" role="doc-backlink">â†©ï¸</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>videojs(video_shortcode_videojs_video1);</script>
<script>videojs(video_shortcode_videojs_video2);</script>



</body></html>