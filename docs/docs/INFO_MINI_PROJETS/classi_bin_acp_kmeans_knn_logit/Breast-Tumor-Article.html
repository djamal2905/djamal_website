<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Djamal TOE">
<meta name="dcterms.date" content="2025-06-12">

<title>DJAMAL WEBSITE - Analyse statistique et apprentissage automatique pour la classification des tumeurs mammaires : étude de la régression logistique suivie d’une comparaison entre modèles logit et KNN</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<script src="../../../site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="../../../site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="index.qmd" class="navbar-brand navbar-brand-logo">
    <img src="../../../images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="index.qmd">
    <span class="navbar-title">DJAMAL WEBSITE</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-statistics--machine-learning" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Statistics &amp; Machine Learning</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-statistics--machine-learning">    
        <li>
    <a class="dropdown-item" href="../../../INFO_MINI_PROJETS/classi_bin_acp_kmeans_knn_logit/Breast-Tumor-Article.html" rel="" target="">
 <span class="dropdown-text">Diagnostic assisté par ACP et régression logistique</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../INFO_MINI_PROJETS/brain-tumor-classification-effcientnet.html" rel="" target="">
 <span class="dropdown-text">Diagnostic tumeurs cérébrales - Reseau de neurones</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../ANALYSES_FACTORIELLES/acp-kmeans.html" rel="" target="">
 <span class="dropdown-text">Reduction de dimensionnalité et clustering non supervisé</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../FORMATIONS/logistic_regression_diabetes.html" rel="" target="">
 <span class="dropdown-text">Modélisation des données à variables dépendantes binaires</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../projet-traitement-donnees/report_writing/synthese-des-travaux.html" rel="" target="">
 <span class="dropdown-text">Prédire la durée de carrière des joueurs NBA</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../INFO_MINI_PROJETS/anomaly-detection-in-transactions-GMM.html" rel="" target="">
 <span class="dropdown-text">Détection d’anomalies dans les transactions à l’aide de modèles de mélange gaussien</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../FORMATIONS/poisson_paludisme.html" rel="" target="">
 <span class="dropdown-text">Modélisation des données de comptage</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../INFO_MINI_PROJETS/shifumi-cnn-yolov8.html" rel="" target="">
 <span class="dropdown-text">Classification des gestes de la main avec Yolo et CNN</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-programming" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Programming</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-programming">    
        <li>
    <a class="dropdown-item" href="../../../INFO_MINI_PROJETS/assistant_virtuel.html" rel="" target="">
 <span class="dropdown-text">Crée ton assistant virtuel avec pyhton</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../INFO_MINI_PROJETS/JavaApp/desktop-app-java-mysql.html" rel="" target="">
 <span class="dropdown-text">Application desktop avec Java et Mysql</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-various" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Various</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-various">    
        <li>
    <a class="dropdown-item" href="../../../FORMATIONS/machine-learning/gradient-descent-linear-reg.html" rel="" target="">
 <span class="dropdown-text">Régression linéaire par descente de gradient - théorie et application</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../publications.html" rel="" target="">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html" rel="" target="">
 <span class="menu-text">About me</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://www.linkedin.com/in/djamal-toe-7a18432b0" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text">LinkedIn</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#résumé-abstract" id="toc-résumé-abstract" class="nav-link active" data-scroll-target="#résumé-abstract">Résumé / Abstract</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  </ul></li>
  <li><a href="#matériels-et-méthododes" id="toc-matériels-et-méthododes" class="nav-link" data-scroll-target="#matériels-et-méthododes">Matériels et Méthododes</a>
  <ul class="collapse">
  <li><a href="#données-utilisées" id="toc-données-utilisées" class="nav-link" data-scroll-target="#données-utilisées">1. Données utilisées</a></li>
  <li><a href="#prétraitement-des-données" id="toc-prétraitement-des-données" class="nav-link" data-scroll-target="#prétraitement-des-données">2. Prétraitement des données</a></li>
  <li><a href="#analyse-en-composantes-principales-acp" id="toc-analyse-en-composantes-principales-acp" class="nav-link" data-scroll-target="#analyse-en-composantes-principales-acp">3. Analyse en Composantes Principales (ACP)</a></li>
  <li><a href="#classification-non-supervisée-par-k-means" id="toc-classification-non-supervisée-par-k-means" class="nav-link" data-scroll-target="#classification-non-supervisée-par-k-means">4. Classification non supervisée par K-Means</a></li>
  <li><a href="#sélection-des-variables-explicatives" id="toc-sélection-des-variables-explicatives" class="nav-link" data-scroll-target="#sélection-des-variables-explicatives">5. Sélection des variables explicatives</a></li>
  <li><a href="#modélisation-statistique---regression-logistique" id="toc-modélisation-statistique---regression-logistique" class="nav-link" data-scroll-target="#modélisation-statistique---regression-logistique">6. Modélisation statistique - Regression logistique</a></li>
  <li><a href="#modélisation-supervisé-machine-learnig" id="toc-modélisation-supervisé-machine-learnig" class="nav-link" data-scroll-target="#modélisation-supervisé-machine-learnig">7. Modélisation supervisé : Machine Learnig</a>
  <ul class="collapse">
  <li><a href="#modèles-utilisés" id="toc-modèles-utilisés" class="nav-link" data-scroll-target="#modèles-utilisés">7.1 Modèles utilisés</a></li>
  <li><a href="#régression-logistique-machine-learning" id="toc-régression-logistique-machine-learning" class="nav-link" data-scroll-target="#régression-logistique-machine-learning"><strong>7.2 Régression logistique (Machine Learning)</strong></a></li>
  <li><a href="#k-plus-proches-voisins-k-nn" id="toc-k-plus-proches-voisins-k-nn" class="nav-link" data-scroll-target="#k-plus-proches-voisins-k-nn"><strong>7.3 K-plus proches voisins (K-NN)</strong></a></li>
  </ul></li>
  <li><a href="#évaluation-des-performances" id="toc-évaluation-des-performances" class="nav-link" data-scroll-target="#évaluation-des-performances">8. Évaluation des performances</a></li>
  <li><a href="#exploration-des-données" id="toc-exploration-des-données" class="nav-link" data-scroll-target="#exploration-des-données">Exploration des données</a></li>
  </ul></li>
  <li><a href="#résultats" id="toc-résultats" class="nav-link" data-scroll-target="#résultats">Résultats</a>
  <ul class="collapse">
  <li><a href="#description-des-variables" id="toc-description-des-variables" class="nav-link" data-scroll-target="#description-des-variables">Description des variables</a></li>
  <li><a href="#résumé-des-types-de-variables" id="toc-résumé-des-types-de-variables" class="nav-link" data-scroll-target="#résumé-des-types-de-variables">Résumé des types de variables</a></li>
  </ul></li>
  <li><a href="#analyse-de-données" id="toc-analyse-de-données" class="nav-link" data-scroll-target="#analyse-de-données">Analyse de données</a>
  <ul class="collapse">
  <li><a href="#analyse-exploratoire" id="toc-analyse-exploratoire" class="nav-link" data-scroll-target="#analyse-exploratoire">Analyse exploratoire</a></li>
  <li><a href="#analyse-en-composantes-principales" id="toc-analyse-en-composantes-principales" class="nav-link" data-scroll-target="#analyse-en-composantes-principales">Analyse en composantes principales</a>
  <ul class="collapse">
  <li><a href="#sélection-de-variables-redondantes-cas-de-radius_mean-area_mean-et-perimeter_mean" id="toc-sélection-de-variables-redondantes-cas-de-radius_mean-area_mean-et-perimeter_mean" class="nav-link" data-scroll-target="#sélection-de-variables-redondantes-cas-de-radius_mean-area_mean-et-perimeter_mean">Sélection de variables redondantes : cas de <code>radius_mean</code>, <code>area_mean</code> et <code>perimeter_mean</code></a></li>
  <li><a href="#variables-sélectionnées" id="toc-variables-sélectionnées" class="nav-link" data-scroll-target="#variables-sélectionnées">Variables sélectionnées</a></li>
  </ul></li>
  <li><a href="#les-kmeans" id="toc-les-kmeans" class="nav-link" data-scroll-target="#les-kmeans">Les Kmeans</a></li>
  <li><a href="#influence-des-caractéristiques-tumorales-sur-le-diagnostic-quelle-importance-pour-chaque-variable" id="toc-influence-des-caractéristiques-tumorales-sur-le-diagnostic-quelle-importance-pour-chaque-variable" class="nav-link" data-scroll-target="#influence-des-caractéristiques-tumorales-sur-le-diagnostic-quelle-importance-pour-chaque-variable">Influence des caractéristiques tumorales sur le diagnostic : quelle importance pour chaque variable ?</a></li>
  <li><a href="#prédiction-du-diagnostic-par-apprentissage-automatique-logit-vs-knn" id="toc-prédiction-du-diagnostic-par-apprentissage-automatique-logit-vs-knn" class="nav-link" data-scroll-target="#prédiction-du-diagnostic-par-apprentissage-automatique-logit-vs-knn">Prédiction du diagnostic par apprentissage automatique <code>Logit</code> vs <code>KNN</code></a></li>
  </ul></li>
  <li><a href="#conclusion-générale" id="toc-conclusion-générale" class="nav-link" data-scroll-target="#conclusion-générale">Conclusion générale</a></li>
  <li><a href="#annexes" id="toc-annexes" class="nav-link" data-scroll-target="#annexes">Annexes</a>
  <ul class="collapse">
  <li><a href="#annexe-0-corrélogramme-des-variables-quantitatives" id="toc-annexe-0-corrélogramme-des-variables-quantitatives" class="nav-link" data-scroll-target="#annexe-0-corrélogramme-des-variables-quantitatives">Annexe 0 : Corrélogramme des variables quantitatives</a></li>
  <li><a href="#annexe-1-pourcentages-des-variances-expliquées-par-les-composantes-principales" id="toc-annexe-1-pourcentages-des-variances-expliquées-par-les-composantes-principales" class="nav-link" data-scroll-target="#annexe-1-pourcentages-des-variances-expliquées-par-les-composantes-principales">Annexe 1 : Pourcentages des variances expliquées par les composantes principales</a></li>
  <li><a href="#annexe-2-hypothèses-et-interprétations-des-tests-statistiques" id="toc-annexe-2-hypothèses-et-interprétations-des-tests-statistiques" class="nav-link" data-scroll-target="#annexe-2-hypothèses-et-interprétations-des-tests-statistiques">Annexe 2 : Hypothèses et interprétations des tests statistiques</a>
  <ul class="collapse">
  <li><a href="#test-de-shapiro-wilk" id="toc-test-de-shapiro-wilk" class="nav-link" data-scroll-target="#test-de-shapiro-wilk"><strong>Test de Shapiro-Wilk</strong></a></li>
  <li><a href="#test-de-levene" id="toc-test-de-levene" class="nav-link" data-scroll-target="#test-de-levene"><strong>Test de Levene</strong></a></li>
  <li><a href="#test-danova-classique" id="toc-test-danova-classique" class="nav-link" data-scroll-target="#test-danova-classique"><strong>Test d’ANOVA classique</strong></a></li>
  <li><a href="#test-danova-de-welch" id="toc-test-danova-de-welch" class="nav-link" data-scroll-target="#test-danova-de-welch"><strong>Test d’ANOVA de Welch</strong></a></li>
  <li><a href="#test-de-kruskal-wallis" id="toc-test-de-kruskal-wallis" class="nav-link" data-scroll-target="#test-de-kruskal-wallis"><strong>Test de Kruskal-Wallis</strong></a></li>
  </ul></li>
  <li><a href="#annexe-4-rapport-de-corrélation" id="toc-annexe-4-rapport-de-corrélation" class="nav-link" data-scroll-target="#annexe-4-rapport-de-corrélation">Annexe 4: Rapport de corrélation</a></li>
  <li><a href="#annexe-5-pondération-des-observations-pour-corriger-le-déséquilibre-des-classes" id="toc-annexe-5-pondération-des-observations-pour-corriger-le-déséquilibre-des-classes" class="nav-link" data-scroll-target="#annexe-5-pondération-des-observations-pour-corriger-le-déséquilibre-des-classes">Annexe 5: Pondération des observations pour corriger le déséquilibre des classes</a></li>
  <li><a href="#annexe-6-codes" id="toc-annexe-6-codes" class="nav-link" data-scroll-target="#annexe-6-codes">Annexe 6: Codes</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Analyse statistique et apprentissage automatique pour la classification des tumeurs mammaires : étude de la régression logistique suivie d’une comparaison entre modèles logit et KNN</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Djamal TOE </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 12, 2025</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="résumé-abstract" class="level1">
<h1>Résumé / Abstract</h1>
<p>Dans cet article, nous étudions la classification des tumeurs mammaires à partir d’un jeu de données biomédical déséquilibré, en combinant des approches statistiques et d’apprentissage automatique. Une analyse exploratoire incluant une analyse en composantes principales (ACP) a permis de réduire la dimensionnalité tout en préservant la structure des données, validée par une classification non supervisée par <code>KMeans</code>. Une modélisation statistique par régression logistique pondérée a ensuite mis en évidence deux variables fortement prédictives : le <strong>périmètre moyen</strong> et le <strong>nombre moyen de points concaves</strong>, avec des <em>odds ratios</em> respectifs de <strong>9,7</strong> et <strong>25,0</strong>.</p>
<p>Dans une seconde phase, deux modèles supervisés — la <strong>régression logistique</strong> et le <strong>K plus proches voisins (KNN)</strong> — ont été comparés après sélection rigoureuse des variables. La régression logistique s’est révélée plus performante en termes de robustesse, de capacité de généralisation et de discrimination (AUC = <strong>0,98</strong>), tandis que le KNN a offert un bon compromis entre précision et rappel. Enfin, nous suggérons que pour des objectifs purement prédictifs, des modèles plus complexes comme <strong>XGBoost</strong> pourraient être envisagés, au prix d’une interprétabilité réduite.</p>
<p><strong>Mots-clés :</strong> <code>Analyse en composantes principales</code>, <code>Sélection de variables</code>, <code>K-plus proches voisins</code>, <code>Régression logistique</code>, <code>k-means</code>, <code>Classification</code>, <code>Données médicales</code>, <code>Tumeurs mammaires</code></p>
<hr>
<p>In this study, we address the classification of breast tumors using a highly imbalanced biomedical dataset, combining statistical methods and machine learning techniques. An exploratory analysis including Principal Component Analysis (PCA) was used to reduce dimensionality while preserving data structure, which was validated through unsupervised clustering with <code>KMeans</code>. A weighted logistic regression model identified two major predictors: <strong>mean perimeter</strong> and <strong>mean number of concave points</strong>, with odds ratios of <strong>9.7</strong> and <strong>25.0</strong>, respectively.</p>
<p>In the second phase, two supervised models — <strong>logistic regression</strong> and <strong>k-nearest neighbors (KNN)</strong> — were compared following rigorous variable selection. Logistic regression demonstrated superior robustness, generalization ability, and discriminative power (AUC = <strong>0.98</strong>), while KNN offered a strong balance between precision and recall. For purely predictive applications, we recommend exploring more complex models such as <strong>XGBoost</strong>, which may increase accuracy at the cost of interpretability.</p>
<p><strong>Keywords:</strong> <code>Principal Component Analysis</code>, <code>Variable Selection</code>, <code>K-Nearest Neighbours</code>, <code>Logistic Regression</code>, <code>k-means</code>, <code>Classification</code>, <code>Medical Data</code>, <code>Breast Tumors</code>.</p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Le cancer représente aujourd’hui l’une des principales causes de morbidité et de mortalité dans le monde. Selon les estimations <strong>GLOBOCAN 2020</strong>, près de 19,3 millions de nouveaux cas de cancer et 10 millions de décès liés à cette maladie ont été enregistrés à l’échelle mondiale en 2020 <span class="citation" data-cites="sung2021global">(<a href="#ref-sung2021global" role="doc-biblioref">Sung et al. 2021</a>)</span>. Cette charge devrait atteindre 28,4 millions de nouveaux cas d’ici 2040, soit une augmentation de 47 %, avec une progression particulièrement marquée dans les pays en développement.</p>
<p>Le cancer du sein a désormais dépassé le cancer du poumon comme cancer le plus fréquemment diagnostiqué dans le monde, avec 2,3 millions de nouveaux cas en 2020 (soit 11,7 % de l’ensemble des cancers). Il constitue également l’une des principales causes de décès par cancer chez la femme, avec environ 685 000 décès en 2020, soit 6,9 % des décès par cancer <span class="citation" data-cites="who2021breast sung2021global">(<a href="#ref-who2021breast" role="doc-biblioref">Organization 2021</a>; <a href="#ref-sung2021global" role="doc-biblioref">Sung et al. 2021</a>)</span>. Cette prévalence élevée, associée à une forte létalité dans les pays à ressources limitées, fait du cancer du sein un enjeu majeur de santé publique mondiale.</p>
<p>Les inégalités géographiques sont notables : alors que l’incidence du cancer du sein est plus élevée dans les pays industrialisés, les taux de mortalité y sont généralement plus faibles, grâce à une détection précoce et à une meilleure prise en charge. À l’inverse, dans de nombreux pays en transition, le diagnostic est souvent posé à un stade avancé, expliquant des taux de mortalité proportionnellement plus élevés <span class="citation" data-cites="sung2021global">(<a href="#ref-sung2021global" role="doc-biblioref">Sung et al. 2021</a>)</span>.</p>
<p>Dans ce contexte, il devient essentiel de mieux comprendre les facteurs explicatifs de la malignité des tumeurs mammaires afin de guider les stratégies de dépistage, de prévention et de traitement. L’analyse de données cliniques et la modélisation statistique peuvent contribuer à cet objectif en identifiant des variables discriminantes et en développant des modèles prédictifs robustes.</p>
<p>C’est dans cette perspective que s’inscrit ce travail, qui poursuit deux objectifs complémentaires :</p>
<ul>
<li><p><strong>Identifier les variables cliniques les plus explicatives du caractère bénin ou malin d’une tumeur mammaire</strong>;</p></li>
<li><p><strong>Ajuster un modèle de machine learning capable de prédire efficacement la nature de la tumeur à partir de ces variables</strong>.</p></li>
</ul>
<p>En atteignant ces objectifs, notre démarche vise à renforcer l’applicabilité des outils prédictifs dans un cadre médical, tout en assurant une meilleure compréhension des dimensions sous-jacentes à la classification tumorale.</p>
</section>
</section>
<section id="matériels-et-méthododes" class="level1">
<h1>Matériels et Méthododes</h1>
<section id="données-utilisées" class="level2">
<h2 class="anchored" data-anchor-id="données-utilisées">1. Données utilisées</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L’étude s’appuie sur le jeu de données Wisconsin Breast Cancer Diagnostic (WBCD), mis à disposition par l’Université du Wisconsin sur kaggle <a href="https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data">(Wolberg, W.H., et al., 1995)</a>. Il contient 569 observations issues d’analyses de prélèvements mammaires, chacune décrite par 30 variables numériques mesurant des caractéristiques morphologiques des noyaux cellulaires (moyenne, écart-type et valeur extrême de la texture, surface, concavité, etc.). La variable cible est binaire et indique si la tumeur est <strong>maligne</strong> (<code>M</code>) ou <strong>bénigne</strong> (<code>B</code>).</p>
</section>
<section id="prétraitement-des-données" class="level2">
<h2 class="anchored" data-anchor-id="prétraitement-des-données">2. Prétraitement des données</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Les étapes suivantes ont été réalisées :</p>
<ul>
<li><p>Suppression de l’identifiant non informatif (id),</p></li>
<li><p>filtrage des variables : seules les mesures de moyenne (se terminant par _mean) ont été retenues pour l’analyse initiale;</p></li>
<li><p>standardisation : toutes les variables ont été centrées et réduites afin d’éviter que leur échelle influence les analyses;</p></li>
<li><p>vérification de la complétude : le jeu de données ne contient pas de valeurs manquantes.</p></li>
</ul>
</section>
<section id="analyse-en-composantes-principales-acp" class="level2">
<h2 class="anchored" data-anchor-id="analyse-en-composantes-principales-acp">3. Analyse en Composantes Principales (ACP)</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Une ACP a été effectuée sur les variables normalisées afin de réduire la dimensionnalité tout en préservant l’information maximale <span class="citation" data-cites="jolliffe2016pca abdi2010principal">(<a href="#ref-jolliffe2016pca" role="doc-biblioref">Jolliffe and Cadima 2016</a>; <a href="#ref-abdi2010principal" role="doc-biblioref">Abdi and Williams 2010</a>)</span>. Les deux premières composantes principales ont été retenues car elles expliquent ensemble plus de 80% de la variance totale.</p>
<p>L’ACP a permis de :</p>
<ul>
<li><p>visualiser les individus dans un plan factoriel 2D (tumeur maligne vs bénigne);</p></li>
<li><p>étudier la structure des variables à l’aide du cercle des corrélations;</p></li>
<li><p>identifier les variables les plus contributives à l’axe de séparation entre les deux classes;</p></li>
</ul>
<p>Cette étape a aussi guidé la sélection finale des variables explicatives, en complément des tests statistiques.</p>
</section>
<section id="classification-non-supervisée-par-k-means" class="level2">
<h2 class="anchored" data-anchor-id="classification-non-supervisée-par-k-means">4. Classification non supervisée par K-Means</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Afin d’analyser la structure intrinsèque des données, une classification non supervisée a été réalisée à l’aide de l’algorithme K-Means <span class="citation" data-cites="macqueen1967some">(<a href="#ref-macqueen1967some" role="doc-biblioref">MacQueen 1967</a>)</span>. Le nombre de clusters a été fixé à k = 2, en cohérence avec les deux catégories diagnostiques.</p>
<p>L’algorithme a été appliqué sur les composantes principales issues de l’ACP, ce qui présente deux avantages :</p>
<ul>
<li><p>réduction du bruit (moins de dimensions);</p></li>
<li><p>visualisation claire des regroupements.</p></li>
</ul>
<p>Les clusters obtenus ont ensuite été comparés aux vraies classes pour évaluer le pouvoir de séparation naturelle des données. Cette approche permet aussi de valider la pertinence des axes factoriels retenus dans l’ACP.</p>
</section>
<section id="sélection-des-variables-explicatives" class="level2">
<h2 class="anchored" data-anchor-id="sélection-des-variables-explicatives">5. Sélection des variables explicatives</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Une série de tests statistiques a été conduite pour identifier les variables présentant une différence significative entre les tumeurs bénignes et malignes :</p>
<ul>
<li><p>Normalité des variables testée via le test de Shapiro-Wilk;</p></li>
<li><p>Homogénéité des variances testée avec le test de Levene;</p></li>
<li><p>Choix du test de comparaison approprié (ANOVA ou test de Kruskal-Wallis);</p></li>
<li><p>Calcul de l’indice <span class="math inline">\(\eta^2\)</span> (eta squared) pour estimer la proportion de variance expliquée.</p></li>
</ul>
</section>
<section id="modélisation-statistique---regression-logistique" class="level2">
<h2 class="anchored" data-anchor-id="modélisation-statistique---regression-logistique">6. Modélisation statistique - Regression logistique</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;La régression logistique binaire a été utilisée pour estimer la probabilité qu’une tumeur soit <strong>maligne</strong> en fonction des variables explicatives sélectionnées <span class="citation" data-cites="hosmer2013applied">(<a href="#ref-hosmer2013applied" role="doc-biblioref">Hosmer, Lemeshow, and Sturdivant 2013</a>)</span>. Ce modèle statistique repose sur la relation log-linéaire entre les covariables et le <strong>logit de la probabilité</strong> d’appartenir à la classe <strong>maligne</strong>.</p>
<p>L’un des avantages majeurs de la régression logistique réside dans son interprétabilité : chaque coefficient estimé peut être interprété comme un effet multiplicatif sur les odds de malignité. Ainsi, une variable avec un coefficient positif augmente la probabilité qu’une tumeur soit maligne, et inversement pour un coefficient négatif.</p>
<p>Les résultats du modèle permettent non seulement de classifier les tumeurs, mais aussi d’identifier les facteurs les plus associés à la malignité, ce qui offre une <strong>lecture médico-biologique utile</strong>.</p>
</section>
<section id="modélisation-supervisé-machine-learnig" class="level2">
<h2 class="anchored" data-anchor-id="modélisation-supervisé-machine-learnig">7. Modélisation supervisé : Machine Learnig</h2>
<section id="modèles-utilisés" class="level3">
<h3 class="anchored" data-anchor-id="modèles-utilisés">7.1 Modèles utilisés</h3>
<p>Afin de comparer les approches classiques et les méthodes d’apprentissage automatique, deux modèles ont été entraînés pour la prédiction du type de tumeur :</p>
<ul>
<li><p>Régression logistique (appliquée ici comme algorithme de machine learning) <span class="citation" data-cites="hosmer2013applied">(<a href="#ref-hosmer2013applied" role="doc-biblioref">Hosmer, Lemeshow, and Sturdivant 2013</a>)</span>,</p></li>
<li><p>K-plus proches voisins (K-NN) avec <span class="math inline">\(k = 5\)</span> <span class="citation" data-cites="cover1967nearest">(<a href="#ref-cover1967nearest" role="doc-biblioref">Cover and Hart 1967</a>)</span>.</p></li>
</ul>
<p>Le jeu de données a été aléatoirement divisé en deux sous-ensembles :</p>
<ul>
<li><p>Entraînement : 80 % des données,</p></li>
<li><p>Test : 20 % des données.</p></li>
</ul>
</section>
<section id="régression-logistique-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="régression-logistique-machine-learning"><strong>7.2 Régression logistique (Machine Learning)</strong></h3>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Le modèle de régression logistique a été ajusté sur l’échantillon d’apprentissage, en prenant en compte les variables préalablement sélectionnées. L’entraînement a permis d’identifier les variables les plus influentes sur le score de prédiction, tout en conservant une bonne capacité généralisable sur les données de test.</p>
<p>Les performances ont été évaluées à l’aide de l’aire sous la courbe ROC (AUC), du rappel, de la précision et du F1-score.</p>
</section>
<section id="k-plus-proches-voisins-k-nn" class="level3">
<h3 class="anchored" data-anchor-id="k-plus-proches-voisins-k-nn"><strong>7.3 K-plus proches voisins (K-NN)</strong></h3>
<p>Le modèle K-NN classe une observation en fonction des classes majoritaires de ses k voisins les plus proches <span class="citation" data-cites="cover1967nearest">(<a href="#ref-cover1967nearest" role="doc-biblioref">Cover and Hart 1967</a>)</span>. Le choix du paramètre k = 2 a été déterminé via validation croisée sur l’échantillon d’apprentissage.</p>
<p>La distance euclidienne a été utilisée comme métrique de proximité. Un soin particulier a été apporté pour éviter le surapprentissage, en équilibrant biais et variance lors de l’optimisation du modèle.</p>
</section>
</section>
<section id="évaluation-des-performances" class="level2">
<h2 class="anchored" data-anchor-id="évaluation-des-performances">8. Évaluation des performances</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Le modèle de régression logistique statistique a été évalué à l’aide des tests de significativité des coefficients, ainsi que de la qualité de l’ajustement global.</p>
<p>Quant aux modèles de machine learning, ils ont été évalués sur l’échantillon test selon plusieurs indicateurs de performance :</p>
<ul>
<li><p><code>Exactitude (Accuracy)</code> : proportion globale de bonnes classifications,</p></li>
<li><p><code>Précision (Precision)</code> : proportion de vraies tumeurs malignes parmi les prédictions positives,</p></li>
<li><p><code>Rappel (Recall)</code> : proportion de vraies tumeurs malignes correctement détectées,</p></li>
<li><p><code>F1-score</code> : compromis entre précision et rappel,</p></li>
<li><p><code>AUC-ROC</code> : mesure de la performance globale du modèle pour discriminer les deux classes.</p></li>
</ul>
<p>Ces métriques permettent une comparaison objective des performances et de la robustesse des modèles utilisés.</p>
<hr>
<blockquote class="blockquote">
<p>L’ACP est faite en amont pour éviter la multicolinéarité et améliorer la robustesse des modèles.<br>
Le clustering permet de découvrir la structure latente des données avant la classification.</p>
</blockquote>
<hr>
</section>
<section id="exploration-des-données" class="level2">
<h2 class="anchored" data-anchor-id="exploration-des-données">Exploration des données</h2>
<p>L’exploration des données comprend :</p>
<ul>
<li>Le résumé statistique descriptif des variables<br>
</li>
<li>La distribution de la variable cible<br>
</li>
<li>L’étude des corrélations entre variables</li>
</ul>
<p>Ces étapes permettent de mieux comprendre la structure et les caractéristiques de la base avant modélisation.</p>
<hr>
</section>
</section>
<section id="résultats" class="level1">
<h1>Résultats</h1>
<section id="description-des-variables" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="description-des-variables">Description des variables</h2>
<p>Les variables de cette base sont construites à partir de l’analyse de <strong>noyaux de cellules</strong> détectés dans des images médicales.</p>
<ul>
<li><p><code>id</code> <em>(int)</em> : Identifiant unique de l’observation (patient).</p></li>
<li><p><code>diagnosis</code> <em>(catégorielle)</em> Variable cible binaire :</p>
<ul>
<li><p><strong>M</strong> : Malignant (maligne)</p></li>
<li><p><strong>B</strong> : Benign (bénigne)</p></li>
</ul></li>
<li><p><strong>Caractéristiques mesurées</strong></p></li>
</ul>
<p>Pour chaque noyau de cellule, 10 mesures statistiques ont été calculées, puis <strong>la moyenne</strong>, <strong>l’écart-type</strong> (erreur standard, noté <code>se</code>), et <strong>la valeur extrême (<code>worst</code>)</strong> ont été rapportés :</p>
<blockquote class="blockquote">
<blockquote class="blockquote">
<blockquote class="blockquote">
<p>Mesures de base :</p>
</blockquote>
</blockquote>
</blockquote>
<p>Ces mesures sont disponibles en 3 versions chacune : <code>.mean</code>, <code>.se</code>, <code>.worst</code></p>
<table class="table">
<colgroup>
<col style="width: 31%">
<col style="width: 68%">
</colgroup>
<thead>
<tr class="header">
<th>Variable de base</th>
<th>Signification</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>radius</code></td>
<td>Rayon moyen du noyau</td>
</tr>
<tr class="even">
<td><code>texture</code></td>
<td>Écart-type des valeurs de niveaux de gris</td>
</tr>
<tr class="odd">
<td><code>perimeter</code></td>
<td>Périmètre du noyau</td>
</tr>
<tr class="even">
<td><code>area</code></td>
<td>Surface du noyau</td>
</tr>
<tr class="odd">
<td><code>smoothness</code></td>
<td>Régularité des contours (valeurs faibles = plus lisses)</td>
</tr>
<tr class="even">
<td><code>compactness</code></td>
<td>Compacité = (périmètre² / surface) - 1.0</td>
</tr>
<tr class="odd">
<td><code>concavity</code></td>
<td>Gravité des concavités dans les contours</td>
</tr>
<tr class="even">
<td><code>concave points</code></td>
<td>Nombre de points concaves sur les contours</td>
</tr>
<tr class="odd">
<td><code>symmetry</code></td>
<td>Symétrie de la cellule</td>
</tr>
<tr class="even">
<td><code>fractal dimension</code></td>
<td>Mesure de la “rugosité” des contours</td>
</tr>
</tbody>
</table>
<p>Chaque mesure est donc déclinée en :</p>
<ul>
<li><p><code>*_mean</code></p></li>
<li><p><code>*_se</code></p></li>
<li><p><code>*_worst</code></p></li>
</ul>
<p>Par exemple :</p>
<ul>
<li><p><code>radius_mean</code>, <code>radius_se</code>, <code>radius_worst</code></p></li>
<li><p><code>texture_mean</code>, <code>texture_se</code>, <code>texture_worst</code></p></li>
<li><p>…</p></li>
<li><p><code>fractal_dimension_mean</code>, <code>fractal_dimension_se</code>, <code>fractal_dimension_worst</code></p></li>
</ul>
<p>Ce qui donne au total 30 variables <code>quantitatives</code>.</p>
<hr>
</section>
<section id="résumé-des-types-de-variables" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="résumé-des-types-de-variables">Résumé des types de variables</h2>
<table class="table">
<colgroup>
<col style="width: 30%">
<col style="width: 55%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th>Type de variable</th>
<th>Nom</th>
<th>Nombre</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Identifiant</td>
<td><code>id</code></td>
<td>1</td>
</tr>
<tr class="even">
<td>Cible binaire</td>
<td><code>diagnosis</code></td>
<td>1</td>
</tr>
<tr class="odd">
<td>Variables numériques (×10 mesures ×3 stats)</td>
<td><code>*_mean</code>, <code>*_se</code>, <code>*_worst</code></td>
<td>30</td>
</tr>
</tbody>
</table>
<hr>
</section>
</section>
<section id="analyse-de-données" class="level1">
<h1>Analyse de données</h1>
<section id="analyse-exploratoire" class="level2">
<h2 class="anchored" data-anchor-id="analyse-exploratoire">Analyse exploratoire</h2>
<ul>
<li><strong>Quelques statistiques descriptives</strong></li>
</ul>
<ul>
<li><strong>Distribution des variables</strong></li>
</ul>
<div class="cell" data-fig.aligne="center">
<div class="cell-output-display">
<div id="fig-hist-quanti" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Breast-Tumor-Article_files/figure-html/fig-hist-quanti-1.png" style="width:90.0%;height:95.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Distribution des variables</figcaption>
</figure>
</div>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Ce graphique illustre la distribution des variables explicatives. On observe une hétérogénéité d’échelle importante entre les différentes variables, ce qui justifie l’application préalable d’une standardisation (centrage-réduction) avant toute analyse multivariée ou modélisation.</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Par ailleurs, la distribution de la variable réponse révèle un déséquilibre notable entre les classes : la proportion de tumeurs bénignes est environ deux fois inférieure à celle des tumeurs malignes. Ce déséquilibre pourrait influencer les performances de certains modèles de classification, en particulier ceux sensibles à la distribution des classes, et devra être pris en compte dans l’évaluation.</p>
<ul>
<li><strong>Corrélogramme des variables quantitatives</strong></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output cell-output-stdout">
<pre><code>(array([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]), [Text(0.5, 0, 'radius_mean'), Text(1.5, 0, 'texture_mean'), Text(2.5, 0, 'perimeter_mean'), Text(3.5, 0, 'area_mean'), Text(4.5, 0, 'smoothness_mean'), Text(5.5, 0, 'compactness_mean'), Text(6.5, 0, 'concavity_mean'), Text(7.5, 0, 'concave points_mean'), Text(8.5, 0, 'symmetry_mean'), Text(9.5, 0, 'fractal_dimension_mean')])</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>(array([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]), [Text(0, 0.5, 'radius_mean'), Text(0, 1.5, 'texture_mean'), Text(0, 2.5, 'perimeter_mean'), Text(0, 3.5, 'area_mean'), Text(0, 4.5, 'smoothness_mean'), Text(0, 5.5, 'compactness_mean'), Text(0, 6.5, 'concavity_mean'), Text(0, 7.5, 'concave points_mean'), Text(0, 8.5, 'symmetry_mean'), Text(0, 9.5, 'fractal_dimension_mean')])</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-corr-two" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Breast-Tumor-Article_files/figure-html/fig-corr-two-3.png" style="width:90.0%;height:95.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Corrélogramme des variables quantitatives statistiquement significatives</figcaption>
</figure>
</div>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Une analyse des corrélations entre les variables explicatives montre que certaines variables sont fortement corrélées entre elles, tandis que d’autres présentent des corrélations plus faibles. Toutefois, une simple observation graphique ne permet pas de conclure sur la significativité statistique de ces associations.</p>
<p>Pour approfondir cette analyse, un matrice de corrélations de pearson annotée avec les p-values a été utilisée. Cela permet de distinguer :</p>
<ul>
<li><p>les corrélations statistiquement significatives,</p></li>
<li><p>des associations qui, bien que visuellement marquées, ne sont pas significatives au seuil de 5%,</p></li>
<li><p>ainsi que des variables non corrélées entre elles, mais corrélées à d’autres.</p></li>
<li><p>Cette redondance entre variables justifie pleinement le recours à une analyse en composantes principales (<code>ACP</code>).</p></li>
</ul>
</section>
<section id="analyse-en-composantes-principales" class="level2">
<h2 class="anchored" data-anchor-id="analyse-en-composantes-principales">Analyse en composantes principales</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pour cette partie spéciquement ainsi que pour la partie statistique du modèle logistique, nous utiliserons le langage <code>R</code> au lieu de python car il est plus facile à prendre en main (avis personnel). Mais pour la partie <code>machine learning</code> nous utiliserons le langage <code>Python</code>.</p>
<p>L’ <code>ACP</code> permettra d’éliminer les variables corrélées entre elles en ne gardant que les plus contributives à la formation des axes que nous choisirons (pour plus de détails visitez ma publication <a href="https://djamal2905.github.io/djamal_website/ANALYSES_FACTORIELLES/acp-kmeans.html">Reduction de dimensionnalité, clustering non supervisé</a>).</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Les deux premiers axes factoriels ont été sélectionné car ceux-ci permettent de conserver plus de 80% de l’information contenue dans les données (voir <code>annexe 1</code>).</p>
<ul>
<li><strong>Analyses des variables</strong></li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div id="fig-var-circle" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Breast-Tumor-Article_files/figure-html/fig-var-circle-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Cartes de la representation des variables sur les dimensions 1 et 2</figcaption>
</figure>
</div>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cette figure met en évidence les principales relations entre les variables dans le plan des premières composantes principales. Elle permet de formuler plusieurs observations importantes :</p>
<ul>
<li><p>La variable <code>texture_mean</code> apparaît comme la moins contributive. Elle présente une très faible corrélation avec les composantes principales retenues, ce qui indique qu’elle n’apporte pas d’information significative pour la séparation entre les groupes.</p></li>
<li><p>Les variables <code>radius_mean</code>, <code>area_mean</code> et <code>perimeter_mean</code> sont très fortement corrélées entre elles. Elles contribuent de manière presque équivalente à la construction des axes principaux de l’analyse. Cette redondance est attendue, car ces variables décrivent toutes la taille du noyau de la cellule, selon des relations géométriques bien établies :</p>
<p><span class="math display">\[
\text{Périmètre} \approx 2\pi \times \text{Rayon}, \quad \text{Aire} \approx \pi \times \text{Rayon}^2
\]</span></p>
<p>Ces relations expliquent que ces trois variables transmettent une information similaire. Pour éviter la redondance, il est judicieux de n’en conserver qu’une seule dans les analyses ultérieures.</p></li>
<li><p>Les variables <code>smoothness_mean</code> et <code>symmetry_mean</code> sont corrélées, mais <code>smoothness_mean</code> se distingue par une contribution plus forte à l’analyse. Elle décrit la régularité des contours, un critère pertinent pour la caractérisation morphologique, tandis que <code>symmetry_mean</code> apporte une information redondante et de moindre poids explicatif.</p></li>
<li><p>Les variables <code>concavity_mean</code> et <code>concave points_mean</code> sont également corrélées. Toutefois, <code>concave points_mean</code> est retenue car elle contribue davantage à la structure globale révélée par l’ACP. Ces variables sont liées à la présence d’irrégularités dans les contours cellulaires, souvent caractéristiques des tumeurs malignes.</p></li>
<li><p>D’autres variables, comme <code>compactness_mean</code>, <code>fractal_dimension_mean</code> et <code>smoothness_mean</code>, apportent des informations complémentaires. Par exemple :</p>
<ul>
<li><code>compactness_mean</code> exprime le rapport entre la surface et le périmètre, donc la forme générale,</li>
<li><code>fractal_dimension_mean</code> mesure la complexité des contours, et reflète l’irrégularité des bords.</li>
</ul></li>
</ul>
<p>Bien que certaines variables soient corrélées, elles capturent des aspects distincts de la morphologie des noyaux. Cela justifie leur présence dans une approche multivariée.</p>
<section id="sélection-de-variables-redondantes-cas-de-radius_mean-area_mean-et-perimeter_mean" class="level3">
<h3 class="anchored" data-anchor-id="sélection-de-variables-redondantes-cas-de-radius_mean-area_mean-et-perimeter_mean">Sélection de variables redondantes : cas de <code>radius_mean</code>, <code>area_mean</code> et <code>perimeter_mean</code></h3>
<p>Pour choisir entre les variables <code>radius_mean</code>, <code>area_mean</code> et <code>perimeter_mean</code>, qui sont fortement corrélées, une procédure rigoureuse de sélection est mise en place, fondée sur l’analyse de la variance (ANOVA). Avant d’appliquer ce test, deux conditions doivent être vérifiées :</p>
<ul>
<li><strong>Normalité des données</strong> dans chaque groupe (<code>B</code> et <code>M</code>) via le test de <strong>Shapiro-Wilk</strong>.</li>
<li><strong>Homogénéité des variances</strong> entre les groupes via le test de <strong>Levene</strong>.</li>
</ul>
<p>En fonction des résultats, le test statistique approprié est sélectionné :</p>
<ul>
<li><p>Si les deux conditions sont remplies, une <strong>ANOVA classique</strong> est appliquée.</p></li>
<li><p>Si les données sont normales mais les variances sont différentes, on utilise l’<strong>ANOVA de Welch</strong>.</p></li>
<li><p>En cas de non-normalité, un <strong>test non paramétrique</strong> est privilégié :</p>
<ul>
<li><p><strong>Wilcoxon-Mann-Whitney</strong> pour deux groupes,</p></li>
<li><p>ou <strong>Kruskal-Wallis</strong> pour plus de deux groupes.</p></li>
</ul></li>
</ul>
<p>Ce processus a été automatisé à l’aide d’une fonction personnalisée. Les détails des tests (Shapiro-Wilk, Levene et choix final) sont présentés en <strong>annexe</strong>.</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Une analyse statistique a été menée pour évaluer si certaines variables différencient significativement les tumeurs bénignes des tumeurs malignes. Les tests de normalité (par groupe), les tests d’homogénéité de variances, ainsi que le test non paramétrique de Wilcoxon-Mann-Whitney ont été appliqués pour cela.</p>
<p>Concernant la variable radius_mean, les tests de normalité indiquent une distribution non normale, notamment pour le groupe M <code>(p = 0.0019)</code>, et le test de Levene rejette l’hypothèse d’homogénéité des variances (p = 0). Le test de Wilcoxon-Mann-Whitney donne un p-value de 0, indiquant une différence significative entre les distributions des deux groupes. On conclut donc que radius_mean permet de distinguer les tumeurs selon leur nature.</p>
<p>De même, pour area_mean, la normalité n’est pas respectée dans les deux groupes<code>(p = 0.0228 pour B, et p = 0 pour M)</code>, les variances ne sont pas homogènes <code>(p = 0)</code>, et le test de Wilcoxon-Mann-Whitney rejette également l’égalité des distributions entre les groupes <code>(p = 0)</code>. Cette variable est donc statistiquement discriminante.</p>
<p>Enfin, perimeter_mean présente aussi une non-normalité pour le groupe M <code>(p = 4e-04)</code> et des variances inégales <code>(p = 0)</code>. Le test de Wilcoxon conclut à une différence significative des distributions entre les deux types de tumeurs.</p>
<p>Ces résultats soutiennent l’idée que ces trois variables contribuent de manière significative à la séparation entre tumeurs bénignes et malignes, et justifient leur inclusion dans les étapes de sélection des variables explicatives.</p>
<p>Cependant, ces variables sont <strong>fortement corrélées entre elles</strong> (<span class="math inline">\(r &gt; 0.95\)</span>). Une telle redondance peut induire des problèmes de <strong>multicolinéarité</strong> dans les modèles statistiques ou de machine learning, rendant l’interprétation des coefficients difficile et dégradant la performance prédictive.</p>
<p>Pour remédier à cela, nous proposons de <strong>sélectionner une seule variable représentative</strong> parmi ces variables fortement corrélées. Le critère retenu est le <strong>rapport de corrélation</strong> avec la variable cible (<code>diagnosis</code>). Ainsi, parmi les variables redondantes, nous conservons <strong>celle ayant la plus forte corrélation absolue avec la classe</strong> à prédire. Ce choix permet de maximiser la contribution informative tout en éliminant les doublons.</p>
<ul>
<li><code>radius_mean</code> : <span class="math inline">\(\eta^2 = 0{,}5329416\)</span><br>
</li>
<li><code>area_mean</code> : <span class="math inline">\(\eta^2 = 0{,}5026581\)</span><br>
</li>
<li><code>perimeter_mean</code> : <span class="math inline">\(\eta^2 = 0{,}5515075\)</span></li>
</ul>
<p>Nous retenons donc <strong><code>perimeter_mean</code></strong>, qui présente le <strong>rapport de corrélation le plus élevé</strong> avec la variable réponse.</p>
</section>
<section id="variables-sélectionnées" class="level3">
<h3 class="anchored" data-anchor-id="variables-sélectionnées">Variables sélectionnées</h3>
<p>Les variables retenues pour l’analyse finale sont :</p>
<ul>
<li><p><code>perimeter_mean</code> : mesure de la taille du noyau,</p></li>
<li><p><code>smoothness_mean</code> : régularité des contours,</p></li>
<li><p><code>fractal_dimension_mean</code> : complexité des bords,</p></li>
<li><p><code>concave points_mean</code> : présence de concavités.</p></li>
<li><p><strong>Conclusion partielle</strong></p></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L’analyse en composantes principales (<code>ACP</code>) a mis en évidence des <strong>groupes de variables fortement corrélées</strong>, traduisant des caractéristiques géométriques proches. Afin d’éviter la <strong>redondance d’information</strong> et les effets de <strong>multicolinéarité</strong>, nous avons conservé, pour chaque groupe, la variable la <strong>plus représentative</strong>.</p>
<p>Cette sélection permet de construire un modèle plus <strong>parcimonieux</strong>, tout en conservant des dimensions complémentaires — liées à la <strong>forme</strong>, la <strong>texture</strong> ou la <strong>complexité morphologique</strong> — essentielles à une bonne discrimination des types de tumeurs.</p>
</section>
</section>
<section id="les-kmeans" class="level2">
<h2 class="anchored" data-anchor-id="les-kmeans">Les Kmeans</h2>
<div class="cell">
<div class="cell-output-display">
<p><img src="Breast-Tumor-Article_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Comme les <strong>deux premières composantes principales</strong> expliquent <strong>plus de 80 % de la variance totale</strong>, nous les retenons pour la suite de l’analyse. Cette réduction de dimension permet de conserver l’essentiel de l’information tout en facilitant la visualisation et les analyses ultérieures.</p>
<p>Dans le cadre de la classification non supervisée, nous appliquons ensuite l’algorithme <strong>K-Means</strong> avec un nombre de <strong>clusters fixé à 2</strong>, en cohérence avec la nature binaire de la variable réponse (<code>diagnosis</code>). L’objectif est d’évaluer si les observations peuvent être regroupées automatiquement en deux groupes distincts, reflétant ou non la distinction entre tumeurs bénignes et malignes.</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;La classification K-Means appliquée aux deux premières composantes principales permet une séparation relativement nette des observations en deux groupes.</p>
<p>Le tableau ci-dessous présente la répartition des observations selon les clusters identifiés par l’algorithme <strong>K-Means</strong> et leur étiquette réelle (<code>diagnosis</code>).</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">Cluster</th>
<th style="text-align: right;">Bénigne (B)</th>
<th style="text-align: right;">Maligne (M)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">163</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: right;">349</td>
<td style="text-align: right;">49</td>
</tr>
</tbody>
</table>
<p>On observe que :</p>
<ul>
<li><p><strong>Cluster 1</strong> est majoritairement composé de tumeurs <strong>malignes</strong> (163 cas M contre 8 cas B), ce qui suggère que ce groupe correspond essentiellement aux observations de type <strong>malin</strong>.</p></li>
<li><p><strong>Cluster 2</strong> regroupe principalement des tumeurs <strong>bénignes</strong> (349 cas B contre 49 cas M), ce qui permet de l’associer globalement à la classe <strong>bénigne</strong>.</p></li>
</ul>
<p>Cette séparation indique que la structure latente des données, projetée dans le sous-espace factoriel, permet déjà une <strong>discrimination naturelle</strong> entre les deux types de tumeurs, sans supervision. Cela renforce l’idée que les variables sélectionnées sont pertinentes pour la classification.</p>
<blockquote class="blockquote">
<blockquote class="blockquote">
<blockquote class="blockquote">
<p>Représentations graphiques</p>
</blockquote>
</blockquote>
</blockquote>
<div class="cell">
<div class="cell-output-display">
<div id="fig-classif-5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Breast-Tumor-Article_files/figure-html/fig-classif-5-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Classification des patients par la méthode des K-moyennes</figcaption>
</figure>
</div>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sur cette figure On observe que les patients sont <strong>pratiquement linéairement séparables</strong> dans le plan défini par les deux premières composantes principales.</p>
<p>Cela signifie que la projection sur ces deux dimensions met bien en évidence une séparation claire entre les deux groupes (bénins et malins), ce qui est cohérent avec la qualité du clustering obtenu par k-means.</p>
<blockquote class="blockquote">
<p>Cette bonne séparation visuelle corrobore la pertinence des variables sélectionnées et confirme que les composantes principales résument efficacement la variance utile à la distinction des diagnostics. Nous pouvons passer à présent aux différents modèles de prédiction (regression logistique et k plus plus proches voisins)</p>
</blockquote>
</section>
<section id="influence-des-caractéristiques-tumorales-sur-le-diagnostic-quelle-importance-pour-chaque-variable" class="level2">
<h2 class="anchored" data-anchor-id="influence-des-caractéristiques-tumorales-sur-le-diagnostic-quelle-importance-pour-chaque-variable">Influence des caractéristiques tumorales sur le diagnostic : quelle importance pour chaque variable ?</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;Pour répondre à cette question, nous avons procédé à une <strong>modélisation statistique</strong> à l’aide d’une régression logistique classique. Les variables explicatives ont été <strong>standardisées</strong> (centrées et réduites) afin de faciliter la comparaison de leurs effets respectifs et de stabiliser l’estimation des coefficients. Cette standardisation permet une interprétation relative : un coefficient traduit alors l’effet d’une variation d’un écart-type de la variable sur la probabilité d’un diagnostic malin. Toutefois, cela rend l’interprétation directe dans l’unité d’origine moins intuitive.</p>
<p>Par ailleurs, la variable cible <code>diagnosis</code> présente un <strong>déséquilibre important</strong> : les cas bénins (<code>B</code>) sont nettement plus nombreux que les cas malins (<code>M</code>). Ce déséquilibre peut induire un <strong>biais dans l’apprentissage</strong>, poussant le modèle à privilégier la classe majoritaire, au détriment de la détection des cas malins, pourtant critiques sur le plan médical.</p>
<p>Pour corriger ce biais, nous avons introduit une <strong>pondération des observations</strong> dans le modèle logistique. Plus précisément, chaque observation de la classe minoritaire (<code>M</code>) a reçu un poids proportionnel au rapport entre les proportions des classes dans l’échantillon.</p>
<p>Cette stratégie permet d’obtenir un modèle plus équitable dans sa capacité à prédire correctement les deux types de tumeurs, en particulier les cas malins qui constituent l’enjeu principal de détection dans un contexte médical.</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-model-logit" class="anchored">

<div id="nyhhcasobv" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#nyhhcasobv table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#nyhhcasobv thead, #nyhhcasobv tbody, #nyhhcasobv tfoot, #nyhhcasobv tr, #nyhhcasobv td, #nyhhcasobv th {
  border-style: none;
}

#nyhhcasobv p {
  margin: 0;
  padding: 0;
}

#nyhhcasobv .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#nyhhcasobv .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#nyhhcasobv .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#nyhhcasobv .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#nyhhcasobv .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#nyhhcasobv .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#nyhhcasobv .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#nyhhcasobv .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#nyhhcasobv .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#nyhhcasobv .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#nyhhcasobv .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#nyhhcasobv .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#nyhhcasobv .gt_spanner_row {
  border-bottom-style: hidden;
}

#nyhhcasobv .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#nyhhcasobv .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#nyhhcasobv .gt_from_md > :first-child {
  margin-top: 0;
}

#nyhhcasobv .gt_from_md > :last-child {
  margin-bottom: 0;
}

#nyhhcasobv .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#nyhhcasobv .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#nyhhcasobv .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#nyhhcasobv .gt_row_group_first td {
  border-top-width: 2px;
}

#nyhhcasobv .gt_row_group_first th {
  border-top-width: 2px;
}

#nyhhcasobv .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#nyhhcasobv .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#nyhhcasobv .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#nyhhcasobv .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#nyhhcasobv .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#nyhhcasobv .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#nyhhcasobv .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#nyhhcasobv .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#nyhhcasobv .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#nyhhcasobv .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#nyhhcasobv .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#nyhhcasobv .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#nyhhcasobv .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#nyhhcasobv .gt_left {
  text-align: left;
}

#nyhhcasobv .gt_center {
  text-align: center;
}

#nyhhcasobv .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#nyhhcasobv .gt_font_normal {
  font-weight: normal;
}

#nyhhcasobv .gt_font_bold {
  font-weight: bold;
}

#nyhhcasobv .gt_font_italic {
  font-style: italic;
}

#nyhhcasobv .gt_super {
  font-size: 65%;
}

#nyhhcasobv .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#nyhhcasobv .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#nyhhcasobv .gt_indent_1 {
  text-indent: 5px;
}

#nyhhcasobv .gt_indent_2 {
  text-indent: 10px;
}

#nyhhcasobv .gt_indent_3 {
  text-indent: 15px;
}

#nyhhcasobv .gt_indent_4 {
  text-indent: 20px;
}

#nyhhcasobv .gt_indent_5 {
  text-indent: 25px;
}

#nyhhcasobv .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#nyhhcasobv div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false"><caption>Table&nbsp;1:  <p>Résultats de la regression logistique</p> </caption>
  <thead>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="label"><span data-qmd-base64="PHN0cm9uZz5DaGFyYWN0ZXJpc3RpYzwvc3Ryb25nPg=="><span class="gt_from_md"><strong>Characteristic</strong></span></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="estimate"><span data-qmd-base64="PHN0cm9uZz5PUjwvc3Ryb25nPg=="><span class="gt_from_md"><strong>OR</strong></span></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="conf.low"><span data-qmd-base64="PHN0cm9uZz45NSUgQ0k8L3N0cm9uZz4="><span class="gt_from_md"><strong>95% CI</strong></span></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="p.value"><span data-qmd-base64="PHN0cm9uZz5wLXZhbHVlPC9zdHJvbmc+"><span class="gt_from_md"><strong>p-value</strong></span></span></th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="label" class="gt_row gt_left">(Intercept)</td>
<td headers="estimate" class="gt_row gt_center">0.97</td>
<td headers="conf.low" class="gt_row gt_center">0.71, 1.34</td>
<td headers="p.value" class="gt_row gt_center">0.9</td></tr>
    <tr><td headers="label" class="gt_row gt_left">perimeter_mean</td>
<td headers="estimate" class="gt_row gt_center">9.64</td>
<td headers="conf.low" class="gt_row gt_center">3.43, 28.9</td>
<td headers="p.value" class="gt_row gt_center">&lt;0.001</td></tr>
    <tr><td headers="label" class="gt_row gt_left">smoothness_mean</td>
<td headers="estimate" class="gt_row gt_center">1.19</td>
<td headers="conf.low" class="gt_row gt_center">0.70, 2.05</td>
<td headers="p.value" class="gt_row gt_center">0.5</td></tr>
    <tr><td headers="label" class="gt_row gt_left">fractal_dimension_mean</td>
<td headers="estimate" class="gt_row gt_center">0.77</td>
<td headers="conf.low" class="gt_row gt_center">0.46, 1.26</td>
<td headers="p.value" class="gt_row gt_center">0.3</td></tr>
    <tr><td headers="label" class="gt_row gt_left">concave points_mean</td>
<td headers="estimate" class="gt_row gt_center">25.1</td>
<td headers="conf.low" class="gt_row gt_center">8.38, 82.0</td>
<td headers="p.value" class="gt_row gt_center">&lt;0.001</td></tr>
  </tbody>
  <tfoot class="gt_sourcenotes">
    <tr>
      <td class="gt_sourcenote" colspan="4"><span data-qmd-base64="QWJicmV2aWF0aW9uczogQ0kgPSBDb25maWRlbmNlIEludGVydmFsLCBPUiA9IE9kZHMgUmF0aW8="><span class="gt_from_md">Abbreviations: CI = Confidence Interval, OR = Odds Ratio</span></span></td>
    </tr>
  </tfoot>
  
</table>
</div>
</div>
</div>
</div>
<p><strong>Interprétation :</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Nous avons ajusté un modèle de régression logistique sur les variables standardisées en tenant compte du déséquilibre entre les classes grâce à une pondération.</p>
<ul>
<li><p>Une augmentation d’un écart-type du <strong>périmètre moyen</strong> (<code>perimeter_mean</code>) multiplie par environ <strong>9.7</strong> les chances d’avoir un diagnostic malin, ce qui est très significatif (p &lt; 0.001).</p></li>
<li><p>Une augmentation d’un écart-type du <strong>nombre moyen de points concaves</strong> (<code>concave points_mean</code>) multiplie par environ <strong>25.0</strong> les chances d’avoir un diagnostic malin, indiquant un effet très fort et hautement significatif (p &lt; 0.001).</p></li>
<li><p>Les variables <strong>lissage moyen</strong> (<code>smoothness_mean</code>) et <strong>dimension fractale moyenne</strong> (<code>fractal_dimension_mean</code>) n’ont pas d’effet significatif sur le diagnostic, leurs odds ratios étant proches de 1 et leurs intervalles de confiance incluant 1.</p></li>
</ul>
<p>Ces résultats montrent que le <strong>périmètre moyen</strong> et le <strong>nombre moyen de points concaves</strong> sont des prédicteurs majeurs du diagnostic malin.<br>
La standardisation des variables permet une interprétation harmonisée des coefficients sur une même échelle, facilitant la comparaison de l’impact relatif de chaque variable.</p>
</section>
<section id="prédiction-du-diagnostic-par-apprentissage-automatique-logit-vs-knn" class="level2">
<h2 class="anchored" data-anchor-id="prédiction-du-diagnostic-par-apprentissage-automatique-logit-vs-knn">Prédiction du diagnostic par apprentissage automatique <code>Logit</code> vs <code>KNN</code></h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dans la partie <strong>régression logistique</strong>, nous avons utilisé l’argument <code>class_weight='balanced'</code> afin de corriger le déséquilibre des classes en attribuant automatiquement un poids inversement proportionnel à leur fréquence.</p>
<p>Pour le modèle <strong>K-plus proches voisins</strong> (<code>K-NN</code>), nous avons appliqué la technique <code>SMOTE (Synthetic Minority Over-sampling Technique)</code> afin de générer des observations synthétiques de la classe minoritaire dans les données d’apprentissage, améliorant ainsi la capacité du modèle à détecter les cas rares.</p>
<div id="fig-métrique" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-métrique-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Breast-Tumor-Article_files/figure-html/fig-métrique-1.png" class="img-fluid figure-img" data-ref-parent="fig-métrique"></p>
<figcaption class="figure-caption">(a) Resultat de notre modèle VS celui de Sci-kit Learn</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-métrique-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Breast-Tumor-Article_files/figure-html/fig-métrique-2.png" class="img-fluid figure-img" data-ref-parent="fig-métrique"></p>
<figcaption class="figure-caption">(b) Moyennes des erreurs quadratiques moyennes</figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;5: Métriques des modèles durant la validation croisée</figcaption><p></p>
</figure>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;La figure ci-dessus présente les métriques d’évaluations des différents modèles ajustés. Elle montre que la <strong>régression logistique</strong> affiche une excellente performance avec une accuracy moyenne de <strong>91 %</strong> et un <code>AUC ROC</code> élevé de <strong>97,5 %</strong>, témoignant d’une très bonne séparation des classes. Elle maintient un bon équilibre entre <code>rappel</code> (<strong>89,1 %</strong>) et <code>précision</code> (<strong>87,3 %</strong>), garantissant une détection fiable des positifs tout en limitant les faux positifs.</p>
<p>De son côté, le <strong>KNN avec SMOTE</strong> présente une performance solide avec une accuracy moyenne de <strong>86,7 %</strong> et un <code>AUC ROC</code> de <strong>95,5 %</strong>, reflétant une bonne capacité à distinguer les classes. Le modèle équilibre efficacement rappel (<strong>86,4 %</strong>) et précision (<strong>80,2 %</strong>), ce qui est essentiel pour détecter les cas positifs sans trop d’erreurs.</p>
<p>La régression logistique surpasse légèrement le <strong>KNN avec SMOTE</strong> en termes de performance globale, offrant une meilleure accuracy et un <code>AUC ROC</code> supérieur, tandis que le <strong>KNN</strong> reste compétitif grâce à un bon équilibre entre rappel et précision.</p>
<blockquote class="blockquote">
<p>On applique SMOTE uniquement sur l’ensemble d’entraînement (jamais sur le test, pour éviter les fuites de données). On conserve le test original non modifié pour une évaluation honnête. La régression logistique gère le déséquilibre avec class_weight=‘balanced’. Le KNN ne gère pas ce paramètre, donc on utilise SMOTE pour créer artificiellement des exemples de la classe minoritaire dans l’entraînement.</p>
</blockquote>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Après avoir comparé les performances des modèles via la validation croisée, il est maintenant pertinent d’entraîner le modèle final sélectionné sur l’ensemble des données d’entraînement afin d’optimiser son apprentissage avant l’évaluation finale. Ceci étant le modèle a été ajusté sur données d’entraînement et ensuite évalué.</p>
<div class="cell">
<div class="cell-output-display">
<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked=""><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)</pre></div></div></div></div></div>
</div>
<div class="cell-output-display">
<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked=""><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsClassifier</label><div class="sk-toggleable__content"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>
</div>
</div>
<ul>
<li><strong>Exactitude des modèles</strong></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Les modèles de <strong>régression logistique</strong> et de <em>KNN</em> présentent des exactitudes respectives sur les données d’entraînement de <strong>91,21 %</strong> et <strong>93,22 %</strong>. Sur les données de test, la régression logistique obtient une meilleure performance avec une accuracy de <strong>93,57 %</strong>, tandis que le <strong>KNN</strong> atteint <strong>90,06 %</strong>, indiquant que la <strong>régression logistique</strong> généralise légèrement mieux.</p>
<p>La <strong>régression logistique</strong> semble mieux généraliser que le KNN, avec une accuracy plus élevée sur les données de test malgré une performance légèrement inférieure à l’entraînement. Cela suggère que le modèle de <strong>régression logistique</strong> est moins sujet au <code>surapprentissage</code> et offre une meilleure <code>robustesse</code> pour la prédiction sur de nouvelles données. En revanche, le <strong>KNN</strong>, bien qu’ayant une meilleure performance à l’entraînement, montre une légère baisse en test, ce qui peut indiquer un certain <code>surajustement</code> aux données d’entraînement.</p>
<ul>
<li><strong>La fonction de coût ou de perte (log-loss)des modèles</strong></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;La <code>log-loss</code> est une mesure utile pour la régression logistique, qui reflète la qualité probabiliste des prédictions.</p>
<ul>
<li><p><strong>La regression logistique</strong> :</p>
<ul>
<li><p><code>Log-loss train (0.1983)</code> et <code>log-loss test (0.1895)</code> sont très proches, et <strong>la perte est même légèrement meilleure (plus faible) sur le test</strong>.</p></li>
<li><p>Cela indique que le modèle ne souffre pas de surapprentissage significatif — il généralise bien sur les données nouvelles.</p></li>
</ul></li>
<li><p><strong>Le <code>KNN</code></strong> :</p></li>
</ul>
<p>Le KNN n’optimise pas explicitement une fonction de perte pendant l’entraînement — c’est un algorithme instance-based, il mémorise les exemples.</p>
<p>On ne peut donc pas parler de “loss” au sens d’une fonction de coût minimisée.</p>
<p>Mais on peut évaluer la performance via la classification error <span class="math inline">\((1 - accuracy)\)</span> ou d’autres métriques.</p>
<ul>
<li><strong>Matrices de confusion</strong></li>
</ul>
<div id="fig-confusion-matrix" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-confusion-matrix-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Breast-Tumor-Article_files/figure-html/fig-confusion-matrix-5.png" class="img-fluid figure-img" data-ref-parent="fig-confusion-matrix" width="480"></p>
<figcaption class="figure-caption">(a) Matrice de confusion - Régression Logistique</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-confusion-matrix-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Breast-Tumor-Article_files/figure-html/fig-confusion-matrix-6.png" class="img-fluid figure-img" data-ref-parent="fig-confusion-matrix" width="480"></p>
<figcaption class="figure-caption">(b) Matrice de confusion - KNN</figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;6: Comparaison des ML (Logit vs KNN - Matrices de confusion)</figcaption><p></p>
</figure>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;La matrice de confusion, illustrée sur la figure ci-dessus, sert à évaluer la performance d’un modèle de classification en détaillant le nombre de prédictions correctes et incorrectes réparties entre les différentes classes. Elle permet de visualiser les vrais positifs, vrais négatifs, faux positifs et faux négatifs, offrant ainsi une compréhension précise des erreurs du modèle.</p>
<p>Dans ce cas, la matrice montre que la <strong>régression logistique</strong> réalise une meilleure classification que le <strong>KNN</strong>, avec plus de vrais positifs et vrais négatifs, et moins d’erreurs, ce qui confirme sa supériorité pour ce problème.</p>
<p>Plus précisement, on observe que le modèle <code>KNN</code> présente une performance de prédiction légèrement inférieure par rapport au modèle de régression logistique, comme le montre la matrice de confusion :</p>
<ul>
<li><code>97</code> vrais négatifs (vrais bénins) contre <code>101</code> pour le modèle logit<br>
</li>
<li><code>57</code> vrais positifs (vrais malins) contre <code>59</code> pour le modèle logit<br>
</li>
<li><code>7</code> faux positifs (faux malins) contre <code>5</code> pour le modèle logit<br>
</li>
<li><code>10</code> faux négatifs (faux bénins) contre <code>6</code> pour le modèle logit</li>
</ul>
<p>Ces résultats indiquent que la régression logistique détecte un peu mieux les classes, avec moins d’erreurs de classification que le KNN.</p>
<ul>
<li><strong><code>Précision</code>, <code>recall</code>, <code>score F1</code>, <code>AUC</code></strong></li>
</ul>
<div id="tbl-class-rep" class="cell tbl-parent quarto-layout-panel anchored">
<div class="panel-caption table-caption">
<p>Rapport de classification des modèles ajustés</p>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="table table-striped table-hover table-condensed table-sm small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
1
</div></th>
<th colspan="5" data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Rapport de classification - Regression logistique
</div></th>
</tr>
<tr class="odd">
<th style="text-align: center;" data-quarto-table-cell-role="th">Modèle</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Classe</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Précision</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Recall</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">F1_Score</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Support</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center; font-weight: bold;">Régression Logistique</td>
<td style="text-align: center;">Benin</td>
<td style="text-align: center;">0.9528</td>
<td style="text-align: center;">0.9439</td>
<td style="text-align: center;">0.9484</td>
<td style="text-align: center;">107</td>
</tr>
<tr class="even">
<td style="text-align: center; font-weight: bold;">Régression Logistique</td>
<td style="text-align: center;">Malin</td>
<td style="text-align: center;">0.9077</td>
<td style="text-align: center;">0.9219</td>
<td style="text-align: center;">0.9147</td>
<td style="text-align: center;">64</td>
</tr>
<tr class="odd">
<td style="text-align: center; font-weight: bold;">Régression Logistique</td>
<td style="text-align: center;">Accuracy</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">0.9357</td>
<td style="text-align: center;">171</td>
</tr>
<tr class="even">
<td style="text-align: center; font-weight: bold;">Régression Logistique</td>
<td style="text-align: center;">Macro avg</td>
<td style="text-align: center;">0.9303</td>
<td style="text-align: center;">0.9329</td>
<td style="text-align: center;">0.9315</td>
<td style="text-align: center;">171</td>
</tr>
<tr class="odd">
<td style="text-align: center; font-weight: bold;">Régression Logistique</td>
<td style="text-align: center;">Weighted avg</td>
<td style="text-align: center;">0.9359</td>
<td style="text-align: center;">0.9357</td>
<td style="text-align: center;">0.9358</td>
<td style="text-align: center;">171</td>
</tr>
<tr class="even">
<td style="text-align: center; font-weight: bold;">Régression Logistique</td>
<td style="text-align: center;">AUC ROC</td>
<td style="text-align: center;">0.9816</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
</tr>
</tbody>
</table>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">


</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="table table-striped table-hover table-condensed table-sm small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
1
</div></th>
<th colspan="5" data-quarto-table-cell-role="th" style="text-align: center; border-bottom: hidden; padding-bottom: 0; padding-left: 3px; padding-right: 3px;"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Rapport de classification - KNN
</div></th>
</tr>
<tr class="odd">
<th style="text-align: center;" data-quarto-table-cell-role="th">Modèle</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Classe</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Précision</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Recall</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">F1_Score</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Support</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center; font-weight: bold;">KNN</td>
<td style="text-align: center;">Benin</td>
<td style="text-align: center;">0.9327</td>
<td style="text-align: center;">0.9065</td>
<td style="text-align: center;">0.9194</td>
<td style="text-align: center;">107</td>
</tr>
<tr class="even">
<td style="text-align: center; font-weight: bold;">KNN</td>
<td style="text-align: center;">Malin</td>
<td style="text-align: center;">0.8507</td>
<td style="text-align: center;">0.8906</td>
<td style="text-align: center;">0.8702</td>
<td style="text-align: center;">64</td>
</tr>
<tr class="odd">
<td style="text-align: center; font-weight: bold;">KNN</td>
<td style="text-align: center;">Accuracy</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">0.9006</td>
<td style="text-align: center;">171</td>
</tr>
<tr class="even">
<td style="text-align: center; font-weight: bold;">KNN</td>
<td style="text-align: center;">Macro avg</td>
<td style="text-align: center;">0.8917</td>
<td style="text-align: center;">0.8986</td>
<td style="text-align: center;">0.8948</td>
<td style="text-align: center;">171</td>
</tr>
<tr class="odd">
<td style="text-align: center; font-weight: bold;">KNN</td>
<td style="text-align: center;">Weighted avg</td>
<td style="text-align: center;">0.9020</td>
<td style="text-align: center;">0.9006</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">171</td>
</tr>
<tr class="even">
<td style="text-align: center; font-weight: bold;">KNN</td>
<td style="text-align: center;">AUC ROC</td>
<td style="text-align: center;">0.9572</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
</tr>
</tbody>
</table>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">


</div>
</div>
</div>
<ul>
<li><p><strong>Rapport de classification de la Régression Logistique</strong></p></li>
<li><p><strong>Exactitude globale (accuracy) :</strong> <code>93,03 %</code>, ce qui signifie que le modèle classe correctement environ <code>93 patients sur 100</code>.</p></li>
<li><p><strong>Précision par classe :</strong></p>
<ul>
<li><p>Pour la classe bénigne (<span class="math inline">\(B\)</span>), la précision est de <code>95,28 %</code>, indiquant une bonne détection des cas bénins.</p></li>
<li><p>Pour la classe maligne (<span class="math inline">\(M\)</span>), la précision est de <code>90,77 %</code>, également satisfaisante. Mais cet écart de précision pourraît être attribué au déquilibre des reponses (<code>Benin</code> et <code>Malin</code>) et cela malgré la stratification et la pondération. Toutefois les métriques telles que <code>F1-Scrore</code> et <code>AUC</code> sont moins sensibles au déséquilibre des classes de la variable reponse (ici la catégorie de tumeur).</p></li>
</ul></li>
<li><p><strong>Rappel (sensibilité) :</strong></p>
<ul>
<li>Classe bénigne : <code>94,39 %</code>, montrant une bonne capacité à détecter les vrais positifs bénins.<br>
</li>
<li>Classe maligne : <code>92,19 %</code>, un peu moins élevée. L’explication donnée en ammont est également valide ici.</li>
</ul></li>
<li><p><strong>F1-score :</strong> <code>94,84 %</code> pour la classe bénigne et <code>91,47 %</code> pour la classe maligne, indiquant un bon équilibre global entre précision et rappel.</p></li>
<li><p><strong>AUC ROC :</strong> <code>0,98116</code>, proche de 1, ce qui montre une excellente capacité de discrimination.</p></li>
</ul>
<hr>
<ul>
<li><p><strong>Rapport de classification d uKNN (K plus proches voisins)</strong></p></li>
<li><p><strong>Exactitude globale (accuracy) :</strong> <code>91,26 %</code>, moins bonne que celle la régression logistique.</p></li>
<li><p><strong>Précision par classe :</strong></p>
<ul>
<li><p>Pour la classe bénigne (<span class="math inline">\(B\)</span>), la précision est de <code>93,46 %</code>, moins bonne que celle la régression logistique.</p></li>
<li><p>Pour la classe maligne (<span class="math inline">\(M\)</span>), la précision est de <code>89, 06%</code>, légèrement inférieure à la régression logistique.</p></li>
</ul></li>
<li><p><strong>Rappel (sensibilité) :</strong></p>
<ul>
<li><p>Classe bénigne : <code>93,46 %</code>, un peu plus faible que le rappel du modèle logit.</p></li>
<li><p>Classe maligne : <code>89, 06%</code>, meilleure que celui de la régression logistique.</p></li>
</ul></li>
<li><p><strong>F1-score :</strong> <code>93,46 %</code> pour la classe bénigne et <code>89,06 %</code> pour la classe maligne. Ces scores sont tous deux inférieurs à celui de la régression logistique.</p></li>
<li><p><strong>AUC ROC :</strong> <code>0,9632</code>, très élevé, mais un peu inférieur à celui de la régression logistique.</p></li>
<li><p><strong>Conclusion partielle </strong></p></li>
</ul>
<p>Les deux modèles présentent des performances globalement comparables pour différencier les patients bénins et malins :</p>
<ul>
<li><p>La <strong>régression logistique</strong> obtient une <strong>meilleure précision globale</strong> ainsi qu’un <strong>meilleur équilibre du F1-score</strong>, notamment pour la classe bénigne, témoignant d’une bonne capacité à limiter les erreurs dans cette catégorie.</p></li>
<li><p>Le <strong>KNN</strong> offre un <strong>rappel plus élevé</strong> pour la classe bénigne et une <strong>bonne AUC ROC</strong>, indiquant une capacité correcte de discrimination globale.</p></li>
</ul>
<p>Cependant, la régression logistique se révèle plus <strong>stable et robuste</strong>, avec une meilleure capacité de <strong>généralisation</strong>. En effet, bien que le KNN affiche un rappel plus important, il présente un risque accru de <strong>surajustement</strong>, ce qui peut nuire à ses performances sur des données très différentes de celles utilisées pour l’entraînement.</p>
<hr>
</section>
</section>
<section id="conclusion-générale" class="level1">
<h1>Conclusion générale</h1>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dans cette étude, nous avons exploré un jeu de données complexe en appliquant d’abord une analyse en composantes principales (<code>ACP</code>) afin de réduire la dimensionnalité et d’identifier les variables les plus informatives.</p>
<p>Une classification non supervisée par <code>KMeans</code> a ensuite été réalisée pour vérifier que cette réduction du nombre de variables ne compromettait pas la structure intrinsèque des données.</p>
<p>La méthode <code>KMeans</code> a permis de regrouper les observations en clusters distincts, confirmant ainsi la présence de groupes homogènes correspondant aux classes <code>B</code> (bénin) et <code>M</code> (malin). Cette étape a validé que la projection sur les composantes principales préservait efficacement la séparation entre ces classes, renforçant la confiance dans la sélection des variables.</p>
<p>Nous avons ajusté un modèle de régression logistique sur les variables standardisées en tenant compte du déséquilibre entre les classes grâce à une pondération.<br>
Les résultats montrent qu’une augmentation d’un écart-type du <strong>périmètre moyen</strong> (<code>perimeter_mean</code>) multiplie par environ <strong>9.7</strong> les chances d’avoir un diagnostic malin, tandis qu’une augmentation d’un écart-type du <strong>nombre moyen de points concaves</strong> (<code>concave points_mean</code>) multiplie ces chances par environ <strong>25.0</strong>, indiquant un effet très fort et hautement significatif (p &lt; 0.001).<br>
En revanche, les variables <strong>lissage moyen</strong> (<code>smoothness_mean</code>) et <strong>dimension fractale moyenne</strong> (<code>fractal_dimension_mean</code>) n’ont pas d’effet significatif, leurs odds ratios étant proches de 1.<br>
La standardisation des variables permet une interprétation harmonisée des coefficients, facilitant la comparaison de l’impact relatif de chaque variable.</p>
<p>La sélection des variables, basée sur des critères statistiques rigoureux, a permis de retenir un ensemble pertinent de caractéristiques discriminantes entre les deux classes.</p>
<p>Nous avons ensuite mis en œuvre deux méthodes de classification supervisée :</p>
<ul>
<li><p>Le k plus proches voisins (<code>KNN</code>), un modèle simple et non paramétrique, capable de capturer efficacement les similarités entre observations ;</p></li>
<li><p>La régression logistique (<code>logit</code>), un modèle probabiliste permettant d’estimer explicitement les probabilités d’appartenance à chaque classe et d’interpréter l’impact des variables explicatives.</p></li>
</ul>
<p>Ainsi, cette démarche combinant réduction de dimension, sélection rigoureuse des variables, et modélisation par <code>KNN</code> et <code>logit</code> constitue une méthodologie robuste pour la classification et l’analyse de données biologiques ou médicales.</p>
<p><strong><em>La régression logistique est globalement préférable dans ce cas, car elle offre une performance plus équilibrée, une meilleure capacité discriminante (AUC) et une stabilité importante, ce qui la rend plus fiable pour un usage clinique ou opérationnel.</em></strong></p>
<p>Pour des applications strictement prédictives, où l’interprétabilité des facteurs explicatifs est moins prioritaire, des modèles plus complexes tels que <strong>XGBoost</strong> peuvent être envisagés. Cette méthode de gradient boosting permet souvent d’améliorer la précision en capturant des relations non linéaires complexes, bien que cela se fasse au détriment de la transparence du modèle.</p>
<hr>
</section>
<section id="annexes" class="level1">
<h1>Annexes</h1>
<section id="annexe-0-corrélogramme-des-variables-quantitatives" class="level2">
<h2 class="anchored" data-anchor-id="annexe-0-corrélogramme-des-variables-quantitatives">Annexe 0 : Corrélogramme des variables quantitatives</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output cell-output-stdout">
<pre><code>(array([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]), [Text(0.5, 0, 'radius_mean'), Text(1.5, 0, 'texture_mean'), Text(2.5, 0, 'perimeter_mean'), Text(3.5, 0, 'area_mean'), Text(4.5, 0, 'smoothness_mean'), Text(5.5, 0, 'compactness_mean'), Text(6.5, 0, 'concavity_mean'), Text(7.5, 0, 'concave points_mean'), Text(8.5, 0, 'symmetry_mean'), Text(9.5, 0, 'fractal_dimension_mean')])</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>(array([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]), [Text(0, 0.5, 'radius_mean'), Text(0, 1.5, 'texture_mean'), Text(0, 2.5, 'perimeter_mean'), Text(0, 3.5, 'area_mean'), Text(0, 4.5, 'smoothness_mean'), Text(0, 5.5, 'compactness_mean'), Text(0, 6.5, 'concavity_mean'), Text(0, 7.5, 'concave points_mean'), Text(0, 8.5, 'symmetry_mean'), Text(0, 9.5, 'fractal_dimension_mean')])</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-corr-one" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Breast-Tumor-Article_files/figure-html/fig-corr-one-1.png" style="width:90.0%;height:95.0%" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;7: Corrélogramme des variables quantitatives</figcaption>
</figure>
</div>
</div>
</div>
<hr>
</section>
<section id="annexe-1-pourcentages-des-variances-expliquées-par-les-composantes-principales" class="level2">
<h2 class="anchored" data-anchor-id="annexe-1-pourcentages-des-variances-expliquées-par-les-composantes-principales">Annexe 1 : Pourcentages des variances expliquées par les composantes principales</h2>
<div class="cell">
<div class="cell-output-display">
<div id="fig-inertie-val" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Breast-Tumor-Article_files/figure-html/fig-inertie-val-3.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;8: Diagramme des variances expliquées par les composantes principales</figcaption>
</figure>
</div>
</div>
</div>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;On observe le coude à partie de la troisième dimension. Mais en se basant sur le critère du taux d’inertie on a environ <strong>80%</strong> de l’information conténue dans les données. Par conséquent notre analyse sera axée sur les deux premiers axes.</p>
<hr>
</section>
<section id="annexe-2-hypothèses-et-interprétations-des-tests-statistiques" class="level2">
<h2 class="anchored" data-anchor-id="annexe-2-hypothèses-et-interprétations-des-tests-statistiques">Annexe 2 : Hypothèses et interprétations des tests statistiques</h2>
<section id="test-de-shapiro-wilk" class="level3">
<h3 class="anchored" data-anchor-id="test-de-shapiro-wilk"><strong>Test de Shapiro-Wilk</strong></h3>
<p>Ce test permet de vérifier la <strong>normalité</strong> d’une distribution.</p>
<ul>
<li><p><strong>Hypothèses</strong> : <span class="math display">\[
\begin{cases}
H_0 : \text{Les données suivent une loi normale} \\
H_1 : \text{Les données ne suivent pas une loi normale}
\end{cases}
\]</span></p></li>
<li><p><strong>Interprétation de la <span class="math inline">\(p\)</span>-valeur</strong> :</p>
<ul>
<li>Si <span class="math inline">\(p &gt; 0.05\)</span> : on <strong>ne rejette pas</strong> <span class="math inline">\({H_0}\)</span> <span class="math inline">\(\Rightarrow\)</span> les données peuvent être considérées comme <strong>normales</strong>.</li>
<li>Si <span class="math inline">\(p \leq 0.05\)</span> : on <strong>rejette</strong> <span class="math inline">\({H_0}\)</span> <span class="math inline">\(\Rightarrow\)</span> les données <strong>ne sont pas normales</strong>.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="test-de-levene" class="level3">
<h3 class="anchored" data-anchor-id="test-de-levene"><strong>Test de Levene</strong></h3>
<p>Ce test permet de vérifier l’<strong>homogénéité des variances</strong> entre les groupes.</p>
<ul>
<li><p><strong>Hypothèses</strong> : <span class="math display">\[
\begin{cases}
H_0 : \text{Les variances des groupes sont égales} \\
H_1 : \text{Les variances des groupes sont différentes}
\end{cases}
\]</span></p></li>
<li><p><strong>Interprétation de la <span class="math inline">\(p\)</span>-valeur</strong> :</p>
<ul>
<li>Si <span class="math inline">\(p &gt; 0.05\)</span> : on <strong>ne rejette pas</strong> <span class="math inline">\({H_0}\)</span> <span class="math inline">\(\Rightarrow\)</span> les variances sont <strong>homogènes</strong>.</li>
<li>Si <span class="math inline">\(p \leq 0.05\)</span> : on <strong>rejette</strong> <span class="math inline">\({H_0}\)</span> <span class="math inline">\(\Rightarrow\)</span> les variances sont <strong>différentes</strong>.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="test-danova-classique" class="level3">
<h3 class="anchored" data-anchor-id="test-danova-classique"><strong>Test d’ANOVA classique</strong></h3>
<p>Ce test compare les <strong>moyennes</strong> de plusieurs groupes. Il nécessite que les données soient <strong>normales</strong> et que les variances soient <strong>homogènes</strong>.</p>
<ul>
<li><p><strong>Hypothèses</strong> : <span class="math display">\[
\begin{cases}
H_0 : \mu_1 = \mu_2 = \cdots = \mu_k \\
H_1 : \exists \, i \ne j \text{ tel que } \mu_i \ne \mu_j
\end{cases}
\]</span></p></li>
<li><p><strong>Interprétation de la <span class="math inline">\(p\)</span>-valeur</strong> :</p>
<ul>
<li>Si <span class="math inline">\(p &gt; 0.05\)</span> : on <strong>ne rejette pas</strong> <span class="math inline">\({H_0}\)</span> <span class="math inline">\(\Rightarrow\)</span> les moyennes sont <strong>statistiquement égales</strong>.</li>
<li>Si <span class="math inline">\(p \leq 0.05\)</span> : on <strong>rejette</strong> <span class="math inline">\({H_0}\)</span> <span class="math inline">\(\Rightarrow\)</span> au moins une moyenne est <strong>différente</strong>.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="test-danova-de-welch" class="level3">
<h3 class="anchored" data-anchor-id="test-danova-de-welch"><strong>Test d’ANOVA de Welch</strong></h3>
<p>Ce test est une <strong>version robuste de l’ANOVA</strong> utilisée lorsque l’<strong>homogénéité des variances n’est pas respectée</strong>, mais que les données restent normales.</p>
<ul>
<li><p><strong>Hypothèses</strong> : <span class="math display">\[
\begin{cases}
H_0 : \mu_1 = \mu_2 = \cdots = \mu_k \\
H_1 : \exists \, i \ne j \text{ tel que } \mu_i \ne \mu_j
\end{cases}
\]</span></p></li>
<li><p><strong>Interprétation de la <span class="math inline">\(p\)</span>-valeur</strong> : identique à celle du test ANOVA classique.</p></li>
</ul>
<hr>
</section>
<section id="test-de-kruskal-wallis" class="level3">
<h3 class="anchored" data-anchor-id="test-de-kruskal-wallis"><strong>Test de Kruskal-Wallis</strong></h3>
<p>Test non paramétrique utilisé en cas de <strong>non-normalité</strong> ou lorsque les données sont <strong>ordinales</strong>.</p>
<ul>
<li><p><strong>Hypothèses</strong> : <span class="math display">\[
\begin{cases}
H_0 : \text{Les distributions des groupes sont identiques} \\
H_1 : \text{Au moins une distribution est différente}
\end{cases}
\]</span></p></li>
<li><p><strong>Interprétation de la <span class="math inline">\(p\)</span>-valeur</strong> :</p>
<ul>
<li>Si <span class="math inline">\(p &gt; 0.05\)</span> : on <strong>ne rejette pas</strong> <span class="math inline">\({H_0}\)</span> <span class="math inline">\(\Rightarrow\)</span> les distributions sont considérées comme <strong>similaires</strong>.</li>
<li>Si <span class="math inline">\(p \leq 0.05\)</span> : on <strong>rejette</strong> <span class="math inline">\({H_0}\)</span> <span class="math inline">\(\Rightarrow\)</span> <strong>au moins une</strong> des distributions <strong>diffère significativement</strong>.</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>Remarque : Tous ces tests renvoient une <strong><span class="math inline">\(p\)</span>-valeur</strong> qui est comparée au seuil de signification habituellement fixé à <strong>5%</strong> (<span class="math inline">\(\alpha = 0.05\)</span>).</p>
</blockquote>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>###Analyse de : radius_mean selon diagnosis 

- Groupe B : p = 0.668 
- Groupe M : p = 0.0019 

- Test de Levene : p = 0 (variances non homogènes) 

Données non normales → Test de Wilcoxon-Mann-Whitney
$$\text{Test de Wilcoxon-Mann-Whitney}$$
**Hypothèses :**
- {H_0} : les distributions des deux groupes sont égales
- {H_1} : les distributions sont différentes

**Résultat du test :** p = 0 
=&gt; Rejet de {H_0} : différence significative entre les groupes.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>###Analyse de : area_mean selon diagnosis 

- Groupe B : p = 0.0228 
- Groupe M : p = 0 

- Test de Levene : p = 0 (variances non homogènes) 

Données non normales → Test de Wilcoxon-Mann-Whitney
$$\text{Test de Wilcoxon-Mann-Whitney}$$
**Hypothèses :**
- {H_0} : les distributions des deux groupes sont égales
- {H_1} : les distributions sont différentes

**Résultat du test :** p = 0 
=&gt; Rejet de {H_0} : différence significative entre les groupes.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>###Analyse de : perimeter_mean selon diagnosis 

- Groupe B : p = 0.7795 
- Groupe M : p = 4e-04 

- Test de Levene : p = 0 (variances non homogènes) 

Données non normales → Test de Wilcoxon-Mann-Whitney
$$\text{Test de Wilcoxon-Mann-Whitney}$$
**Hypothèses :**
- {H_0} : les distributions des deux groupes sont égales
- {H_1} : les distributions sont différentes

**Résultat du test :** p = 0 
=&gt; Rejet de {H_0} : différence significative entre les groupes.</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="annexe-4-rapport-de-corrélation" class="level2">
<h2 class="anchored" data-anchor-id="annexe-4-rapport-de-corrélation">Annexe 4: Rapport de corrélation</h2>
<p>Le rapport de corrélation <span class="math inline">\(\eta^2\)</span> est une mesure de l’effet qui quantifie la proportion de la variance expliquée par un facteur.</p>
<p>Il est défini par la formule suivante :</p>
<p><span class="math display">\[
\eta^2 = \frac{\sum_{i=1}^{k} n_i (\bar{y}_i - \bar{y})^2}{\sum_{i=1}^{k} \sum_{j=1}^{n_i} (y_{ij} - \bar{y})^2}
\]</span></p>
<p>où :</p>
<ul>
<li><span class="math inline">\(k\)</span> est le nombre de groupes,</li>
<li><span class="math inline">\(n_i\)</span> est la taille du groupe <span class="math inline">\(i\)</span>,</li>
<li><span class="math inline">\(\bar{y}_i\)</span> est la moyenne du groupe <span class="math inline">\(i\)</span>,</li>
<li><span class="math inline">\(\bar{y}\)</span> est la moyenne globale,</li>
<li><span class="math inline">\(y_{ij}\)</span> est l’observation <span class="math inline">\(j\)</span> du groupe <span class="math inline">\(i\)</span>.</li>
</ul>
<p>Cette mesure permet d’évaluer l’ampleur de la différence entre les groupes, en indiquant la proportion de la variance totale attribuable à la variation entre groupes.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5329416</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5026581</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5515075</code></pre>
</div>
</div>
<hr>
</section>
<section id="annexe-5-pondération-des-observations-pour-corriger-le-déséquilibre-des-classes" class="level2">
<h2 class="anchored" data-anchor-id="annexe-5-pondération-des-observations-pour-corriger-le-déséquilibre-des-classes">Annexe 5: Pondération des observations pour corriger le déséquilibre des classes</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dans notre jeu de données, la variable cible <code>diagnosis</code> est déséquilibrée : les tumeurs bénignes (<code>B</code>) sont plus fréquentes que les tumeurs malignes (<code>M</code>). Cette inégalité peut biaiser l’apprentissage du modèle en le poussant à favoriser la classe majoritaire, au détriment de la détection correcte des cas malins, pourtant plus critiques en pratique clinique.</p>
<p>Afin de corriger ce déséquilibre, nous avons introduit une <strong>pondération des observations</strong> dans le modèle de régression logistique. Concrètement, chaque observation maligne s’est vue attribuer un poids défini comme suit :</p>
<p><span class="math display">\[
w_i =
\begin{cases}
1, &amp; \text{si } diagnosis_i = \texttt{B} \\
\frac{p_B}{p_M}, &amp; \text{si } diagnosis_i = \texttt{M}
\end{cases}
\]</span></p>
<p>où <span class="math inline">\(p_B\)</span> et <span class="math inline">\(p_M\)</span> représentent respectivement les proportions de cas bénins et malins dans l’échantillon. Cette pondération permet de <strong>renforcer l’importance des observations rares</strong> (les cas malins) et de <strong>rééquilibrer l’influence des deux classes</strong> lors de l’ajustement du modèle.</p>
<p>Ainsi, le modèle devient plus robuste face au déséquilibre et améliore sa capacité à détecter les tumeurs malignes, ce qui est crucial dans un contexte médical.</p>
<hr>
</section>
<section id="annexe-6-codes" class="level2">
<h2 class="anchored" data-anchor-id="annexe-6-codes">Annexe 6: Codes</h2>
<ul>
<li><strong>Chargement des packages, des données et standardisation des variables</strong></li>
</ul>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Importation des librairies nécessaires</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix, roc_auc_score, roc_curve</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> SMOTE</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.loc[:, [<span class="st">"diagnosis"</span>, <span class="st">"perimeter_mean"</span>, <span class="st">"smoothness_mean"</span>, <span class="st">"fractal_dimension_mean"</span>, <span class="st">"concave points_mean"</span>]]</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Variables explicatives et cible</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">'diagnosis'</span>])</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'diagnosis'</span>]</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y.<span class="bu">map</span>({<span class="st">'B'</span>: <span class="dv">0</span>, <span class="st">'M'</span>: <span class="dv">1</span>})</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Séparation train/test</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Mise à l’échelle des variables</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><strong>Validation croisée</strong></li>
</ul>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedKFold, cross_validate</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Définition du modèle logit</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>logit <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span><span class="dv">42</span>, max_iter<span class="op">=</span><span class="dv">1000</span>, class_weight<span class="op">=</span><span class="st">'balanced'</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Validation croisée stratifiée à 5 plis</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>cv <span class="op">=</span> StratifiedKFold(n_splits<span class="op">=</span><span class="dv">5</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation avec plusieurs métriques</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>scores_logit <span class="op">=</span> cross_validate(</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    logit,</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    X_train_scaled,</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    y_train,</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span>cv,</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span>[<span class="st">'accuracy'</span>, <span class="st">'precision'</span>, <span class="st">'recall'</span>, <span class="st">'f1'</span>, <span class="st">'roc_auc'</span>],</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    return_train_score<span class="op">=</span><span class="va">False</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.pipeline <span class="im">import</span> Pipeline <span class="im">as</span> ImbPipeline</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Pipeline avec SMOTE + KNN</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>knn_pipeline <span class="op">=</span> ImbPipeline(steps<span class="op">=</span>[</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'smote'</span>, SMOTE(random_state<span class="op">=</span><span class="dv">42</span>)),</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'knn'</span>, KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>))</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Validation croisée avec les mêmes métriques</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>scores_knn <span class="op">=</span> cross_validate(</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    knn_pipeline,</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    X_train_scaled,</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    y_train,</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span>cv,</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span>[<span class="st">'accuracy'</span>, <span class="st">'precision'</span>, <span class="st">'recall'</span>, <span class="st">'f1'</span>, <span class="st">'roc_auc'</span>],</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    return_train_score<span class="op">=</span><span class="va">False</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><strong>Ajustement du modèle sur l’ensemble d’entrainement</strong></li>
</ul>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Modèle 1 : Régression Logistique ---</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>logit <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span><span class="dv">42</span>, max_iter<span class="op">=</span><span class="dv">1000</span>, class_weight<span class="op">=</span><span class="st">'balanced'</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>logit.fit(X_train_scaled, y_train)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>y_pred_logit <span class="op">=</span> logit.predict(X_test_scaled)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>y_proba_logit <span class="op">=</span> logit.predict_proba(X_test_scaled)[:,<span class="dv">1</span>]</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Modèle 2 : KNN ---</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>smote <span class="op">=</span> SMOTE(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>X_train_res, y_train_res <span class="op">=</span> smote.fit_resample(X_train_scaled, y_train)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train_res, y_train_res)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>y_pred_knn <span class="op">=</span> knn.predict(X_test_scaled)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>y_proba_knn <span class="op">=</span> knn.predict_proba(X_test_scaled)[:,<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><strong>Evaluation du modèle (métriques : train - test)</strong></li>
</ul>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>y_train_pred_logit <span class="op">=</span> logit.predict(X_train_scaled)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>train_accuracy_logit <span class="op">=</span> accuracy_score(y_train_pred_logit, y_train)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>y_train_pred_knn <span class="op">=</span> knn.predict(X_train_scaled)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>train_accuracy_knn <span class="op">=</span> accuracy_score(y_train_pred_knn, y_train)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train Accuracy Logit: </span><span class="sc">{</span>train_accuracy_logit<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train Accuracy KNN: </span><span class="sc">{</span>train_accuracy_knn<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>y_train_pred_logit <span class="op">=</span> logit.predict(X_train_scaled)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>train_accuracy_logit <span class="op">=</span> accuracy_score(y_train_pred_logit, y_train)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>y_train_pred_knn <span class="op">=</span> knn.predict(X_train_scaled)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>train_accuracy_knn <span class="op">=</span> accuracy_score(y_train_pred_knn, y_train)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train Accuracy Logit: </span><span class="sc">{</span>train_accuracy_logit<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train Accuracy KNN: </span><span class="sc">{</span>train_accuracy_knn<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><strong>Exactitude du test des modèles</strong></li>
</ul>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>acc_logit <span class="op">=</span> accuracy_score(y_test, y_pred_logit)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>acc_knn <span class="op">=</span> accuracy_score(y_test, y_pred_knn)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy Régression Logistique : </span><span class="sc">{</span>acc_logit<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy KNN : </span><span class="sc">{</span>acc_knn<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><strong>Fonction de perte</strong></li>
</ul>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> log_loss</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>train_loss_logit <span class="op">=</span> log_loss(y_train, logit.predict_proba(X_train_scaled))</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>test_loss_logit <span class="op">=</span> log_loss(y_test, logit.predict_proba(X_test_scaled))</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss train (logit): </span><span class="sc">{</span>train_loss_logit<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss test (logit): </span><span class="sc">{</span>test_loss_logit<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><strong><code>Précision</code>, <code>recall</code>, <code>score F1</code>, <code>AUC</code></strong></li>
</ul>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> eval_classif(y_true, y_pred, y_proba, model_name<span class="op">=</span><span class="st">"Modèle"</span>):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"== Results for </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> =="</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification report : :"</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(classification_report(y_true, y_pred, digits<span class="op">=</span><span class="dv">4</span>))</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    auc <span class="op">=</span> roc_auc_score(y_true, y_proba)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"AUC ROC : </span><span class="sc">{</span>auc<span class="sc">:.4f}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>eval_classif(y_test, y_pred_logit, y_proba_logit, <span class="st">"Régression Logistique"</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>eval_classif(y_test, y_pred_knn, y_proba_knn, <span class="st">"KNN"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-abdi2010principal" class="csl-entry" role="listitem">
Abdi, Hervé, and Lynne J Williams. 2010. <span>“Principal Component Analysis.”</span> <em>Wiley Interdisciplinary Reviews: Computational Statistics</em> 2 (4): 433–59. <a href="https://doi.org/10.1002/wics.101">https://doi.org/10.1002/wics.101</a>.
</div>
<div id="ref-cover1967nearest" class="csl-entry" role="listitem">
Cover, T., and P. Hart. 1967. <span>“Nearest Neighbor Pattern Classification.”</span> <em>IEEE Transactions on Information Theory</em> 13 (1): 21–27. <a href="https://doi.org/10.1109/TIT.1967.1053964">https://doi.org/10.1109/TIT.1967.1053964</a>.
</div>
<div id="ref-hosmer2013applied" class="csl-entry" role="listitem">
Hosmer, David W., Stanley Lemeshow, and Rodney X. Sturdivant. 2013. <em>Applied Logistic Regression</em>. Vol. 398. John Wiley &amp; Sons.
</div>
<div id="ref-jolliffe2016pca" class="csl-entry" role="listitem">
Jolliffe, Ian T., and Jorge Cadima. 2016. <span>“Principal Component Analysis: A Review and Recent Developments.”</span> <em>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</em> 374 (2065): 20150202. <a href="https://doi.org/10.1098/rsta.2015.0202">https://doi.org/10.1098/rsta.2015.0202</a>.
</div>
<div id="ref-macqueen1967some" class="csl-entry" role="listitem">
MacQueen, J. 1967. <span>“Some Methods for Classification and Analysis of Multivariate Observations.”</span> In <em>Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability</em>, 1:281–97. 14. University of California Press.
</div>
<div id="ref-who2021breast" class="csl-entry" role="listitem">
Organization, World Health. 2021. <span>“Breast Cancer.”</span> <a href="https://www.who.int/news-room/fact-sheets/detail/breast-cancer" class="uri">https://www.who.int/news-room/fact-sheets/detail/breast-cancer</a>.
</div>
<div id="ref-sung2021global" class="csl-entry" role="listitem">
Sung, Hyuna, Jacques Ferlay, Rebecca L Siegel, Mathieu Laversanne, Isabelle Soerjomataram, Ahmedin Jemal, and Freddie Bray. 2021. <span>“Global Cancer Statistics 2020: GLOBOCAN Estimates of Incidence and Mortality Worldwide for 36 Cancers in 185 Countries.”</span> <em>CA: A Cancer Journal for Clinicians</em> 71 (3): 209–49.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>