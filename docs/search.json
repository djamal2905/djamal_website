[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "",
    "text": "Bienvenue sur mon site personnel.\nJe suis Djamal Y. TOE, statisticien passionn√© par les analyses avanc√©es, la visualisation de donn√©es, et la r√©solution de probl√®mes complexes √† travers des approches quantitatives. Ce site pr√©sente mes projets, mes recherches, et mes contributions dans le domaine des statistiques et de la science des donn√©es. Je suis titulaire d‚Äôune licence professionnelle en statistiques-informatique et actuellement √©l√®ve ing√©nieur en Data Science √† l‚ÄôEcole Nationale de la statistique et de l‚ÄôAnalyse de l‚ÄôInformation √† Bruz Rennes, France."
  },
  {
    "objectID": "about.html#√†-propos-de-moi",
    "href": "about.html#√†-propos-de-moi",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "√Ä propos de moi",
    "text": "√Ä propos de moi\nJe combine mes comp√©tences en statistiques, programmation et analyse de donn√©es pour transformer des ensembles de donn√©es en informations exploitables. Mon objectif est d‚Äôam√©liorer la prise de d√©cision gr√¢ce √† des mod√®les et des m√©thodes robustes. Ayant effectuer des stages en entreprises, j‚Äôai appris beaucoup de choses notamment en bio-statistiques et sur les mod√©lisations qui y sont utilis√©es. J‚Äôai √©galement des connaissance en cartographie (avec R)."
  },
  {
    "objectID": "about.html#exp√©rience",
    "href": "about.html#exp√©rience",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Exp√©rience",
    "text": "Exp√©rience\n\n\nStagiaire au Centre de M√©thodologie et de Gestion de donn√©es au Centre MURAZ sis Bobo-Dioulasso, Burkina Faso & l‚ÄôInstitut National de recherche en Science de la Sant√© sis Bobo-Dioulasso, Burkina Faso\n\ndur√©e : 10 mois Fin Juillet 2023 - Fin Avril 2024\nTravail effectu√© :\n\nAnalyse exploratoire de donn√©es\nTests statistiques et Mod√©lisations\nSyst√®me d‚Äôinformation g√©ographique\nRedaction automatique de rapports\nTravail en equipe (d√©coupage de la ville de Bobo-Dioulasso en plusieurs sites pour le deploiement des agents de collecte de donn√©es) sur le projet d‚Äôaide des personnes ag√©es (MAAKOROBA)\nGestion des analyses de routines du service (ACP, AFC, ACM, Regressions)\nM√©thode d‚Äôanalyse factorielles pour la reduction de dimensionnalit√©s, calcul des taux d‚Äôinerties modifi√©s de Jean-Paul BENZECRI\nApplication de l‚Äôalgorithme du K-Nearest Neighbour pour la classification\n\n\nJourn√©es Internationales de la S√©curit√© Sanitaire des Aliments 2024\n\ndur√©e : 1 mois Mars 2024 - Avril 2024\nTravail effectu√© :\n\nConception d‚Äôun formulaire interactif pour la collecte des drafts.\nD√©veloppement d‚Äôune application d√©di√©e au traitement et √† l‚Äôexport des donn√©es au format appropri√©.\nAutomatisation du processus pour optimiser l‚Äôanalyse et la gestion des drafts.\nPython, KoboCollect, Microsoft Word et Microsoft Excel\n\n\nProjet Statistique | Ecole Nationale de la Statistique et de l‚ÄôAnalyse de l‚ÄôInformation, Rennes Frances\ndur√©e : 5 mois D√©cembre 2024 ‚Äì √† pr√©sent\nTravail effectu√© :\n\nR√©daction de rapports d‚Äôanalyse statistique, incluant la m√©thodologie et l‚Äôinterpr√©tation des r√©sultats.\nAnalyse exploratoire des donn√©es pour identifier les tendances et structures sous-jacentes.\nR√©alisation de tests statistiques afin de valider les hypoth√®ses et √©valuer la significativit√© des r√©sultats.\nAnalyse des correspondances multiples (ACM) pour explorer les relations entre variables cat√©gorielles.\nGithub pour le travail en √©quipe\n\nProjet Traitement de donn√©es | Ecole Nationale de la Statistique et de l‚ÄôAnalyse de l‚ÄôInformation, Rennes Frances\ndur√©e : 2 mois F√©vrier 2022 ‚Äì √† pr√©sent\nTravail effectu√© :\n\nPython\nVisualisation des donn√©es seaborn\nD√©v√©loppement d‚Äôune application pour les utilisateurs avec pyhton shiny\nGithub pour le travail en √©quipe\nR√©daction de rapports des traitements effectu√©s sur les donn√©es (Rmarkdown)\n\nProjet d‚Äô√©conomie | Ecole Nationale de la Statistique et de l‚ÄôAnalyse de l‚ÄôInformation, Rennes Frances\ndur√©e : 4 mois Fin Novembre 2024 ‚Äì √† Mars 2025\nTravail effectu√© :\n\nR√©vue de litt√©rature\nSynth√®se et r√©sum√© des √©tudes\nRedaction du rapport\nDiscussion des m√©thodes √©conom√©triques utiilis√©es\nTravail en √©quipe"
  },
  {
    "objectID": "about.html#projets-personnels",
    "href": "about.html#projets-personnels",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Projets personnels",
    "text": "Projets personnels\n\n\n1. Analyses Factorielles et Visualisations\n\nAnalyses factorielles (ACP, AFC, ACM, AFM, AFD) pour comprendre les structures complexes des donn√©es.\nVisualisation interactive des r√©sultats pour une meilleure interpr√©tation.\n\n\n\n\n2. Mod√®les de R√©gression et Pr√©vision\n\n\nR√©gression lin√©aire, logistique, et mixte\nPr√©visions √† l‚Äôaide de mod√®les de s√©ries temporelles (pas trop avanc√©)\n\n\n\n\n3. Applications Statistiques\n\n\nD√©veloppement d‚Äôoutils interactifs pour l‚Äôanalyse de donn√©es (Shiny, Quarto)\nRapports automatis√©s (Rmarkdown, Bookdown)\n\n\n\n\n4. Applications Bureau et Web\n\n\nD√©v√©loppement de logiciel bureau pour la gestion des caisses\nD√©v√©loppement de sites web avec python&Django (pas trop avanc√©)\n\n\n\n\n5. Computer vision\n\nJe d√©bute dans la vision par ordinateur avec :\n\nLa SVM (Support Vector Machine)\nLe KNN (K- Nearest Neighbour)\nL‚ÄôACP (L‚ÄôAnalyse en Composante Principale)\nLes reseaux de neurones convolutionnels (en cours d‚Äôapprentissage)\n\n\n\n\n6. Langages de programmtion et outils statistiques\n\n\nPython, Java, C++ & C\nR, Stata, SPSS (Moyen)\nHtml, Css\nPower Bi\nOffice et Suites\nSyst√®me de Gestion de donn√©es :\n\nMySql\nOracle SQL"
  },
  {
    "objectID": "about.html#derni√®res-publications",
    "href": "about.html#derni√®res-publications",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Derni√®res publications üìö",
    "text": "Derni√®res publications üìö\n\nüìà Mod√©lisation statistique\n\n√âvaluation de l‚Äôimpact d‚Äôune intervention sur les cas de paludisme\n\nMod√©lisation des donn√©es de comptage par r√©gression de Poisson\n\nPr√©dire le diab√®te chez les femmes √† l‚Äôaide d‚Äôune r√©gression logistique\n\nMod√®le √† variable d√©pendante binaire appliqu√© √† un jeu de donn√©es m√©dical et machine learning\n\nPr√©dire la dur√©e de carri√®re des joueurs NBA\n\nUne approche par r√©gression lin√©aire supervis√©e\n\nClasser les gestes de la main (pierre, feuille, ciseau)\n\nUtilisation du reseau de neurones convolutionnel et de yolov8\n\n\n\n\n\nü§ñ Programmation et projets interactifs\n\nCr√©er un assistant virtuel avec commandes vocales en Python\n\nMini-projet m√™lant reconnaissance vocale, traduction et intelligence artificielle\n\n\n\n\n\nüîç Analyse exploratoire et visualisation\n\nExploration des techniques d‚Äôanalyse factorielle\n\nPCA, AFC, ACM sur des jeux de donn√©es\n\nCr√©ation de cartes th√©matiques avec R (choropl√®thes, proportions)\n\nUtilisation des packages sf, tmap, leaflet\n\n\n\n\n\nüßë‚Äçüè´ Formations et bonnes pratiques\n\nR√©aliser des pr√©sentations dynamiques avec R et RStudio Utilisation de Quarto, Reveal.js et astuces pour pr√©senter efficacement"
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html",
    "href": "ANALYSES_FACTORIELLES/TP03.html",
    "title": "Djamaldbz - M√©thodes d‚ÄôAnalyse factorielle TP02",
    "section": "",
    "text": "packages_ &lt;- c(\"ggplot2\", \"dplyr\",\"readxl\",\"cowplot\")\n\nfor (pkg in packages_) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}"
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#quelques-d√©finitions",
    "href": "ANALYSES_FACTORIELLES/TP03.html#quelques-d√©finitions",
    "title": "Djamaldbz - M√©thodes d‚ÄôAnalyse factorielle TP02",
    "section": "Quelques d√©finitions",
    "text": "Quelques d√©finitions\n¬†¬†¬†¬†¬†¬†Le calcul de l‚Äôempreinte √©cologique et de la biocapacit√© nous aide √† r√©pondre √† la question de recherche fondamentale : Quelle est la demande des √™tres humains envers les surfaces biologiquement productives (empreinte √©cologique) par rapport √† la quantit√© que la plan√®te (ou la surface productive d‚Äôune r√©gion) peut r√©g√©n√©rer sur ces surfaces (biocapacit√©) ?\n\nHectare global (gha) : C‚Äôest l‚Äôunit√© choisie pour exprimer toutes les quantit√©s d‚Äôint√©r√™t concernant la consommation/√©mission de carbone. Une unit√© de surface correspondant √† la productivit√© moyenne d‚Äôun hectare de terres mondiales. Un hectare de terres agricoles vaudra plus d‚Äôhectares globaux qu‚Äôun hectare de d√©sert.\nEmpreinte √©cologique (en gha par personne) : Le nombre de gha requis pour produire les besoins et absorber les d√©chets d‚Äôun pays.\nBiocapacit√© (en gha) : La capacit√© d‚Äôun pays √† produire ce dont il a besoin et √† absorber ses d√©chets (r√©serve √©cologique).\nJour de d√©passement : Jour de l‚Äôann√©e o√π la demande d‚Äôun pays d√©passe sa biocapacit√© annuelle."
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#chargement-des-donn√©es",
    "href": "ANALYSES_FACTORIELLES/TP03.html#chargement-des-donn√©es",
    "title": "Djamaldbz - M√©thodes d‚ÄôAnalyse factorielle TP02",
    "section": "Chargement des donn√©es",
    "text": "Chargement des donn√©es\n\n##-- Installer et Charger les packages requis\n###--- vecteurs des packages\npackages &lt;- c(\"factoextra\", \"corrr\", \"FactoMineR\", \"dplyr\",\"kableExtra\",\"corrplot\",\n              \"explor\")\n\n###--- Boucle pour installer et charger les packages\nfor (pkg in packages) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}\n\n##-- charger la base de donn√©es via le lien web\nlink.to.data &lt;- \"https://marieetienne.github.io/datasets/overshootday_overview.csv\"\ndf &lt;- read.csv(link.to.data)"
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#analyse-exploratoire-des-donn√©es",
    "href": "ANALYSES_FACTORIELLES/TP03.html#analyse-exploratoire-des-donn√©es",
    "title": "Djamaldbz - M√©thodes d‚ÄôAnalyse factorielle TP02",
    "section": "Analyse exploratoire des donn√©es",
    "text": "Analyse exploratoire des donn√©es\n\nnrow(df); ncol(df) ;dim(df)\n\n[1] 182\n\n\n[1] 13\n\n\n[1] 182  13\n\n\nLes donn√©es sont compos√©es de 182 lignes et de 13 colonnes."
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#r√©sum√©-statitique-des-variables",
    "href": "ANALYSES_FACTORIELLES/TP03.html#r√©sum√©-statitique-des-variables",
    "title": "Djamaldbz - M√©thodes d‚ÄôAnalyse factorielle TP02",
    "section": "R√©sum√© statitique des variables",
    "text": "R√©sum√© statitique des variables\nOn utilise la commande summary(df) tout simplement, mais pour une question d‚Äôexth√©tique on utilise ce code.\n\n##-- summary pour les variable num√©riques\nsummary.df.num &lt;- sapply(df[sapply(df, is.numeric)], function(x) {\n  c(\n    min = min(x, na.rm = TRUE),\n    Q1 = quantile(x, 0.25, na.rm = TRUE),\n    Q3 = quantile(x, 0.75, na.rm = TRUE),\n    med = quantile(x, 0.5, na.rm = TRUE),\n    mean = mean(x, na.rm = TRUE),\n    max = max(x, na.rm = TRUE),\n    count = sum(!is.na(x)),\n    sd = sd(x, na.rm = TRUE),\n    `NA's` = round(sum(is.na(x)),0)\n  )\n})\nsummary.df.num &lt;- as.data.frame(summary.df.num)\n\nEnsuite nous affichons ce resum√© dans un tableau :\n\n\n\nTableau 1 : R√©sum√© statistique des variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlife_expectancy\nhdi\nper_capita_gdp\npop\ntotal_prod\ntotal_cons\nbiocapacity\nnumber_of_countries_required\nnumber_of_earths_required\novershoot_day\n\n\n\n\nmin\n52,525000\n0,3850000\n732,836\n0,06200\n0,371747\n0,5540298\n0,1041268\n0,0180633\n0,3668548\n41,0000\n\n\nQ1.25%\n65,747000\n0,5945000\n4888,255\n2,64100\n1,156834\n1,2195240\n0,6633750\n0,8273357\n0,8075166\n143,0000\n\n\nQ3.75%\n76,400695\n0,8350000\n31670,000\n32,91550\n3,828778\n3,8418335\n2,6656718\n2,7330613\n2,5438978\n365,0000\n\n\nmed.50%\n71,900000\n0,7310000\n13548,200\n10,01950\n1,924223\n2,3197815\n1,3622344\n1,7280656\n1,5360601\n239,0000\n\n\nmean\n71,180320\n0,7177193\n21139,464\n43,47636\n2,879469\n2,9624675\n3,5569055\n2,9127705\n1,9616192\n239,7802\n\n\nmax\n84,445610\n0,9620000\n120505,000\n1480,63200\n13,394536\n13,1263342\n85,6461100\n55,1061868\n8,6916969\n365,0000\n\n\ncount\n175,000000\n171,0000000\n163,000\n182,00000\n182,000000\n181,0000000\n181,0000000\n181,0000000\n181,0000000\n182,0000\n\n\nsd\n7,615465\n0,1533110\n22330,819\n156,03751\n2,515235\n2,1957327\n10,0256869\n5,1916277\n1,4539202\n109,5507\n\n\nNA‚Äôs\n7,000000\n11,0000000\n19,000\n0,00000\n0,000000\n1,0000000\n1,0000000\n1,0000000\n1,0000000\n0,0000\n\n\n\nNote: aby Djamal Y. TOE\n\n\n¬†¬†Nous constatons que ceraines variables ont des donn√©es manquantes, nous pouvons d√©cider de soit les supprimer, soit les pr√©dire avec des m√©thodes d‚Äôimputation en fonction de leurs importances. Mais pour le moment nous allons juste les supprimer.\n\ndf &lt;- na.omit(df)\nnrow(df)\n\n[1] 162\n\n\nAinsi nous passons de 182 √† 162 lignes."
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#contruction-de-lanalyse-en-composante-principale",
    "href": "ANALYSES_FACTORIELLES/TP03.html#contruction-de-lanalyse-en-composante-principale",
    "title": "Djamaldbz - M√©thodes d‚ÄôAnalyse factorielle TP02",
    "section": "Contruction de l‚ÄôAnalyse en composante principale",
    "text": "Contruction de l‚ÄôAnalyse en composante principale\n\nLe poids pour les pays : Les tailles respectives des populations de chaques pays car cela garantit que l‚Äôanalyse est repr√©sentative des diff√©rences globales, en tenant compte de l‚Äôimpact d√©mographique des pays.\nM√©trique : Normalisation des donn√©es car les variables ne sont pas toutes sur la m√™me √©chelle. Cela permet d‚Äô√©viter que les variables avec de grosses valeurs (grandes √©chelles) dominent l‚Äôanalyse.\nvariables sup :\n\nQuali sup : region, income_group\nQuanti sup : pop\n\n\n\nR√©alisation de l‚ÄôACP\n\nV√©rifions la corr√©lations entre les variables quantitatives\n\n\nnumeric.vars &lt;- as.data.frame(df[sapply(df, is.numeric)])\nM &lt;- round(cor(numeric.vars),2) #- Calculer la matrice de corr√©lation\n\n##-- cr√©er un objet qui contient une palette de couleur pour le gradiant dans le plot\ncol &lt;- colorRampPalette(c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\"))\n\n##-- dessiner le graphique\ncorrplot(M, method=\"color\", col=col(200),  \n         type=\"upper\", order=\"hclust\", \n         addCoef.col = \"black\", #- ajout des coefficients correlation\n         tl.col=\"black\", tl.srt=45, tl.cex = 1\n         , #- couleur, rotation et police de texte des libell√©s \n         ##-- ne pas afficher les coefficients de corr√©lations sur la diagonale (ils valent tous 1)\n         diag=FALSE \n         ) \n\n\n\n\nFigure 1 : Matrice de corr√©lations\n\n\n\n\n¬†¬†¬†¬†On voit qu‚Äôil y‚Äô a quand m√™me des variables qui sont &lt;&gt; (pour l‚Äôaffirmer avec plus d‚Äôassurance il serait judicieux de faire un test billat√©ral de corr√©lation de Pearson avec la commande cor.test(method = ‚Äúpearson‚Äù, alternative = ‚Äútwo.sided‚Äù)).\n\nCr√©ation du mod√®le de l‚ÄôACP\n\n\ndata.pca &lt;- df[,-1] #- s√©lectionner toute les variables sauf la variable pays\nrownames(data.pca) &lt;- df[,1] #- renommer les lignes avec les noms des pays (individus)\npoids &lt;- df$pop\npca.model &lt;- PCA(data.pca, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca$pop,\n                 quanti.sup = 6)\n\n##- explor(pca.model) pour une interface interactive\n\n\n\nRecup√©ration des valeurs propres et des variances\n\neigen.values &lt;- pca.model$eig\nknitr::kable(eigen.values[1:3,2:3], caption = capTab(\"Inerties expliqu√©es par les 3 premiers axes\"))\n\n\nTableau 2 : Inerties expliqu√©es par les 3 premiers axes\n\n\n\npercentage of variance\ncumulative percentage of variance\n\n\n\n\ncomp 1\n69,758338\n69,75834\n\n\ncomp 2\n16,485374\n86,24371\n\n\ncomp 3\n4,865912\n91,10962\n\n\n\n\n\nOn remarque que les axes 1,2 et 3 repr√©sentent respectivement 69,76, 16,49 et 4,09, donc au total 91,11\nOn pourrait aussi visualiser le graphique des valeurs propres :\n\nplt.eig &lt;- fviz_eig(pca.model, title = \"Valeurs propres avec Singapore\")\n\n\n\nQualit√© de representation des plans / sur les plans\n\nQualit√© de representation des plans\n\n¬†¬†Le premier plan a un taux d‚Äôinertie sup√©rieur √† 86 %, il capte une grande partie de l‚Äôinformation pr√©sente dans les donn√©es ce qui signifie qu‚Äôil √† une bonne qualit√© de representation alors que le second (1-3) en capte environ 74,63 % donc a une faible qualit√© de repr√©senatation compar√© au premier. En depit de ce fait, les deux plans ont quand m√™me qualit√© de repr√©sentation si mous fions au crit√®re du taux d‚Äôinertie.\n\nQualit√© de representation sur les plans\n\n(1-2)\n\n\nLES VARIABLES\n\ngraph.cos2.var &lt;- fviz_pca_var(pca.model,col.var=\"cos2\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel=TRUE, ggtheme = theme_light())\n\ngraph.cos2.var\n\n\n\n\nFigure 3 : Qualit√©s de representation des variables\n\n\n\n\nConcernant les variables, on constate qu‚Äôelles toutes sont bien represent√©es avec des cosinus carr√©s qui ont une valeur minimale environ 0,8 √† part les variables biocapacity, life_expectancy, number_of_countries_required qui ont un cosinus carr√©s qui vaut environ 0,7.\nLES INDIVIDUS\n\nthreshold &lt;- 0.85\ndata.ind.cos2 &lt;- pca.model$ind$cos2\n\ndim1 &lt;- data.ind.cos2[,\"Dim.1\"]\ndim1 &lt;- dim1[dim1 &gt;= threshold]\ncountries.dim1 &lt;- names(dim1)\nnames(dim1) &lt;-  NULL\n\ndim2 &lt;- data.ind.cos2[,\"Dim.2\"]\ndim2 &lt;- dim2[dim2 &gt;= 0.6]\ncountries.dim2 &lt;- names(dim2)\nnames(dim2) &lt;-  NULL\n\n##-- cr√©tion des dataframes \ndim1.df &lt;- data.frame(\n  Country = countries.dim1,\n  `Cos carr√©` = dim1\n) %&gt;% arrange(desc(dim1))\n\n\ndim2.df &lt;- data.frame(\n  Country = countries.dim2,\n  `Cos carr√©` = dim2\n) %&gt;% arrange(desc(dim2))\n\n\n##-- cr√©ation des tableaux kableExtra\ndim1.tbl &lt;- kableExtra::kbl(dim1.df, caption = capTab(\"Individus ayant un cosinus carr√© sup√©rieur ou √©gal √† 0,85 sur l'axe 1\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des donn√©es :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\ndim2.tbl &lt;- kableExtra::kbl(dim2.df, caption = capTab(\"Individus ayant un cosinus carr√© sup√©rieur ou √©gal √† 0,6 sur l'axe 2\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))  %&gt;% add_footnote(label = \"Source des donn√©es :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\n\ndim1.tbl\n\n\n\nTableau 3 : Individus ayant un cosinus carr√© sup√©rieur ou √©gal √† 0,85 sur l'axe 1\n\n\nCountry\nCos.carr√©\n\n\n\n\nRwanda\n0,9810454\n\n\nNepal\n0,9772128\n\n\nHaiti\n0,9763067\n\n\nPakistan\n0,9745537\n\n\nSao Tome and Principe\n0,9617076\n\n\nIndia\n0,9558559\n\n\nKenya\n0,9448689\n\n\nTogo\n0,9425662\n\n\nMalawi\n0,9425394\n\n\nTanzania, United Republic of\n0,9419010\n\n\nEthiopia\n0,9390190\n\n\nGambia\n0,9377395\n\n\nPoland\n0,9272053\n\n\nYemen\n0,9228666\n\n\nCzech Republic\n0,9218239\n\n\nAustria\n0,9047663\n\n\nGuatemala\n0,9044971\n\n\nMyanmar\n0,8964483\n\n\nBurundi\n0,8916493\n\n\nCambodia\n0,8911437\n\n\nDenmark\n0,8896874\n\n\nUnited States of America\n0,8875048\n\n\nSlovenia\n0,8840522\n\n\nMalaysia\n0,8840507\n\n\nBenin\n0,8831711\n\n\nSudan\n0,8713134\n\n\nSenegal\n0,8705626\n\n\nTimor-Leste\n0,8640862\n\n\nBelgium\n0,8604596\n\n\nAngola\n0,8591836\n\n\nGhana\n0,8579621\n\n\nSierra Leone\n0,8542504\n\n\nSlovakia\n0,8524619\n\n\n\na Source des donn√©es : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\n\ndim2.tbl \n\n\n\nTableau 4 : Individus ayant un cosinus carr√© sup√©rieur ou √©gal √† 0,6 sur l'axe 2\n\n\nCountry\nCos.carr√©\n\n\n\n\nNamibia\n0,7502317\n\n\nParaguay\n0,6807204\n\n\nBrazil\n0,6672407\n\n\nBolivia\n0,6609662\n\n\nBarbados\n0,6458843\n\n\n\na Source des donn√©es : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\n\n\nAXE 1 : On voit que les pays (individus) comme le Togo, le Yemen, les USA, le Rwanda sont tres bien represent√©s. RMRQ : Il y en a d‚Äôautres\nAXE 2 : Il n‚Äôy a que 6 pays qui sont bien repr√©sent√©s sur cet axe. Il s‚Äôagit de la Namibie, le Paraguay, le Br√©sil, la Bolivie et Barbados.\n\nREMARQUE :  Pour le plan form√© des axes 1 et 3, on peut proc√©der la m√™me que celle en amont\n\n\nCaract√©risation des axes\n\ngraph.contrib.var &lt;- fviz_pca_var(pca.model,col.var=\"contrib\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel=TRUE, ggtheme = theme_light())\n\ngraph.contrib.var\n\n\n\n\nFigure 4 : Cercle de corr√©lation des variables et leur contribution √† la formation des axes\n\n\n\n\n\n\nComment l‚ÄôACP est-elle modifi√©e si on retire Singapour de l‚Äôanalyse ?\n\ndata.pca.sans.singapore &lt;- data.pca %&gt;% filter(rownames(data.pca) != \"Singapore\")\npoids &lt;- df$pop\npca.model.sans.singapore &lt;- PCA(data.pca.sans.singapore, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca.sans.singapore$pop,\n                 quanti.sup = 6)\n\n##-- explor(pca.model)\n\n\nplt.eig.sans.sing &lt;- fviz_eig(pca.model.sans.singapore, title = \"Valeurs propres sans Singapore\") \ncomp.eig &lt;-  cowplot::plot_grid(\n  plt.eig,\n  plt.eig.sans.sing,\n  ncol = 2\n)+ theme_light()\ncomp.eig\n\n\n\n\nFigure 5 : Comparaison des valeurs propres issues de l‚ÄôACP aevc et sans Singapore\n\n\n\n\n¬†¬†On voit que rien ne se passe (pas de changement brusque) au niveau de la qualit√© des axes. Voyons de plus pr√™t ce qui se passe :\n\nplot.indiv.avec.sing &lt;- fviz_pca_ind(pca.model) + \n                        theme_light()\nplot.indiv.avec.sing\n\n\n\n\nFigure 6 : Comparaison des valeurs propres issues de l‚ÄôACP aevc et sans Singapore\n\n\n\n\n¬†¬†On voit que Singapore est atypique. Cela pourrait signifier que Singapore participe fortement √† la formation de l‚Äôaxe 2 (point plus proche de l‚Äôaxe 1).\n\ndata &lt;- as.data.frame(pca.model$ind$contrib)\ndata &lt;-  data %&gt;% arrange(desc(Dim.2)) %&gt;% head(10)\nkableExtra::kbl(data, caption = capTab(\"Contribution des individus √† la formation des axes par contribution d√©croissante suivant l'axe 2\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))  %&gt;% add_footnote(label = \"Source des donn√©es :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\nTableau 5 : Contribution des individus √† la formation des axes par contribution d√©croissante suivant l'axe 2\n\n\n\nDim.1\nDim.2\nDim.3\nDim.4\nDim.5\n\n\n\n\nSingapore\n0,7259355\n15,139608\n28,5623680\n9,9266768\n5,6933884\n\n\nBrazil\n0,2363938\n11,748028\n0,2780798\n16,7474472\n0,1489935\n\n\nChina\n6,3338962\n10,346574\n0,9583694\n1,3599693\n36,9834265\n\n\nRussian Federation\n3,7284884\n10,223438\n4,1131775\n0,1010599\n3,8319553\n\n\nCanada\n3,7127169\n6,392768\n0,8335954\n3,8719645\n0,0267550\n\n\nJapan\n2,3347045\n4,109062\n0,8491595\n0,6848764\n2,2016647\n\n\nUnited States of America\n21,6581050\n3,434086\n3,0985377\n22,3391460\n5,4054986\n\n\nKorea, Republic of\n1,9711036\n2,758601\n0,8457859\n0,0962515\n0,0745840\n\n\nAustralia\n1,8672806\n2,568678\n0,0085414\n1,3778438\n0,3505079\n\n\nGuyana\n0,0605633\n2,548944\n1,0759061\n8,5175485\n0,9606747\n\n\n\na Source des donn√©es : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEt pourtant il contribue fortement √† la formation de l‚Äôaxe 2, il est m√™me celui qui contribue les plus √† la formation des axes. Le fait que Singapore contribue le plus √† la formation des axes et que rien ne change lorsqu‚Äôil est retir√© de l‚Äôanalyse s‚Äôexplique tout simplement par sa taille de population. En effet la taille de la population a √©t√© utilis√©e comme poids des individus qui sont ici les pays."
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#identifications-des-pays-en-fonction-de-leur-groupe-de-revenu",
    "href": "ANALYSES_FACTORIELLES/TP03.html#identifications-des-pays-en-fonction-de-leur-groupe-de-revenu",
    "title": "Djamaldbz - M√©thodes d‚ÄôAnalyse factorielle TP02",
    "section": "Identifications des pays en fonction de leur groupe de revenu",
    "text": "Identifications des pays en fonction de leur groupe de revenu\n\nIl s‚Äôagit juste d‚Äôune parenth√®se qui n‚Äôa rien avoir avec l‚Äôobjectif de l‚Äô√©tude\n\n\n##-- D√©finitions des groupes de revenus\nincome_groups_definitions &lt;- c(\n  \"UM\" = \"Upper-Middle\",\n  \"LM\" = \"Lower-Middle\",\n  \"HI\" = \"High Income\",\n  \"LI\" = \"Low Income\"\n)\n\n\n##-- Ajouter une colonne avec les d√©finitions correspondantes\ndata.pca$income_group_def &lt;- as.factor(income_groups_definitions[data.pca$income_group])\n\n\ngraph_indiv &lt;- fviz_pca_ind(\n  pca.model,\n  select.ind = list(\n    contrib = 50\n  ),\n  invisible = c(\"quanti.sup\",\"ind.sup\"),\n  habillage = data.pca$income_group_def,\n  addEllipses = TRUE,\n  repel = TRUE,\n) + theme_light() \n\n\ngraph_indiv\n\n\n\n\nFigure 7 : Affichage des 40 individus qui contribuent le plus √† la formation des axes en fonction de leur groupe de revenu\n\n\n\n#hc.pca &lt;- HCPC(pca.model, nb.clust=3)\n\n¬†¬†¬†¬†¬†¬†On voit que les groupes ne sont pas bien s√©par√©s, raison pour laquelle les ellipses ont des partie qui co√Øncident. Cela pourrait signifier que les les groupes de revenus sont trop similaires pour etre clairement s√©par√©s sur les axes s√©lectionn√©s (dans le plan des composantes principales). Cela pourrait aussi fait cas d‚Äôh√©t√©rog√©n√©it√©, c‚Äôest-√†-dire que les groupes ne sont pas homog√®nes (grande variabilit√© intra-groupe).\n¬†¬†¬†¬†¬†¬†A bien regarder, nous aurions pu les regrouper en trois groupes de revenu, en combinant les Low income et les Low middle income, les Upper middle income (avec certains pays du High income) et enfin le dernier groupe les high income. Il faut noter que tout √ßa n‚Äôest que purement visuel m√™me si on a quand m√™me une grande partie de l‚Äôinformation contenue dans les donn√©es rien qu‚Äôavec ces deux plans (plus de 80%).\n\nDeux ACP diff√©rentes\n\nPourquoi r√©aliser deux ACP diff√©rentes ?\n\n¬†¬†Pour simplement calculer la 1-√®re valeur propre de chaque groupe de variables (empreinte √©cologique et de developpement) afin de les utiliser ponderer les variables afin qu‚Äôelles contribuent de mani√®re √©quitable √† la formation des axes. Pour plus de d√©tails aller √† la sous-section et sur le site de mon professeur de M√©thodes d‚ÄôAnalyses Factorielles en cliquanr sur ce lien https://marieetienne.github.io/MAF/01_afm.html#/title-slide.\nOn pr√©f√®re utiliser la premi√®re valeur propre (\\(\\lambda_{k1}\\)) car elle capturerait l‚Äôessentiel de l‚Äôinertie d‚Äôun groupe et permet une pond√©ration coh√©rente et √©quilibr√©e dans l‚ÄôAFM. La seconde valeur propre refl√®te des structures secondaires ou r√©siduelles qui ne sont pas pertinentes pour normaliser les contributions des groupes dans l‚Äôanalyse globale.\n\nvariables.empreinte &lt;- df[, c(\"total_prod\", \"total_cons\", \"biocapacity\", \"number_of_earths_required\", \"overshoot_day\", \"pop\")]\nrownames(variables.empreinte) &lt;- df$country\nvariables.developpement &lt;- df[, c(\"life_expectancy\", \"hdi\", \"per_capita_gdp\",\"pop\")]\nrownames(variables.developpement) &lt;- df$country\n\n\nACP sur les variables d‚Äôempruntes √©cologiques\n¬†¬†¬†¬†¬†¬†Il s‚Äôagit ici de faire l‚ÄôACP que sur les variables d‚Äôempruntes √©cologiques et de mettre les autres variables (de developpement) en quantitatives suppl√©mentaires.\n\ndata.pca &lt;- df[,-1] ## s√©lectionner toute les variables sauf la variable pays\nrownames(data.pca) &lt;- df[,1] ## renommer les lignes avec les noms des pays (individus)\npoids &lt;- df$pop\nacp_empreinte &lt;- PCA(data.pca, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca$pop,\n                 quanti.sup = c(6,1,2,3))\n\n##-- 1ere valeur propre\nacp_empreinte$eig[1,1]\n\n[1] 4,115324\n\n\nLa premi√®re valeur propre est : 4,12\n\n\nACP sur les variables d‚Äôempruntes √©cologiques\n\nacp.developpement &lt;- PCA(data.pca, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca$pop,\n                 quanti.sup = 6:12)\n\n##-- 1ere valeur propre\nacp.developpement$eig[1,1]\n\n[1] 2,592046\n\n\nLa premi√®re valeur propre est : 2,59\n\n\nR√©alisons l‚ÄôAFM manuellement\n\nvariables.empreinte.pond &lt;- variables.empreinte[,-ncol(variables.empreinte)]/sqrt(acp_empreinte$eig[1,1])\n\nvariables.developpement.pond &lt;- variables.developpement[,-ncol(variables.developpement)]/sqrt(\n  acp.developpement$eig[1,1]\n)\n\nvariables.empreinte.pond$group &lt;- \"Empreinte √©cologique\"\nvariables.developpement.pond$group &lt;- \"developpement\"\n\ndf.afm &lt;- cbind(variables.empreinte.pond, \n                variables.developpement.pond,\n                pop = df$pop,\n                region = df$region,\n                income_group = df$income_group)\n\nacp.afm &lt;- PCA(df.afm, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\", \"group\"),\n                 graph = FALSE,\n                 row.w = df.afm$pop,\n                 quanti.sup = 9)\n\nvariance.cum.val.prop.2acp &lt;- acp.afm$eig[, c(1,3)]\ncolnames(variance.cum.val.prop.2acp) &lt;- c(\"Valeur propres\", \"Pourcentage de variance cumul√©e\")\n\n\nkableExtra::kbl(variance.cum.val.prop.2acp, caption = capTab(\"Valeurs propres et variances cumul√©es de chaque axes issues d'une AFM manuelle\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des donn√©es :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\nTableau 6 : Valeurs propres et variances cumul√©es de chaque axes issues d'une AFM manuelle\n\n\n\nValeur propres\nPourcentage de variance cumul√©e\n\n\n\n\ncomp 1\n5,4257689\n67,82211\n\n\ncomp 2\n1,3223267\n84,35120\n\n\ncomp 3\n0,6522681\n92,50455\n\n\ncomp 4\n0,3973880\n97,47190\n\n\ncomp 5\n0,1005256\n98,72847\n\n\ncomp 6\n0,0689548\n99,59040\n\n\ncomp 7\n0,0327679\n100,00000\n\n\ncomp 8\n0,0000000\n100,00000\n\n\n\na Source des donn√©es : https://marieetienne.github.io/datasets/overshootday_overview.csv"
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#afm",
    "href": "ANALYSES_FACTORIELLES/TP03.html#afm",
    "title": "Djamaldbz - M√©thodes d‚ÄôAnalyse factorielle TP02",
    "section": "REALISATION DE L‚ÄôAFM",
    "text": "REALISATION DE L‚ÄôAFM\n\nPourquoi r√©aliser une AFM au lieu d‚Äôune ACP tout court?\n\n¬†¬†¬†¬†¬†¬†L‚ÄôAnalyse Factorielle Multiple (AFM) permet d‚Äôaller au-del√† des limites d‚Äôune Analyse en Composantes Principales (ACP) classique, particuli√®rement lorsque les variables d‚Äôun jeu de donn√©es ne sont pas √† la m√™me √©chelle ou lorsqu‚Äôelles sont organis√©es en groupes. La normalisation dans l‚ÄôACP sert √† ramener toutes les variables √† une m√™me √©chelle, √©vitant ainsi que certaines variables dominent artificiellement l‚Äôanalyse en raison de leur variance plus √©lev√©e. Par exemple d‚Äôautres ont une contribution √©lev√©e que d‚Äôautres alors que c‚Äôest juste l‚Äôunit√© de m√©sure qui p√®se plus.\n¬†¬†Cependant, cette normalisation n‚Äôest pas suffisante lorsque les variables sont regroup√©es par th√©matique ou nature. Par exemple, supposons un jeu de donn√©es contenant \\(n\\) variables, parmi lesquelles \\(n - k\\) \\(\\text{avec k telque  } \\forall \\text{ j} \\neq \\text{k, }\\)\n\\(\\text{n - k} &gt; \\text{n - j o√π n - j est le nombre de variables dans tous les autres groupes ou dans un autre groupe j}\\) appartiennent √† un groupe \\(i\\) .Dans ce cas, le groupe \\(i\\) peut influencer de mani√®re disproportionn√©e les r√©sultats de l‚ÄôACP, simplement en raison de la taille du groupe. Cela signifie que, m√™me apr√®s normalisation, le poids collectif du groupe \\(i\\) dans la construction des composantes principales pourrait √™tre trop important par rapport aux autres groupes.\n¬†¬†L‚ÄôAFM r√©sout ce probl√®me en int√©grant un poids √©quilibr√© entre les groupes. Elle consid√®re chaque groupe comme une entit√©, ind√©pendamment du nombre de variables qu‚Äôil contient. Cela permet une contribution √©quitable des groupes aux axes factoriels. Par cons√©quent, l‚ÄôAFM est particuli√®rement adapt√©e dans des contextes o√π les variables appartiennent √† des th√©matiques distinctes (par exemple, des groupes li√©s √† des disciplines diff√©rentes : sant√©, √©conomie, environnement).\nIl est crucial de pr√©server l‚Äô√©quilibre des contributions entre ces th√©matiques pour √©viter les biais d‚Äôinterpr√©tation. Ainsi, l‚ÄôAFM fournit une perspective multidimensionnelle plus √©quilibr√©e et pertinente pour analyser des jeux de donn√©es complexes, tout en respectant la structure inh√©rente des variables\n\nR√©alisons l‚ÄôAFM √† pr√©sent\n\n\n#-- cr√©ation de la table pour l'AFM. Les vriables doivent √™tre rang√©es \n#-- suivant le groupe (variables du groupe 1 ensuite celles du groupe 2 ...)\ndata.afm &lt;- data.pca %&gt;%\n  select(\n    life_expectancy, hdi, per_capita_gdp,  ##-- Variables de developpement\n    total_prod, total_cons, biocapacity, ##------ Variables\n    number_of_earths_required, overshoot_day ##-- d'empreinte √©cologique\n)\n\nmodel.afm &lt;- MFA(\n    data.afm, \n    group = c(5, 3), ##-- Sp√©cifie le nombre de variables dans chaque groupe\n    type = rep(\"s\", 2), ##-- Indique que les variables doivent √™tre normalis√©es pour chaque groupe\n    name.group = c(\"Developpement\", \"Empreinte ecologique\"), ##-- Nommer les groupes\n    graph = F  ##-- G√©n√©rer un graphique\n)\nvariance.cum.val.prop.afm &lt;- model.afm$eig[, c(1,3)]\ncolnames(variance.cum.val.prop.afm) &lt;- c(\"Valeur propres\", \"Pourcentage de variance cumul√©e\")\n\n\nkableExtra::kbl(variance.cum.val.prop.afm, caption = capTab(\"Valeurs propres et variances cumul√©es de chaque axes issues d'une AFM avec R\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des donn√©es :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\nTableau 7 : Valeurs propres et variances cumul√©es de chaque axes issues d'une AFM avec R\n\n\n\nValeur propres\nPourcentage de variance cumul√©e\n\n\n\n\ncomp 1\n1,9203865\n67,85068\n\n\ncomp 2\n0,5123847\n85,95414\n\n\ncomp 3\n0,2050340\n93,19836\n\n\ncomp 4\n0,0790131\n95,99003\n\n\ncomp 5\n0,0659024\n98,31848\n\n\ncomp 6\n0,0327210\n99,47457\n\n\ncomp 7\n0,0148713\n100,00000\n\n\ncomp 8\n0,0000000\n100,00000\n\n\n\na Source des donn√©es : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\nOn voit qu‚Äôil n‚Äôy a pas tr√®s grande diff√©rence entre les pourcentage de variances cumul√©es des deux AFM (manuellement @variance.cum.val.prop.2acp et avec R) parcontre les valeurs propres ne sont pas les m√™mes.\n\nOn peut visualiser les variables\n\n\nfviz_mfa_var(model.afm, axes = c(1,2), choice= \"quanti.var\", repel = T) + theme_light()\n\n\n\n\nFigure 8 : Visualisation des variables dans le plan (1,2) avec les r√©sultats de l‚ÄôAFM\n\n\n\n\n\nOn peut visualiser leur qualit√© de representation\n\n\ngraph.cos.var.afm &lt;- fviz_mfa_var(model.afm, axes = c(1,2), choice= \"quanti.var\", col.var=\"cos2\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel = T, ggtheme = theme_light())\n\ngraph.cos.var.afm\n\n\n\n\nFigure 9 : Qualit√© de repr√©sentation des variables dans le plan (1,2) avec les r√©sultats de l‚ÄôAFM\n\n\n\n\n\nLeur contribution √† la formation des axes\n\n\ngraph.contrib.var.afm &lt;- fviz_mfa_var(model.afm,col.var=\"contrib\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel=TRUE, ggtheme = theme_light())\n\ngraph.contrib.var.afm\n\n\n\n\nFigure 10 : Cercle de corr√©lation des variables et leur contribution √† la formation des axes"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#contexte",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#contexte",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Contexte",
    "text": "Contexte\n\nLe jeu de donn√©es mtcars est l‚Äôun des ensembles de donn√©es les plus connus en statistiques et science des donn√©es. Il contient des informations sur les sp√©cifications techniques et les performances de 32 mod√®les de voitures des ann√©es 1970. Ce dataset offre une opportunit√© unique d‚Äôexplorer des relations entre des variables m√©caniques, comme la consommation en carburant, la puissance ou encore le poids des v√©hicules."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#probl√©matique",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#probl√©matique",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Probl√©matique",
    "text": "Probl√©matique\n\nComment exploiter les relations entre les caract√©ristiques des voitures pour identifier des groupes ou des tendances qui pourraient aider √† la prise de d√©cision dans le secteur automobile ?"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#objectif-g√©n√©ral",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#objectif-g√©n√©ral",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Objectif g√©n√©ral",
    "text": "Objectif g√©n√©ral\n\n√âtudier les relations entre les caract√©ristiques techniques des voitures afin de d√©gager des tendances et des informations utiles pour la conception ou la s√©lection des v√©hicules."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#objectifs-sp√©cifiques",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#objectifs-sp√©cifiques",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Objectifs sp√©cifiques",
    "text": "Objectifs sp√©cifiques\n\n\nExplorer les relations entre la consommation en carburant (mpg) et les caract√©ristiques m√©caniques\n\n\n\n\nIdentifier des groupes de voitures ayant des caract√©ristiques similaires √† l‚Äôaide d‚Äôanalyses descriptives et graphiques."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#mat√©riels",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#mat√©riels",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Mat√©riels",
    "text": "Mat√©riels\n\nLogiciel utilis√© : RStudio avec les packages n√©cessaires (ggplot2, dplyr, cowplot, etc.)\nSource des donn√©es : Jeu de donn√©es int√©gr√© mtcars."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "M√©thode",
    "text": "M√©thode\n\nNettoyage des donn√©es : V√©rification des valeurs manquantes ou aberrantes.\nAnalyse descriptive : Moyennes, m√©dianes, √©cart-types pour chaque variable."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode-1",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "M√©thode",
    "text": "M√©thode\nMod√©lisation multivari√©e : Variables utilis√©es\n\nmpg : Consommation de carburant en miles par gallon (variable d√©pendante).\nwt : Poids du v√©hicule (en milliers de livres).\ncyl : Nombre de cylindres du moteur.\nam: Type de transmission (0 = automatique, 1 = manuelle).\ncarb : Nombre de carburateurs.\nhp : Puissance brute du moteur (en chevaux-vapeur)."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode-2",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode-2",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "M√©thode",
    "text": "M√©thode\nMod√©lisation multivari√©e :\n\\[\n\\mathbf{Y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\no√π :\n\n\\(Y\\): Vecteur des valeurs observ√©es (d√©pendantes ici mpg)\n\\(X\\) : Matrice des variables explicatives (ind√©pendantes), incluant une colonne de 1 pour l‚Äôintercept.\n\\(\\beta\\) : Vecteur des coefficients estim√©s du mod√®le.\n\\(\\epsilon\\) : Vecteur des erreurs r√©siduelles."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode-3",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode-3",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "M√©thode",
    "text": "M√©thode\nTests de significativit√© des coefficients\nTest t de Student\n\nHypoth√®se nulle  \\(H_0\\) : le coefficient est √©gal √† z√©ro (c‚Äôest-√†-dire, la variable n‚Äôa pas d‚Äôeffet significatif).\nHypoth√®se alternative \\(H_a\\) : Le coefficient est diff√©rent de z√©ro.\n\nSi la p-valeur est inf√©rieure √† un seuil significatif \\(p &lt; 0.05\\), nous rejetons l‚Äôhypoth√®se nulle et concluons que la variable a un effet significatif sur la variable d√©pendante."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode-4",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode-4",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "M√©thode",
    "text": "M√©thode\nSignificativit√© globale du mod√®le : Test F\n\nHypoth√®se nulle \\(H_0\\): Tous les coefficients sont √©gaux √† z√©ro (pas de pouvoir explicatif).\nHypoth√®se alternative \\(H_a\\) : Au moins un coefficient est diff√©rent de z√©ro (le mod√®le est significatif).\n\nSi la p-valeur du test \\(F\\) est inf√©rieure √† \\(0.05\\), nous rejetons l‚Äôhypoth√®se nulle et concluons que le mod√®le est significatif."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode-5",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode-5",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "M√©thode",
    "text": "M√©thode\nR-carr√© : qualit√© d‚Äôajustement\n\n\\(R^2\\) varie entre 0 et 1 :\n\nUn \\(R^2\\) proche de 1 signifie que le mod√®le explique bien les variations de la variable d√©pendante.\nUn \\(R^2\\) proche de 0 indique que le mod√®le n‚Äôexplique que peu ou pas les variations de la variable d√©pendante."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode-6",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#m√©thode-6",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "M√©thode",
    "text": "M√©thode\n\nVisualisations :\n\nGraphiques de dispersion (scatterplots) pour √©tudier les corr√©lations\nHistogrammes pour analyser la distribution des variables"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#pr√©sentation-de-l√©chantillon",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#pr√©sentation-de-l√©chantillon",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Pr√©sentation de l‚Äô√©chantillon",
    "text": "Pr√©sentation de l‚Äô√©chantillon\n\n\n\n\n\nTable 1 : Description des variables du jeu de donn√©es\n\n\nColonne\nNom\nDescription\n\n\n\n\n[,1]\nmpg\nMiles par gallon (US)\n\n\n[,2]\ncyl\nNombre de cylindres\n\n\n[,3]\ndisp\nCylindr√©e (en pouces cubes)\n\n\n[,4]\nhp\nPuissance brute (chevaux)\n\n\n[,5]\ndrat\nRapport du pont arri√®re\n\n\n[,6]\nwt\nPoids (en milliers de livres)\n\n\n[,7]\nqsec\nTemps pour parcourir 1/4 de mile\n\n\n[,8]\nvs\nType de moteur (0 = V, 1 = ligne droite)\n\n\n[,9]\nam\nType de transmission (0 = automatique, 1 = manuelle)\n\n\n[,10]\ngear\nNombre de vitesses avant\n\n\n[,11]\ncarb\nNombre de carburateurs\n\n\n\na R : mtcars"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#pr√©sentation-de-l√©chantillon-1",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#pr√©sentation-de-l√©chantillon-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Pr√©sentation de l‚Äô√©chantillon",
    "text": "Pr√©sentation de l‚Äô√©chantillon\nR√©sum√© statistiques\n\n\n\n\nTable 2 : R√©sum√© statistique des variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nmin\n10.400000\n4.000000\n71.1000\n52.00000\n2.7600000\n1.5130000\n14.500000\n0.0000000\n0.0000000\n3.0000000\n1.0000\n\n\nQ1.25%\n15.425000\n4.000000\n120.8250\n96.50000\n3.0800000\n2.5812500\n16.892500\n0.0000000\n0.0000000\n3.0000000\n2.0000\n\n\nQ3.75%\n22.800000\n8.000000\n326.0000\n180.00000\n3.9200000\n3.6100000\n18.900000\n1.0000000\n1.0000000\n4.0000000\n4.0000\n\n\nmed.50%\n19.200000\n6.000000\n196.3000\n123.00000\n3.6950000\n3.3250000\n17.710000\n0.0000000\n0.0000000\n4.0000000\n2.0000\n\n\nmean\n20.090625\n6.187500\n230.7219\n146.68750\n3.5965625\n3.2172500\n17.848750\n0.4375000\n0.4062500\n3.6875000\n2.8125\n\n\nmax\n33.900000\n8.000000\n472.0000\n335.00000\n4.9300000\n5.4240000\n22.900000\n1.0000000\n1.0000000\n5.0000000\n8.0000\n\n\ncount\n32.000000\n32.000000\n32.0000\n32.00000\n32.0000000\n32.0000000\n32.000000\n32.0000000\n32.0000000\n32.0000000\n32.0000\n\n\nsd\n6.026948\n1.785922\n123.9387\n68.56287\n0.5346787\n0.9784574\n1.786943\n0.5040161\n0.4989909\n0.7378041\n1.6152\n\n\nNA‚Äôs\n0.000000\n0.000000\n0.0000\n0.00000\n0.0000000\n0.0000000\n0.000000\n0.0000000\n0.0000000\n0.0000000\n0.0000\n\n\n\nNote: aR : mtcars"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#r√©sultats-principaux-mod√©lisation",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#r√©sultats-principaux-mod√©lisation",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "R√©sultats principaux : Mod√©lisation",
    "text": "R√©sultats principaux : Mod√©lisation\nS√©lection de mod√®le en ajoutant ou en supprimant des variables pour minimiser l‚ÄôAIC\n\n\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI\n      p-value\n    \n  \n  \n    wt\n-3.9\n-5.4, -2.5\n&lt;0.001\n    am\n2.9\n0.05, 5.8\n0.047\n    qsec\n1.2\n0.63, 1.8\n&lt;0.001\n  \n  \n    \n      Abbreviation: CI = Confidence Interval"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#r√©sultats-principaux-mod√©lisation-1",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#r√©sultats-principaux-mod√©lisation-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "R√©sultats principaux : Mod√©lisation",
    "text": "R√©sultats principaux : Mod√©lisation\n\nPoids (wt) : L‚Äôaugmentation du poids r√©duit la consommation de carburant, avec un coefficient n√©gatif significatif (p-value = 0.000199)\nNombre de cylindres (cyl) : L‚Äôeffet des cylindres est l√©g√®rement n√©gatif, mais le lien reste faible. p-value = 0.098480 (juste au seuil de signification √† 0.1)."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#r√©sultats-principaux-mod√©lisation-2",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#r√©sultats-principaux-mod√©lisation-2",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "R√©sultats principaux : Mod√©lisation",
    "text": "R√©sultats principaux : Mod√©lisation\n\nPuissance (hp) : Pas de relation directe significative entre la puissance et la consommation. p-value = 0.140015.\nOptimisation : Le mod√®le sugg√®re que la r√©duction du poids des voitures pourrait am√©liorer leur efficacit√© √©nerg√©tique."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#r√©sultats-s√©condaires",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#r√©sultats-s√©condaires",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "R√©sultats s√©condaires",
    "text": "R√©sultats s√©condaires\nR√©partition des voitures par cylindres\n\nLa majorit√© des voitures ont 4 ou 8 cylindres."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#r√©sultats-s√©condaires-1",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#r√©sultats-s√©condaires-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "R√©sultats s√©condaires",
    "text": "R√©sultats s√©condaires\nR√©partition des voitures par transmission"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#r√©sultats-s√©condaires-2",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#r√©sultats-s√©condaires-2",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "R√©sultats s√©condaires",
    "text": "R√©sultats s√©condaires"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#discussions-1",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#discussions-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Discussions",
    "text": "Discussions\n\nPoids (wt) : Impact significatif sur la consommation en carburant (mpg) avec une p-valeur tr√®s faible\nNombre de cylindres (cyl) : Effet marginalement significatif (p = 0,098)\nPuissance (hp) : Pas d‚Äôimpact significatif sur la consommation (p = 0,14)"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#discussions-2",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#discussions-2",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Discussions",
    "text": "Discussions\n\nR¬≤ ajust√© : 82,6 %, ce qui indique un bon ajustement du mod√®le\nTest F : Le mod√®le est globalement significatif (p &lt; 0,05).\nPuissance (hp) : Pas de relation directe significative entre la puissance et la consommation. p-value = 0.140015."
  },
  {
    "objectID": "FORMATIONS/logistic_regression_diabetes.html",
    "href": "FORMATIONS/logistic_regression_diabetes.html",
    "title": "Djamaldbz - Mod√©lisation des donn√©es √† variables d√©pendantes qualitatives : Regression logistique √† variable d√©pendante dichotomique",
    "section": "",
    "text": "Le mod√®le logistique est une technique statistique largement utilis√©e pour mod√©liser des variables d√©pendantes binaires ou des proportions. Il est fondamental en √©conom√©trie, en sciences sociales, en biostatistique et dans de nombreux autres domaines."
  },
  {
    "objectID": "FORMATIONS/logistic_regression_diabetes.html#importation-des-biblioth√®ques-necessaires",
    "href": "FORMATIONS/logistic_regression_diabetes.html#importation-des-biblioth√®ques-necessaires",
    "title": "Djamaldbz - Mod√©lisation des donn√©es √† variables d√©pendantes qualitatives : Regression logistique √† variable d√©pendante dichotomique",
    "section": "Importation des biblioth√®ques necessaires",
    "text": "Importation des biblioth√®ques necessaires\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nimport numpy as np"
  },
  {
    "objectID": "FORMATIONS/logistic_regression_diabetes.html#chargement-des-donn√©es-et-verification-suscinte-de-leur-qualit√©",
    "href": "FORMATIONS/logistic_regression_diabetes.html#chargement-des-donn√©es-et-verification-suscinte-de-leur-qualit√©",
    "title": "Djamaldbz - Mod√©lisation des donn√©es √† variables d√©pendantes qualitatives : Regression logistique √† variable d√©pendante dichotomique",
    "section": "Chargement des donn√©es et verification suscinte de leur qualit√©",
    "text": "Chargement des donn√©es et verification suscinte de leur qualit√©\n\ndf = pd.read_csv('diabetes-dataset.csv')\nprint('\\nAffichage des donn√©es\\n')\n\n\nAffichage des donn√©es\n\ndisplay(df.head(5))\n\n   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n0            6      148             72  ...                     0.627   50        1\n1            1       85             66  ...                     0.351   31        0\n2            8      183             64  ...                     0.672   32        1\n3            1       89             66  ...                     0.167   21        0\n4            0      137             40  ...                     2.288   33        1\n\n[5 rows x 9 columns]\n\nprint('\\nInformations sur les donn√©es\\n')\n\n\nInformations sur les donn√©es\n\ndisplay(df.info)\n\n&lt;bound method DataFrame.info of      Pregnancies  Glucose  ...  Age  Outcome\n0              6      148  ...   50        1\n1              1       85  ...   31        0\n2              8      183  ...   32        1\n3              1       89  ...   21        0\n4              0      137  ...   33        1\n..           ...      ...  ...  ...      ...\n763           10      101  ...   63        0\n764            2      122  ...   27        0\n765            5      121  ...   30        0\n766            1      126  ...   47        1\n767            1       93  ...   23        0\n\n[768 rows x 9 columns]&gt;\n\nprint('\\nResum√© statistique des donn√©es\\n')\n\n\nResum√© statistique des donn√©es\n\ndisplay(df.describe)\n\n&lt;bound method NDFrame.describe of      Pregnancies  Glucose  ...  Age  Outcome\n0              6      148  ...   50        1\n1              1       85  ...   31        0\n2              8      183  ...   32        1\n3              1       89  ...   21        0\n4              0      137  ...   33        1\n..           ...      ...  ...  ...      ...\n763           10      101  ...   63        0\n764            2      122  ...   27        0\n765            5      121  ...   30        0\n766            1      126  ...   47        1\n767            1       93  ...   23        0\n\n[768 rows x 9 columns]&gt;"
  },
  {
    "objectID": "FORMATIONS/logistic_regression_diabetes.html#chargement-des-donn√©es-et-verification-suscinte-de-leur-qualit√©-1",
    "href": "FORMATIONS/logistic_regression_diabetes.html#chargement-des-donn√©es-et-verification-suscinte-de-leur-qualit√©-1",
    "title": "Djamaldbz - Mod√©lisation des donn√©es √† variables d√©pendantes qualitatives : Regression logistique √† variable d√©pendante dichotomique",
    "section": "Chargement des donn√©es et verification suscinte de leur qualit√©",
    "text": "Chargement des donn√©es et verification suscinte de leur qualit√©\n\nAffichage des informations sur les donn√©es\n\ndf = pd.read_csv('diabetes-dataset.csv')\nprint('\\nAffichage des donn√©es\\n')\n\n\nAffichage des donn√©es\n\ndisplay(df.head(5))\n\n   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n0            6      148             72  ...                     0.627   50        1\n1            1       85             66  ...                     0.351   31        0\n2            8      183             64  ...                     0.672   32        1\n3            1       89             66  ...                     0.167   21        0\n4            0      137             40  ...                     2.288   33        1\n\n[5 rows x 9 columns]\n\nprint('\\nInformations sur les donn√©es\\n')\n\n\nInformations sur les donn√©es\n\ndisplay(df.info)\n\n&lt;bound method DataFrame.info of      Pregnancies  Glucose  ...  Age  Outcome\n0              6      148  ...   50        1\n1              1       85  ...   31        0\n2              8      183  ...   32        1\n3              1       89  ...   21        0\n4              0      137  ...   33        1\n..           ...      ...  ...  ...      ...\n763           10      101  ...   63        0\n764            2      122  ...   27        0\n765            5      121  ...   30        0\n766            1      126  ...   47        1\n767            1       93  ...   23        0\n\n[768 rows x 9 columns]&gt;\n\nprint('\\nResum√© statistique des donn√©es\\n')\n\n\nResum√© statistique des donn√©es\n\ndisplay(df.describe)\n\n&lt;bound method NDFrame.describe of      Pregnancies  Glucose  ...  Age  Outcome\n0              6      148  ...   50        1\n1              1       85  ...   31        0\n2              8      183  ...   32        1\n3              1       89  ...   21        0\n4              0      137  ...   33        1\n..           ...      ...  ...  ...      ...\n763           10      101  ...   63        0\n764            2      122  ...   27        0\n765            5      121  ...   30        0\n766            1      126  ...   47        1\n767            1       93  ...   23        0\n\n[768 rows x 9 columns]&gt;\n\n\n\n\nV√©rification des valeurs manquantes\n\ndf.columns.isna().sum()\n\n0\n\n\n¬†¬†¬†¬†¬†¬†Il y‚Äô a aucune valeur manquante car les donn√©es ont bien √©t√© nettoy√©es avant d‚Äô√™tre mise √† disposition sur kaggle.\n\n\nAffichage des statistiques des variables\n¬†¬†¬†¬†¬†¬†Etant donn√©es que les informations sur les variables sont en ce moment ou j‚Äô√©cris indisponibles sur kaggle.\n\nprint('Affichage des valeurs uniques des variables\\n')\n\nAffichage des valeurs uniques des variables\n\nfor variable in df.columns:\n    if variable != \"DiabetesPedigreeFunction\": # je saute car √ßa fait beaucoup long √† l'affichage\n      print(f'\\n {variable}\\n')\n      print(df[variable].unique())\n\n\n Pregnancies\n\n[ 6  1  8  0  5  3 10  2  4  7  9 11 13 15 17 12 14]\n\n Glucose\n\n[148  85 183  89 137 116  78 115 197 125 110 168 139 189 166 100 118 107\n 103 126  99 196 119 143 147  97 145 117 109 158  88  92 122 138 102  90\n 111 180 133 106 171 159 146  71 105 101 176 150  73 187  84  44 141 114\n  95 129  79   0  62 131 112 113  74  83 136  80 123  81 134 142 144  93\n 163 151  96 155  76 160 124 162 132 120 173 170 128 108 154  57 156 153\n 188 152 104  87  75 179 130 194 181 135 184 140 177 164  91 165  86 193\n 191 161 167  77 182 157 178  61  98 127  82  72 172  94 175 195  68 186\n 198 121  67 174 199  56 169 149  65 190]\n\n BloodPressure\n\n[ 72  66  64  40  74  50   0  70  96  92  80  60  84  30  88  90  94  76\n  82  75  58  78  68 110  56  62  85  86  48  44  65 108  55 122  54  52\n  98 104  95  46 102 100  61  24  38 106 114]\n\n SkinThickness\n\n[35 29  0 23 32 45 19 47 38 30 41 33 26 15 36 11 31 37 42 25 18 24 39 27\n 21 34 10 60 13 20 22 28 54 40 51 56 14 17 50 44 12 46 16  7 52 43 48  8\n 49 63 99]\n\n Insulin\n\n[  0  94 168  88 543 846 175 230  83  96 235 146 115 140 110 245  54 192\n 207  70 240  82  36  23 300 342 304 142 128  38 100  90 270  71 125 176\n  48  64 228  76 220  40 152  18 135 495  37  51  99 145 225  49  50  92\n 325  63 284 119 204 155 485  53 114 105 285 156  78 130  55  58 160 210\n 318  44 190 280  87 271 129 120 478  56  32 744 370  45 194 680 402 258\n 375 150  67  57 116 278 122 545  75  74 182 360 215 184  42 132 148 180\n 205  85 231  29  68  52 255 171  73 108  43 167 249 293  66 465  89 158\n  84  72  59  81 196 415 275 165 579 310  61 474 170 277  60  14  95 237\n 191 328 250 480 265 193  79  86 326 188 106  65 166 274  77 126 330 600\n 185  25  41 272 321 144  15 183  91  46 440 159 540 200 335 387  22 291\n 392 178 127 510  16 112]\n\n BMI\n\n[33.6 26.6 23.3 28.1 43.1 25.6 31.  35.3 30.5  0.  37.6 38.  27.1 30.1\n 25.8 30.  45.8 29.6 43.3 34.6 39.3 35.4 39.8 29.  36.6 31.1 39.4 23.2\n 22.2 34.1 36.  31.6 24.8 19.9 27.6 24.  33.2 32.9 38.2 37.1 34.  40.2\n 22.7 45.4 27.4 42.  29.7 28.  39.1 19.4 24.2 24.4 33.7 34.7 23.  37.7\n 46.8 40.5 41.5 25.  25.4 32.8 32.5 42.7 19.6 28.9 28.6 43.4 35.1 32.\n 24.7 32.6 43.2 22.4 29.3 24.6 48.8 32.4 38.5 26.5 19.1 46.7 23.8 33.9\n 20.4 28.7 49.7 39.  26.1 22.5 39.6 29.5 34.3 37.4 33.3 31.2 28.2 53.2\n 34.2 26.8 55.  42.9 34.5 27.9 38.3 21.1 33.8 30.8 36.9 39.5 27.3 21.9\n 40.6 47.9 50.  25.2 40.9 37.2 44.2 29.9 31.9 28.4 43.5 32.7 67.1 45.\n 34.9 27.7 35.9 22.6 33.1 30.4 52.3 24.3 22.9 34.8 30.9 40.1 23.9 37.5\n 35.5 42.8 42.6 41.8 35.8 37.8 28.8 23.6 35.7 36.7 45.2 44.  46.2 35.\n 43.6 44.1 18.4 29.2 25.9 32.1 36.3 40.  25.1 27.5 45.6 27.8 24.9 25.3\n 37.9 27.  26.  38.7 20.8 36.1 30.7 32.3 52.9 21.  39.7 25.5 26.2 19.3\n 38.1 23.5 45.5 23.1 39.9 36.8 21.8 41.  42.2 34.4 27.2 36.5 29.8 39.2\n 38.4 36.2 48.3 20.  22.3 45.7 23.7 22.1 42.1 42.4 18.2 26.4 45.3 37.\n 24.5 32.2 59.4 21.2 26.7 30.2 46.1 41.3 38.8 35.2 42.3 40.7 46.5 33.5\n 37.3 30.3 26.3 21.7 36.4 28.5 26.9 38.6 31.3 19.5 20.1 40.8 23.4 28.3\n 38.9 57.3 35.6 49.6 44.6 24.1 44.5 41.2 49.3 46.3]\n\n Age\n\n[50 31 32 21 33 30 26 29 53 54 34 57 59 51 27 41 43 22 38 60 28 45 35 46\n 56 37 48 40 25 24 58 42 44 39 36 23 61 69 62 55 65 47 52 66 49 63 67 72\n 81 64 70 68]\n\n Outcome\n\n[1 0]\n\n\nAu vu de ces valeurs, on peut dire que (vu qu‚Äôil n‚Äôy a aucune description des disponible sur kaggle):\n\npregnancies represente le nombre de grossesses contract√©es;\nglucose represente la quantit√© de glucose dans le sang;\nBloodPressure represente la pression sanguine;\nSkinThickness represente l‚Äô√©paisseur du pli cutan√© tricipital;\nBMI correspond √† l‚ÄôIndice de Masse Corporelle (IMC)\nAge de la patiente\nInsulin repr√©sente la concentration s√©rique d‚Äôinsuline mesur√©e (g√©n√©ralement en micro-unit√©s par millilitre (ŒºU/ml))\nDiabetesPedigreeFunction repr√©sente une mesure de la pr√©disposition g√©n√©tique au diab√®te\nOutcome represente l‚Äô√©tat de la patiente (atteinte ou non du diab√®te)"
  },
  {
    "objectID": "FORMATIONS/logistic_regression_diabetes.html#analyse-exploratoire-des-donn√©es",
    "href": "FORMATIONS/logistic_regression_diabetes.html#analyse-exploratoire-des-donn√©es",
    "title": "Djamaldbz - Mod√©lisation des donn√©es √† variables d√©pendantes qualitatives : Regression logistique √† variable d√©pendante dichotomique",
    "section": "Analyse exploratoire des donn√©es",
    "text": "Analyse exploratoire des donn√©es\n¬†¬†¬†¬†¬†¬†Cette analyse est effectu√©e dans l‚Äôoptique de mieux comprendre les donn√©es afin de pouvoir bien sp√©cifier le mod√®le logistique.\n\nAnalyse descriptives rapides (Voir la distribution des donn√©es)\n\n# Cr√©ation de la figure avec une grille 3 lignes x 2 colonnes\nfig, axes = plt.subplots(3, 2, figsize=(12, 12))\n\n# Premier sous-graphe : Distribution du nombre de grossesses\nsns.histplot(data=df['Pregnancies'], ax=axes[0, 0])\naxes[0, 0].set_title(\"Distribution du nombre de grossesses\")\n\n# Deuxi√®me sous-graphe : Distribution du niveau de glucose\nsns.histplot(data=df['Glucose'], ax=axes[0, 1])\naxes[0, 1].set_title(\"Distribution du niveau de glucose\")\n\n# Troisi√®me sous-graphe : Distribution de la pression sanguine\nsns.histplot(data=df['BloodPressure'], ax=axes[1, 0])\naxes[1, 0].set_title(\"Distribution de la pression sanguine\")\n\n# Quatri√®me sous-graphe : Distribution de l'√©paisseur du pli cutan√© (SkinThickness)\nsns.histplot(data=df['SkinThickness'], ax=axes[1, 1])\naxes[1, 1].set_title(\"Distribution de l'√©paisseur du pli cutan√©\")\n\n# Cinqui√®me sous-graphe : Distribution de l'insuline\nsns.histplot(data=df['Insulin'], ax=axes[2, 0])\naxes[2, 0].set_title(\"Distribution de l'insuline\")\n\n# Sixi√®me sous-graphe : Distribution de l'IMC (BMI)\nsns.histplot(data=df['BMI'], ax=axes[2, 1])\naxes[2, 1].set_title(\"Distribution de l'IMC\")\n\n# Ajustement automatique des espaces pour\n# √©viter le chevauchement des titres et labels\nplt.tight_layout()\n\n# Affichage de la figure\nplt.show()\n\n\n\n\n\n\nVerification de la colin√©arit√©\n¬†¬†¬†¬†¬†¬†En effet avant de sp√©cifier un mod√®le, il faut s‚Äôassurer qu‚Äôil n‚Äôy a pas multicolin√©arit√©. C‚Äôest-√†-dire verifier que les variables ne sont pas corr√©l√©es entre elles ce qui permettra d‚Äô√©viter de fausses estimations.\n\n# S√©lectionner que les variables num√©riques des donn√©es\ndf_variables_numeriques = df.select_dtypes(include=[np.number])\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(df_variables_numeriques.corr(), annot=True, cmap='coolwarm', fmt='.2f')\nplt.title('Heatmap de correlation des variables num√©riques du jeu de donn√©es')\nplt.tight_layout()\nplt.show()\n\n\n\n\n¬†¬†¬†¬†¬†¬†Ce corr√©lollogramme montre que les variables ne sont pas lin√©airement corr√©l√©es entre elle. Donc on peut ajuster le mod√®le de regression logistique."
  },
  {
    "objectID": "FORMATIONS/logistic_regression_diabetes.html#sp√©cification-et-√©valution-du-mod√®le-logistique",
    "href": "FORMATIONS/logistic_regression_diabetes.html#sp√©cification-et-√©valution-du-mod√®le-logistique",
    "title": "Djamaldbz - Mod√©lisation des donn√©es √† variables d√©pendantes qualitatives : Regression logistique √† variable d√©pendante dichotomique",
    "section": "Sp√©cification et √©valution du mod√®le logistique",
    "text": "Sp√©cification et √©valution du mod√®le logistique\n¬†¬†¬†¬†¬†¬†A ce niveau, j‚Äôai partitionn√© les donn√©es en ammont dans le but de faire du machine learning (ajustement, prediction et validation du mod√®le) plus tard (dans la section suivante). Nous avons les donn√©es d‚Äôentrainement qui constituent 80% des donn√©es et des donn√©es de test qui en constituent 20. Ici j‚Äôajuste juste un mod√®le de regression logistique aux donn√©es que j‚Äôessaie d‚Äôinterpreter.\n\n# Les biblioth√®ques de machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\nfrom sklearn.inspection import permutation_importance\n\n\n# Separation des variables explicatives and de la variable d√©pendante\n\n# X : matrice des variables explicatives\nX = df.drop('Outcome', axis=1)\n\n# y : variable d√©pendante\ny = df['Outcome']\n\n# partition des donn√©es en donn√©es de tests et d'entrainement\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nimport statsmodels.api as sm\n\n# Ajout d'une colonne de 1 pour l'intercept (obligatoire dans statsmodels)\nX_train_const = sm.add_constant(X_train)\n\n# Cr√©ation du mod√®le logistique\nmodel = sm.Logit(y_train, X_train_const)\n\n# Ajustement du mod√®le\nresult = model.fit()\n\nOptimization terminated successfully.\n         Current function value: 0.467835\n         Iterations 6\n\n# Affichage du r√©sum√© avec les p-values\ndisplay(result.summary())\n\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                Outcome   No. Observations:                  614\nModel:                          Logit   Df Residuals:                      605\nMethod:                           MLE   Df Model:                            8\nDate:                Mon, 19 May 2025   Pseudo R-squ.:                  0.2752\nTime:                        17:05:40   Log-Likelihood:                -287.25\nconverged:                       True   LL-Null:                       -396.34\nCovariance Type:            nonrobust   LLR p-value:                 9.311e-43\n============================================================================================\n                               coef    std err          z      P&gt;|z|      [0.025      0.975]\n--------------------------------------------------------------------------------------------\nconst                       -9.0359      0.837    -10.802      0.000     -10.675      -7.396\nPregnancies                  0.0645      0.036      1.791      0.073      -0.006       0.135\nGlucose                      0.0341      0.004      8.055      0.000       0.026       0.042\nBloodPressure               -0.0139      0.006     -2.260      0.024      -0.026      -0.002\nSkinThickness                0.0031      0.008      0.397      0.691      -0.012       0.019\nInsulin                     -0.0018      0.001     -1.782      0.075      -0.004       0.000\nBMI                          0.1026      0.017      5.948      0.000       0.069       0.136\nDiabetesPedigreeFunction     0.6945      0.330      2.107      0.035       0.049       1.341\nAge                          0.0371      0.011      3.400      0.001       0.016       0.058\n============================================================================================"
  },
  {
    "objectID": "FORMATIONS/logistic_regression_diabetes.html#qualit√©-dajustement",
    "href": "FORMATIONS/logistic_regression_diabetes.html#qualit√©-dajustement",
    "title": "Djamaldbz - Mod√©lisation des donn√©es √† variables d√©pendantes qualitatives : Regression logistique √† variable d√©pendante dichotomique",
    "section": "Qualit√© d‚ÄôAjustement",
    "text": "Qualit√© d‚ÄôAjustement\n\nLog-Likelihood : -287.25. Un log-vraisemblance plus √©lev√© (moins n√©gatif) indique un meilleur ajustement.\nPseudo R-squared : 0.2752. Cela signifie que le mod√®le explique environ 27.52% de la variabilit√© dans les donn√©es, ce qui indique un ajustement mod√©r√©. Dans les mod√®les lin√©aires g√©n√©ralis√©s, il est fr√©quent d‚Äôavoir des pseudo-R2 un peu faible.\nLLR p-value : 9.311e-43, tr√®s faible, indiquant que le mod√®le est significatif globalement."
  },
  {
    "objectID": "FORMATIONS/logistic_regression_diabetes.html#ad√©quation-du-mod√®le",
    "href": "FORMATIONS/logistic_regression_diabetes.html#ad√©quation-du-mod√®le",
    "title": "Djamaldbz - Mod√©lisation des donn√©es √† variables d√©pendantes qualitatives : Regression logistique √† variable d√©pendante dichotomique",
    "section": "Ad√©quation du Mod√®le",
    "text": "Ad√©quation du Mod√®le\n\nConvergence : Le mod√®le a converg√© en 6 it√©rations, sugg√©rant un bon comportement de l‚Äôalgorithme d‚Äôoptimisation.\nDf Model : 8, indiquant 8 variables explicatives."
  },
  {
    "objectID": "FORMATIONS/logistic_regression_diabetes.html#interpr√©tation-des-coefficients-1",
    "href": "FORMATIONS/logistic_regression_diabetes.html#interpr√©tation-des-coefficients-1",
    "title": "Djamaldbz - Mod√©lisation des donn√©es √† variables d√©pendantes qualitatives : Regression logistique √† variable d√©pendante dichotomique",
    "section": "Interpr√©tation des Coefficients",
    "text": "Interpr√©tation des Coefficients\nLa probabilit√© \\(p\\) que \\(y = 1\\) (c‚Äôest-√†-dire que la patiente ait le diab√®te) est donn√©e par la fonction sigmo√Øde :\n\\(p = \\frac{1}{1 + \\exp(-\\beta)}\\)\no√π : - \\(\\beta\\) est le coefficient du mod√®le de r√©gression logistique.\n\n\\(\\exp(-\\beta)\\) repr√©sente l‚Äôexponentielle de \\(-\\beta\\).\n\nAinsi, cette fonction transforme la valeur lin√©aire ( ) en une probabilit√© entre 0 et 1.\n\nIntercept (-9.0359) : Lorsque toutes les variables sont √† 0, la probabilit√© pr√©dite que y=1 est proche de 0.\nGlucose (0.0341, p&lt;0.001) : Une augmentation de 1 unit√© de glucose augmente significativement les odds de l‚Äôissue y=1.\nBMI (0.1026, p&lt;0.001) : Indique une relation positive forte entre l‚ÄôIMC et l‚Äôissue.\nBloodPressure (-0.0139, p=0.024) : Relation n√©gative significative, mais l‚Äôeffet est faible.\nDiabetesPedigreeFunction (0.6945, p=0.035) : Un ant√©c√©dent familial a un impact positif significatif.\nAge (0.0371, p=0.001) : L‚Äô√¢ge est un facteur significatif.\nSkinThickness et Insulin : Effet non significatif (au seuil de risque \\(\\alpha\\) = 0,05)."
  },
  {
    "objectID": "FORMATIONS/logistic_regression_diabetes.html#conclusion-1",
    "href": "FORMATIONS/logistic_regression_diabetes.html#conclusion-1",
    "title": "Djamaldbz - Mod√©lisation des donn√©es √† variables d√©pendantes qualitatives : Regression logistique √† variable d√©pendante dichotomique",
    "section": "Conclusion",
    "text": "Conclusion\nLe mod√®le a une bonne capacit√© pr√©dictive mais n‚Äôexplique pas toute la variabilit√©. Certaines variables sont significatives (Glucose, BMI, Age), alors que d‚Äôautres, comme l‚ÄôInsuline, ne le sont pas."
  },
  {
    "objectID": "FORMATIONS/logistic_regression_diabetes.html#machine-learning",
    "href": "FORMATIONS/logistic_regression_diabetes.html#machine-learning",
    "title": "Djamaldbz - Mod√©lisation des donn√©es √† variables d√©pendantes qualitatives : Regression logistique √† variable d√©pendante dichotomique",
    "section": "Machine learning",
    "text": "Machine learning\n\nAjustement du mod√®le aux donn√©es d‚Äôapprentissage\n\n# Initialisation et entrainnement du classificateur (Regression Logistique)\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\n\nLogisticRegression(max_iter=1000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression(max_iter=1000)\n\n# faire les prediction sur les donn√©es de test\ny_pred = model.predict(X_test)\n\n# calcul du score de pr√©cision\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy Score: {accuracy:.4f}')\n\nAccuracy Score: 0.7468\n\n\n¬†¬†¬†¬†¬†¬†L‚Äôaccuracy score de 0.7468 signifie que le mod√®le a correctement class√© 74.68% des √©chantillons dans le jeu de test. Cette m√©trique donne une indication de la proportion des pr√©dictions correctes par rapport au nombre total d‚Äôobservations. Plus l‚Äôaccuracy est proche de 1 (ou 100%), plus le mod√®le est performant.\n\n\nEvaluation du mod√®le\n\n\nMatrice de confusion\n\n\n\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(6,4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Matrice de confusion')\nplt.xlabel('Donn√©es pr√©dites')\nplt.ylabel('Donn√©es observ√©es')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\\[\n\\textbf{Vrais Positifs (VP)} = 37 \\quad \\text{(Mod√®le pr√©dit que la patiente a le diab√®te et c'est correct)}\n\\] \\[\n\\textbf{Faux Positifs (FP)} = 21 \\quad \\text{(Mod√®le pr√©dit que la patiente a le diab√®te, mais c'est incorrect)}\n\\]\n\\[\n\\textbf{Faux N√©gatifs (FN)} = 18 \\quad \\text{(Mod√®le pr√©dit que la patiente n'a pas le diab√®te, mais c'est incorrect)}\n\\]\n\\[\n\\textbf{Vrais N√©gatifs (VN)} = 78 \\quad \\text{(Mod√®le pr√©dit que la patiente n'a pas le diab√®te et c'est correct)}\n\\]\n\n\n\nM√©triques de performance\n\n\n\n\\[\n\\text{Pr√©cision} = \\frac{\\text{VP}}{\\text{VP} + \\text{FP}} = \\frac{37}{37 + 21} = \\frac{37}{58} \\approx 0.6379\n\\]\n\\[\n\\textbf{Rappel} (Recall) :\n\\text{Rappel} = \\frac{\\text{VP}}{\\text{VP} + \\text{FN}} = \\frac{37}{37 + 18} = \\frac{37}{55} \\approx 0.6727\n\\]\n\\[\n\\textbf{Score F1} (F1-Score) :\n\\text{F1-Score} = 2 \\times \\frac{\\text{Pr√©cision} \\times \\text{Rappel}}{\\text{Pr√©cision} + \\text{Rappel}} = 2 \\times \\frac{0.6379 \\times 0.6727}{0.6379 + 0.6727} \\approx 0.6548\n\\]\n\\[\n\\textbf{Exactitude} (Accuracy) :\n\\text{Exactitude} = \\frac{\\text{VP} + \\text{VN}}{\\text{Total}} = \\frac{37 + 78}{37 + 78 + 21 + 18} = \\frac{115}{154} \\approx 0.7468\n\\]\n\n\nCourbe de ROC\n\n\n\ny_prob = model.predict_proba(X_test)[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(6,4))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Courbe ROC (Aire = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlabel('Taux de Faux Positifs')\nplt.ylabel('Taux de Vrais Positifs')\nplt.title('Caract√©ristique de Performance du Mod√®le (Courbe ROC)')\nplt.legend(loc='lower right')\nplt.show()\n\n\n\n\n¬†¬†¬†¬†¬†¬†La courbe ROC (Receiver Operating Characteristic) est un graphique qui permet d‚Äô√©valuer la performance d‚Äôun mod√®le de classification binaire. Elle trace la relation entre :\n\nLe Taux de Vrais Positifs (TPR, True Positive Rate) : La proportion des vrais positifs parmi les cas positifs r√©els.\nLe Taux de Faux Positifs (FPR, False Positive Rate) : La proportion des faux positifs parmi les cas n√©gatifs r√©els.\n\n¬†¬†¬†¬†¬†¬†La courbe ROC montre comment le mod√®le se comporte pour diff√©rents seuils de d√©cision. Un mod√®le parfait aura une courbe qui monte rapidement vers le coin sup√©rieur gauche (haute TPR et faible FPR), tandis qu‚Äôun mod√®le al√©atoire suivra la diagonale du graphique (FPR = TPR).\n¬†¬†¬†¬†¬†¬†L‚ÄôAire Sous la Courbe (AUC) mesure la qualit√© globale du mod√®le. Une AUC proche de 1 indique un excellent mod√®le, tandis qu‚Äôune AUC proche de 0.5 indique un mod√®le √©quivalent √† un choix al√©atoire.\nDans notre cas AUC vaut 0,81 donc notre mod√®le tient la route.\n\n\n\nVerifions qu‚Äôon a les m√™me coefficients que ceux de l‚Äôajustement √† la section pr√©c√©dente\n\n\n\n\nmodel.intercept_\n\narray([-9.00707993])\n\n\n\n# affichage des coefficients estim√©s du mod√®le\nmodel.coef_\n\narray([[ 0.06436473,  0.03410147, -0.01387533,  0.00326297, -0.00180169,\n         0.10262329,  0.62588811,  0.03708342]])\n\n\nEt oui on a les m√™mes coefficients.\nSi vous avez des questions, vous pouvez me contacter !!!\nRetour √† la page d‚Äôaccueuil"
  },
  {
    "objectID": "FORMATIONS/PAYANTES/R/FormationR.html",
    "href": "FORMATIONS/PAYANTES/R/FormationR.html",
    "title": "Djamaldbz - Formations en R en pr√©sentiel et en ligne avec Djamal et Sa√Ød",
    "section": "",
    "text": "Ces formations sont con√ßues pour diff√©rents publics cibles : √©tudiants en pharmacie, m√©decine, biologie, statistiques et ceux aui sont dans des domaines n√©cessitant les stats ou pas. Chaque session dure 2 heures, avec une fr√©quence de 2 sessions par semaine. Les formations d√©butent le 22 f√©vrier 2025.\n\n\n\n\n5 000 FCFA par session de 2 heures.\nChaque formation compl√®te comprend 4 sessions, soit 20 000 FCFA par participant.\n\n\n\n\n\n\n\nCalendrier des Formations\n\n\nDate\nPublic.cible\nSujet\n\n\n\n\n22 f√©vrier\nPharmacie\nIntroduction √† R\n\n\n22 f√©vrier\nM√©decine\nIntroduction √† R\n\n\n22 f√©vrier\nBiologie\nIntroduction √† R\n\n\n26 f√©vrier\nStatistiques\nR pour les statisticiens\n\n\n\n\n\n\n\n\n\n\n\nObjectif : Apprendre √† g√©rer, analyser et visualiser des donn√©es pharmacologiques.\nSessions :\n\nIntroduction √† R.\nGestion des donn√©es pharmacologiques.\nVisualisation des donn√©es.\nAnalyse statistique (tests t, ANOVA).\n\n\n\n\n\n\nObjectif : Explorer des donn√©es cliniques et √©pid√©miologiques.\nSessions :\n\nIntroduction √† R.\nStatistiques descriptives.\nVisualisation des donn√©es m√©dicales.\n\n\n\n\n\n\nObjectif : Analyser des donn√©es biologiques\nSessions :\n\nIntroduction √† R.\nVisualisation des donn√©es biologiques.\nAnalyse statistique.\n\n\n\n\n\n\nObjectif : Approfondir les outils statistiques et analytiques.\nSessions :\n\nR pour les statisticiens.\nVisualisations avanc√©es avec ggplot2.\nMod√©lisation statistique (mod√®les lin√©aires, g√©n√©ralis√©s).\nProgrammation avanc√©e (cr√©ation de fonctions, etc ‚Ä¶).\n\n\n\n\n\n\n\n\nRappel\n\n\n\nPour celles et ceux qui ne font pas partie des domaines mentionn√©s, ne vous inqui√©tez pas : cette formation est con√ßue pour √™tre accessible et adapt√©e √† tous les profils. Vous en tirerez pleinement profit !\n\n\n\n\n\n\n\n\nLocalisation pour la formation en pr√©sentiel\n\n\n\nLes participants doivent √™tre au Burkina-Faso, plus pr√©cisement dans la ville de Bobo-Dioulasso. Les s√©ances en ligne interviendront rarement. Elles serviront √† donner certains details et seront une alternatives en cas d‚Äôemp√™chement !!!\n\n\n\n\n\n\n\n\nLocalisation pour la formation en pr√©sentiel\n\n\n\nPour les participants ayant des empechements (localisation g√©ographique, timing etc ‚Ä¶), une formartion ligne sera possible mais au lieu de 2h ce sera 1h30 !!!\n\n\n\n\n\n\nLes participants b√©n√©ficieront de formations pratiques, avec des cas d‚Äôutilisation adapt√©s √† leur domaine. Inscrivez-vous d√®s maintenant pour r√©server votre place! üòä\n\nPOUR PLUS D‚ÄôINFORMATIONS !!!\n\n¬†¬†¬†¬†¬†¬†Veuillez contacter le num√©ro whatsapp suivant : +226 57036356"
  },
  {
    "objectID": "FORMATIONS/PAYANTES/R/FormationR.html#plan-des-formations-en-r---niveau-1",
    "href": "FORMATIONS/PAYANTES/R/FormationR.html#plan-des-formations-en-r---niveau-1",
    "title": "Djamaldbz - Formations en R en pr√©sentiel et en ligne avec Djamal et Sa√Ød",
    "section": "",
    "text": "Ces formations sont con√ßues pour diff√©rents publics cibles : √©tudiants en pharmacie, m√©decine, biologie, statistiques et ceux aui sont dans des domaines n√©cessitant les stats ou pas. Chaque session dure 2 heures, avec une fr√©quence de 2 sessions par semaine. Les formations d√©butent le 22 f√©vrier 2025.\n\n\n\n\n5 000 FCFA par session de 2 heures.\nChaque formation compl√®te comprend 4 sessions, soit 20 000 FCFA par participant.\n\n\n\n\n\n\n\nCalendrier des Formations\n\n\nDate\nPublic.cible\nSujet\n\n\n\n\n22 f√©vrier\nPharmacie\nIntroduction √† R\n\n\n22 f√©vrier\nM√©decine\nIntroduction √† R\n\n\n22 f√©vrier\nBiologie\nIntroduction √† R\n\n\n26 f√©vrier\nStatistiques\nR pour les statisticiens\n\n\n\n\n\n\n\n\n\n\n\nObjectif : Apprendre √† g√©rer, analyser et visualiser des donn√©es pharmacologiques.\nSessions :\n\nIntroduction √† R.\nGestion des donn√©es pharmacologiques.\nVisualisation des donn√©es.\nAnalyse statistique (tests t, ANOVA).\n\n\n\n\n\n\nObjectif : Explorer des donn√©es cliniques et √©pid√©miologiques.\nSessions :\n\nIntroduction √† R.\nStatistiques descriptives.\nVisualisation des donn√©es m√©dicales.\n\n\n\n\n\n\nObjectif : Analyser des donn√©es biologiques\nSessions :\n\nIntroduction √† R.\nVisualisation des donn√©es biologiques.\nAnalyse statistique.\n\n\n\n\n\n\nObjectif : Approfondir les outils statistiques et analytiques.\nSessions :\n\nR pour les statisticiens.\nVisualisations avanc√©es avec ggplot2.\nMod√©lisation statistique (mod√®les lin√©aires, g√©n√©ralis√©s).\nProgrammation avanc√©e (cr√©ation de fonctions, etc ‚Ä¶).\n\n\n\n\n\n\n\n\nRappel\n\n\n\nPour celles et ceux qui ne font pas partie des domaines mentionn√©s, ne vous inqui√©tez pas : cette formation est con√ßue pour √™tre accessible et adapt√©e √† tous les profils. Vous en tirerez pleinement profit !\n\n\n\n\n\n\n\n\nLocalisation pour la formation en pr√©sentiel\n\n\n\nLes participants doivent √™tre au Burkina-Faso, plus pr√©cisement dans la ville de Bobo-Dioulasso. Les s√©ances en ligne interviendront rarement. Elles serviront √† donner certains details et seront une alternatives en cas d‚Äôemp√™chement !!!\n\n\n\n\n\n\n\n\nLocalisation pour la formation en pr√©sentiel\n\n\n\nPour les participants ayant des empechements (localisation g√©ographique, timing etc ‚Ä¶), une formartion ligne sera possible mais au lieu de 2h ce sera 1h30 !!!\n\n\n\n\n\n\nLes participants b√©n√©ficieront de formations pratiques, avec des cas d‚Äôutilisation adapt√©s √† leur domaine. Inscrivez-vous d√®s maintenant pour r√©server votre place! üòä\n\nPOUR PLUS D‚ÄôINFORMATIONS !!!\n\n¬†¬†¬†¬†¬†¬†Veuillez contacter le num√©ro whatsapp suivant : +226 57036356"
  },
  {
    "objectID": "FORMATIONS/poisson_paludisme.html",
    "href": "FORMATIONS/poisson_paludisme.html",
    "title": "Djamaldbz - Mod√©lisation des donn√©es de comptage",
    "section": "",
    "text": "Le monde actuel est confront√© √† de multiples risques sanitaires, notamment ceux li√©s aux maladies vectorielles telles que le paludisme. En effet, le paludisme est la maladie la plus mortelle transmise par les moustiques dans le monde ((OMS) 2023). Selon l‚ÄôOMS, plusieurs millions de personnes ont √©t√© infect√©es par le paludisme en 2022 (environ 249 millions), entra√Ænant pr√®s de 608 000 d√©c√®s(Mondiale de la Sant√©) 2023).\nPlusieurs actions ont √©t√© men√©es pour lutter contre ce fl√©au, notamment la distribution de moustiquaires, les campagnes de sensibilisation √† l‚Äôhygi√®ne, la chimiopr√©vention saisonni√®re, ainsi que le traitement intermittent pour les femmes enceintes.\nDjamaland a √©t√© choisi comme pays pour la mise en oeuvre d‚Äôune intervention progressive, principalement en raison de sa forte incidence du paludisme. L‚Äôintervention comprend quatre phases et couvre l‚Äôensemble des r√©gions du pays.\nVoici la description de chaque phase :\n\nPhase 1 : Aucun village n‚Äôa re√ßu d‚Äôintervention.\nPhase 2 : Les quatre r√©gions ont b√©n√©fici√© de la distribution de moustiquaires.\nPhase 3 : En plus de la distribution de moustiquaires, des actions de sensibilisation sur les bonnes pratiques d‚Äôutilisation ont √©t√© mises en place.\nPhase 3 suite : En compl√©ment de la distribution et de la sensibilisation, un programme de partage des techniques de bonne hygi√®ne a √©t√© int√©gr√©.\n\nLa base contenait √©galement des informations sur les facteurs environnementaux (pression atmosph√©rique, vitesse du vent, indice UV, humidit√© relative).\nLe but de cette √©tude est donc d‚Äô√©valuer l‚Äôimpact de l‚Äôintervention durant ces diff√©rentes phases.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(tidyverse)\nlibrary(gtsummary)\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(MASS) \nlibrary(car)\n\n\nInformation sur les variables\n\n¬†¬†¬†¬†¬†¬†On affiche ici les informations sur les variables de la base de donn√©es. On voit qu‚Äôil y‚Äôa 19 colonnes (variables) et 1040 lignes (observations).\n\ndata %&gt;%\n  glimpse()\n\nRows: 1.040\nColumns: 19\n$ Semaine                  &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14‚Ä¶\n$ R√©gion                   &lt;fct&gt; R1, R1, R1, R1, R1, R1, R1, R1, R1, R1, R1, R‚Ä¶\n$ Saison                   &lt;chr&gt; \"Seche\", \"Seche\", \"Seche\", \"Seche\", \"Seche\", ‚Ä¶\n$ Phase                    &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ `Taux de couverture`     &lt;dbl&gt; 0,1575155, 0,2576610, 0,1817954, 0,2766035, 0‚Ä¶\n$ Temp√©rature              &lt;dbl&gt; 25,52402, 31,06084, 28,69764, 28,11317, 30,57‚Ä¶\n$ Humidit√©                 &lt;dbl&gt; 43,75700, 44,61046, 51,25039, 49,40113, 48,49‚Ä¶\n$ Pluviom√©trie             &lt;dbl&gt; 16,0111516, 8,2997481, 44,7344354, 38,9232328‚Ä¶\n$ `Vitesse du vent`        &lt;dbl&gt; 6,239284, 7,855973, 3,604419, 6,324740, 2,649‚Ä¶\n$ `Pression atmosph√©rique` &lt;dbl&gt; 1015,6362, 1008,8631, 1008,3488, 1022,2085, 1‚Ä¶\n$ `Indice de chaleur`      &lt;dbl&gt; 19,83300, 25,96362, 23,67617, 22,94634, 25,61‚Ä¶\n$ `Couverture nuageuse`    &lt;dbl&gt; 82,280557, 57,209495, 32,469455, 14,619983, 1‚Ä¶\n$ `Vent en hauteur`        &lt;dbl&gt; 14,668663, 8,698154, 11,789413, 14,660355, 11‚Ä¶\n$ `Indice UV`              &lt;dbl&gt; 7,03602105, 10,09389904, 0,64470344, 5,463245‚Ä¶\n$ `Temp√©rature de l'eau`   &lt;dbl&gt; 33,22569, 28,26913, 28,00962, 29,71320, 28,66‚Ä¶\n$ `Humidit√© √† l‚Äôombre`     &lt;dbl&gt; 53,83643, 64,71406, 55,98915, 63,04538, 62,21‚Ä¶\n$ A√©rosols                 &lt;dbl&gt; 1,477347, 4,530642, 34,596087, 80,345317, 18,‚Ä¶\n$ `Cas palustres`          &lt;dbl&gt; 97, 62, 76, 66, 163, 67, 154, 168, 79, 58, 15‚Ä¶\n$ Dates                    &lt;date&gt; 2021-01-08, 2021-01-15, 2021-01-22, 2021-01-‚Ä¶\n\n\n¬†¬†¬†¬†¬†¬†On affiche ensuite un r√©sum√© statistique des variables dans le but de reperer certaines anomalies s‚Äôil y en a. Mais dans ce cas, il y‚Äôen a pas car j‚Äôai moi m√™me g√©n√©r√© les donn√©es et donc j‚Äôai veill√© √† ce qu‚Äôil n y ait pas de valeurs manquantes.\n\nlibrary(dplyr)\ndata %&gt;%\n  summary()\n\n    Semaine       R√©gion      Saison          Phase   Taux de couverture\n Min.   :  1,00   R1:260   Length:1040        0:516   Min.   :0,1001    \n 1st Qu.: 65,75   R2:260   Class :character   1:104   1st Qu.:0,2019    \n Median :130,50   R3:260   Mode  :character   2:208   Median :0,4023    \n Mean   :130,50   R4:260                      3:212   Mean   :0,4301    \n 3rd Qu.:195,25                                       3rd Qu.:0,6584    \n Max.   :260,00                                       Max.   :0,8998    \n  Temp√©rature       Humidit√©      Pluviom√©trie       Vitesse du vent\n Min.   :13,64   Min.   :35,41   Min.   :  0,04131   Min.   :2,001  \n 1st Qu.:23,97   1st Qu.:48,81   1st Qu.: 21,90016   1st Qu.:3,975  \n Median :27,09   Median :54,81   Median : 41,11740   Median :5,975  \n Mean   :27,08   Mean   :61,99   Mean   : 64,46301   Mean   :5,913  \n 3rd Qu.:30,21   3rd Qu.:78,54   3rd Qu.:106,59262   3rd Qu.:7,826  \n Max.   :40,19   Max.   :95,11   Max.   :199,59270   Max.   :9,998  \n Pression atmosph√©rique Indice de chaleur Couverture nuageuse Vent en hauteur \n Min.   : 980,4         Min.   : 8,405    Min.   : 0,0502     Min.   : 5,007  \n 1st Qu.:1006,5         1st Qu.:19,530    1st Qu.:25,7869     1st Qu.: 7,288  \n Median :1012,9         Median :22,434    Median :50,2530     Median : 9,831  \n Mean   :1012,9         Mean   :22,400    Mean   :50,5150     Mean   : 9,916  \n 3rd Qu.:1019,5         3rd Qu.:25,580    3rd Qu.:76,9193     3rd Qu.:12,654  \n Max.   :1041,6         Max.   :36,178    Max.   :99,9899     Max.   :14,995  \n   Indice UV         Temp√©rature de l'eau Humidit√© √† l‚Äôombre    A√©rosols       \n Min.   : 0,001759   Min.   :20,80        Min.   : 42,66     Min.   : 0,00251  \n 1st Qu.: 3,201972   1st Qu.:26,32        1st Qu.: 58,98     1st Qu.:23,49266  \n Median : 5,851642   Median :28,40        Median : 64,76     Median :47,47861  \n Mean   : 6,034127   Mean   :28,40        Mean   : 72,04     Mean   :48,53851  \n 3rd Qu.: 9,109514   3rd Qu.:30,54        3rd Qu.: 88,35     3rd Qu.:73,70956  \n Max.   :11,971607   Max.   :37,70        Max.   :104,38     Max.   :99,89207  \n Cas palustres       Dates           \n Min.   : 13,0   Min.   :2021-01-08  \n 1st Qu.: 58,0   1st Qu.:2022-04-06  \n Median : 93,0   Median :2023-07-03  \n Mean   :111,2   Mean   :2023-07-03  \n 3rd Qu.:145,2   3rd Qu.:2024-09-28  \n Max.   :466,0   Max.   :2025-12-26  \n\n\n¬†¬†¬†¬†¬†¬†Pour cette √©tude, la variable d‚Äôint√©r√™t est le nombre de nouveaux cas de paludisme enregistr√©s chaque semaine (t), avec des valeurs variant de 1 √† 260 dans les quatre r√©gions du pays."
  },
  {
    "objectID": "FORMATIONS/poisson_paludisme.html#description-du-jeu-de-donn√©es",
    "href": "FORMATIONS/poisson_paludisme.html#description-du-jeu-de-donn√©es",
    "title": "Djamaldbz - Mod√©lisation des donn√©es de comptage",
    "section": "",
    "text": "Le monde actuel est confront√© √† de multiples risques sanitaires, notamment ceux li√©s aux maladies vectorielles telles que le paludisme. En effet, le paludisme est la maladie la plus mortelle transmise par les moustiques dans le monde ((OMS) 2023). Selon l‚ÄôOMS, plusieurs millions de personnes ont √©t√© infect√©es par le paludisme en 2022 (environ 249 millions), entra√Ænant pr√®s de 608 000 d√©c√®s(Mondiale de la Sant√©) 2023).\nPlusieurs actions ont √©t√© men√©es pour lutter contre ce fl√©au, notamment la distribution de moustiquaires, les campagnes de sensibilisation √† l‚Äôhygi√®ne, la chimiopr√©vention saisonni√®re, ainsi que le traitement intermittent pour les femmes enceintes.\nDjamaland a √©t√© choisi comme pays pour la mise en oeuvre d‚Äôune intervention progressive, principalement en raison de sa forte incidence du paludisme. L‚Äôintervention comprend quatre phases et couvre l‚Äôensemble des r√©gions du pays.\nVoici la description de chaque phase :\n\nPhase 1 : Aucun village n‚Äôa re√ßu d‚Äôintervention.\nPhase 2 : Les quatre r√©gions ont b√©n√©fici√© de la distribution de moustiquaires.\nPhase 3 : En plus de la distribution de moustiquaires, des actions de sensibilisation sur les bonnes pratiques d‚Äôutilisation ont √©t√© mises en place.\nPhase 3 suite : En compl√©ment de la distribution et de la sensibilisation, un programme de partage des techniques de bonne hygi√®ne a √©t√© int√©gr√©.\n\nLa base contenait √©galement des informations sur les facteurs environnementaux (pression atmosph√©rique, vitesse du vent, indice UV, humidit√© relative).\nLe but de cette √©tude est donc d‚Äô√©valuer l‚Äôimpact de l‚Äôintervention durant ces diff√©rentes phases.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(tidyverse)\nlibrary(gtsummary)\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(MASS) \nlibrary(car)\n\n\nInformation sur les variables\n\n¬†¬†¬†¬†¬†¬†On affiche ici les informations sur les variables de la base de donn√©es. On voit qu‚Äôil y‚Äôa 19 colonnes (variables) et 1040 lignes (observations).\n\ndata %&gt;%\n  glimpse()\n\nRows: 1.040\nColumns: 19\n$ Semaine                  &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14‚Ä¶\n$ R√©gion                   &lt;fct&gt; R1, R1, R1, R1, R1, R1, R1, R1, R1, R1, R1, R‚Ä¶\n$ Saison                   &lt;chr&gt; \"Seche\", \"Seche\", \"Seche\", \"Seche\", \"Seche\", ‚Ä¶\n$ Phase                    &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ `Taux de couverture`     &lt;dbl&gt; 0,1575155, 0,2576610, 0,1817954, 0,2766035, 0‚Ä¶\n$ Temp√©rature              &lt;dbl&gt; 25,52402, 31,06084, 28,69764, 28,11317, 30,57‚Ä¶\n$ Humidit√©                 &lt;dbl&gt; 43,75700, 44,61046, 51,25039, 49,40113, 48,49‚Ä¶\n$ Pluviom√©trie             &lt;dbl&gt; 16,0111516, 8,2997481, 44,7344354, 38,9232328‚Ä¶\n$ `Vitesse du vent`        &lt;dbl&gt; 6,239284, 7,855973, 3,604419, 6,324740, 2,649‚Ä¶\n$ `Pression atmosph√©rique` &lt;dbl&gt; 1015,6362, 1008,8631, 1008,3488, 1022,2085, 1‚Ä¶\n$ `Indice de chaleur`      &lt;dbl&gt; 19,83300, 25,96362, 23,67617, 22,94634, 25,61‚Ä¶\n$ `Couverture nuageuse`    &lt;dbl&gt; 82,280557, 57,209495, 32,469455, 14,619983, 1‚Ä¶\n$ `Vent en hauteur`        &lt;dbl&gt; 14,668663, 8,698154, 11,789413, 14,660355, 11‚Ä¶\n$ `Indice UV`              &lt;dbl&gt; 7,03602105, 10,09389904, 0,64470344, 5,463245‚Ä¶\n$ `Temp√©rature de l'eau`   &lt;dbl&gt; 33,22569, 28,26913, 28,00962, 29,71320, 28,66‚Ä¶\n$ `Humidit√© √† l‚Äôombre`     &lt;dbl&gt; 53,83643, 64,71406, 55,98915, 63,04538, 62,21‚Ä¶\n$ A√©rosols                 &lt;dbl&gt; 1,477347, 4,530642, 34,596087, 80,345317, 18,‚Ä¶\n$ `Cas palustres`          &lt;dbl&gt; 97, 62, 76, 66, 163, 67, 154, 168, 79, 58, 15‚Ä¶\n$ Dates                    &lt;date&gt; 2021-01-08, 2021-01-15, 2021-01-22, 2021-01-‚Ä¶\n\n\n¬†¬†¬†¬†¬†¬†On affiche ensuite un r√©sum√© statistique des variables dans le but de reperer certaines anomalies s‚Äôil y en a. Mais dans ce cas, il y‚Äôen a pas car j‚Äôai moi m√™me g√©n√©r√© les donn√©es et donc j‚Äôai veill√© √† ce qu‚Äôil n y ait pas de valeurs manquantes.\n\nlibrary(dplyr)\ndata %&gt;%\n  summary()\n\n    Semaine       R√©gion      Saison          Phase   Taux de couverture\n Min.   :  1,00   R1:260   Length:1040        0:516   Min.   :0,1001    \n 1st Qu.: 65,75   R2:260   Class :character   1:104   1st Qu.:0,2019    \n Median :130,50   R3:260   Mode  :character   2:208   Median :0,4023    \n Mean   :130,50   R4:260                      3:212   Mean   :0,4301    \n 3rd Qu.:195,25                                       3rd Qu.:0,6584    \n Max.   :260,00                                       Max.   :0,8998    \n  Temp√©rature       Humidit√©      Pluviom√©trie       Vitesse du vent\n Min.   :13,64   Min.   :35,41   Min.   :  0,04131   Min.   :2,001  \n 1st Qu.:23,97   1st Qu.:48,81   1st Qu.: 21,90016   1st Qu.:3,975  \n Median :27,09   Median :54,81   Median : 41,11740   Median :5,975  \n Mean   :27,08   Mean   :61,99   Mean   : 64,46301   Mean   :5,913  \n 3rd Qu.:30,21   3rd Qu.:78,54   3rd Qu.:106,59262   3rd Qu.:7,826  \n Max.   :40,19   Max.   :95,11   Max.   :199,59270   Max.   :9,998  \n Pression atmosph√©rique Indice de chaleur Couverture nuageuse Vent en hauteur \n Min.   : 980,4         Min.   : 8,405    Min.   : 0,0502     Min.   : 5,007  \n 1st Qu.:1006,5         1st Qu.:19,530    1st Qu.:25,7869     1st Qu.: 7,288  \n Median :1012,9         Median :22,434    Median :50,2530     Median : 9,831  \n Mean   :1012,9         Mean   :22,400    Mean   :50,5150     Mean   : 9,916  \n 3rd Qu.:1019,5         3rd Qu.:25,580    3rd Qu.:76,9193     3rd Qu.:12,654  \n Max.   :1041,6         Max.   :36,178    Max.   :99,9899     Max.   :14,995  \n   Indice UV         Temp√©rature de l'eau Humidit√© √† l‚Äôombre    A√©rosols       \n Min.   : 0,001759   Min.   :20,80        Min.   : 42,66     Min.   : 0,00251  \n 1st Qu.: 3,201972   1st Qu.:26,32        1st Qu.: 58,98     1st Qu.:23,49266  \n Median : 5,851642   Median :28,40        Median : 64,76     Median :47,47861  \n Mean   : 6,034127   Mean   :28,40        Mean   : 72,04     Mean   :48,53851  \n 3rd Qu.: 9,109514   3rd Qu.:30,54        3rd Qu.: 88,35     3rd Qu.:73,70956  \n Max.   :11,971607   Max.   :37,70        Max.   :104,38     Max.   :99,89207  \n Cas palustres       Dates           \n Min.   : 13,0   Min.   :2021-01-08  \n 1st Qu.: 58,0   1st Qu.:2022-04-06  \n Median : 93,0   Median :2023-07-03  \n Mean   :111,2   Mean   :2023-07-03  \n 3rd Qu.:145,2   3rd Qu.:2024-09-28  \n Max.   :466,0   Max.   :2025-12-26  \n\n\n¬†¬†¬†¬†¬†¬†Pour cette √©tude, la variable d‚Äôint√©r√™t est le nombre de nouveaux cas de paludisme enregistr√©s chaque semaine (t), avec des valeurs variant de 1 √† 260 dans les quatre r√©gions du pays."
  },
  {
    "objectID": "FORMATIONS/poisson_paludisme.html#description-du-nombre-de-cas-pour-chaque-r√©gion",
    "href": "FORMATIONS/poisson_paludisme.html#description-du-nombre-de-cas-pour-chaque-r√©gion",
    "title": "Djamaldbz - Mod√©lisation des donn√©es de comptage",
    "section": "Description du nombre de cas pour chaque r√©gion",
    "text": "Description du nombre de cas pour chaque r√©gion\n\np1 &lt;- ggplot(data, aes(x = Dates, y = `Cas palustres`, color = R√©gion)) +\n  geom_line() +\n  facet_wrap(~R√©gion, scales = \"free_y\") +\n  labs(title = \"\", x = \"Ann√©e\", y = \"Nombre de cas\") +\n  geom_vline(xintercept = as.numeric(as.Date(\"2023-06-30\")), \n           linetype = \"dashed\", color = \"darkred\", size = 0.5) +\n  geom_vline(xintercept = as.numeric(as.Date(\"2023-12-29\")), \n           linetype = \"dashed\", color = \"darkblue\", size = 0.5) +\n  geom_vline(xintercept = as.numeric(as.Date(\"2024-12-24\")), \n           linetype = \"dashed\", color = \"royalblue\", size = 0.5) +\n  theme_light() +\n  scale_x_date(date_breaks = \"12 months\", date_labels = \"%b %Y\") +  \n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\np_interactif1 &lt;- ggplotly(p1)\n\np_interactif1\n\n\n\nFigure 1 : Evolution du nombre de cas de paludisme entre 2021 et 2025\n\n\n¬†¬†¬†¬†¬†¬†La courbe des s√©ries temporelles des cas de paludisme de 2021 √† 2025 pour les quatre r√©gions de l‚Äô√©tude montre une tendance g√©n√©rale √† la baisse, particuli√®rement marqu√©e apr√®s la mise en place des interventions. L‚Äôinterpretation reste quasi pareille pour toute les regions.\nLe test de Mann-Kendall confirme statistiquement cette tendance d√©croissante significative (p-value &lt; 0.05), avec une diminution notable observ√©e dans chaque r√©gion d√®s l‚Äôimpl√©mentation de la premi√®re phase du projet (figure @ref{fig:evolution}).\nPar ailleurs, le test de Kruskal-Wallis appliqu√© aux diff√©rentes phases du projet r√©v√®le une diff√©rence significative entre le nombre de cas observ√©s avant et apr√®s les interventions (p-value &lt; 0.05), sugg√©rant un impact positif des mesures mises en place.\nEnfin, le pic √©pid√©mique le plus √©lev√© a √©t√© observ√© en 2021 dans les r√©gions 1, 3 et 4, avec respectivement 392, 396 et 466 cas de paludisme enregistr√©s aux mois de septembre et octobre. Pour la r√©gion 2, le pic a √©t√© atteint en 2022, avec 384 cas observ√©s (figure @ref{fig:evolution})."
  },
  {
    "objectID": "FORMATIONS/poisson_paludisme.html#mod√©lisation",
    "href": "FORMATIONS/poisson_paludisme.html#mod√©lisation",
    "title": "Djamaldbz - Mod√©lisation des donn√©es de comptage",
    "section": "Mod√©lisation",
    "text": "Mod√©lisation\n\nAnalyse de la corr√©lation entre les variables m√©t√©orologiques\n¬†¬†¬†¬†¬†¬†L‚Äôanalyse de la corr√©lation entre les variables montre des liens de corr√©lation relativement faibles. De plus, le calcul de l‚Äôindice de KMO, permettant de v√©rifier l‚Äôad√©quation des donn√©es √† l‚Äôanalyse en composantes principales, a montr√© une valeur de 0,5, confirmant le faible niveau de corr√©lation entre les covariables et ne justifiant ainsi pas la r√©alisation d‚Äôune ACP.\n\ndata_meteo &lt;- data[ , c(6:10 , 13)]\n\n##-- Calcul de la matrice de corr√©lation\ncor_matrix &lt;- cor(data_meteo, use = \"complete.obs\")\n\n##-- Transformation de la matrice de corr√©lation en format long pour ggplot2\ncor_melted &lt;- melt(cor_matrix)\ncor_melted$value &lt;- round(cor_melted$value , 2)\ncolnames(cor_melted)[3] &lt;- \"Coefficient de corr√©lation\"\n\n##-- Cr√©ation de la heatmap\ncor_plot &lt;- ggplot(cor_melted, aes(x = Var1, y = Var2, fill = `Coefficient de corr√©lation`)) +\n  geom_tile() +\n  scale_fill_gradient2(low = \"blue\", mid = \"white\", high = \"red\", midpoint = 0) +  \n##-- Bleu pour n√©gatif, rouge pour positif\n  theme_light() +\n  labs(x = \"Variables\",\n       y = \"Variables\") +\n  theme(\n    axis.text.x = element_text(angle = 90, hjust = 1, size = 10, face = \"bold\"),\n    axis.text.y = element_text(size = 10, face = \"bold\"),\n    axis.title.x = element_text(size = 10, face = \"bold\"),\n    axis.title.y = element_text(size = 10, face = \"bold\")\n  )\nggplotly(cor_plot)\n\n\n\nFigure 2 : Heatmap des Corr√©lations entre Variables M√©t√©orologiques\n\n\n\nlibrary(psych)\ndata_meteo &lt;- data[, 6:17]\nKMO(data_meteo)\n\nError in solve.default(r) : \n  system is computationally singular: reciprocal condition number = 2.76177e-18\n\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = data_meteo)\nOverall MSA =  0,5\nMSA for each item = \n           Temp√©rature               Humidit√©           Pluviom√©trie \n                   0,5                    0,5                    0,5 \n       Vitesse du vent Pression atmosph√©rique      Indice de chaleur \n                   0,5                    0,5                    0,5 \n   Couverture nuageuse        Vent en hauteur              Indice UV \n                   0,5                    0,5                    0,5 \n  Temp√©rature de l'eau     Humidit√© √† l‚Äôombre               A√©rosols \n                   0,5                    0,5                    0,5 \n\n\n\n\nMod√©lisation\n\nmodel &lt;- glm(`Cas palustres` ~ Temp√©rature + `Taux de couverture` + Humidit√© + Pluviom√©trie + `Vitesse du vent` + `Pression atmosph√©rique` + Phase, \n             data = data, family = poisson())\n\n#summary(model, exponentiate = TRUE)\n\n\ntbl_regression(model, exponentiate = TRUE) %&gt;%\n  add_global_p() %&gt;%\n  modify_header(label = \"**Variables**\") %&gt;%\n  bold_labels() %&gt;%\n  modify_caption(caption = capTab(\"R√©sultats de la r√©gression de Poisson : Analyse des facteurs de risque\"))\n\n\n\n\n\n  Tableau 1 : R√©sultats de la r√©gression de Poisson : Analyse des facteurs de risque\n  \n    \n      Variables\n      IRR\n      95% CI\n      p-value\n    \n  \n  \n    Temp√©rature\n1,00\n1,00, 1,00\n0,002\n    Taux de couverture\n1,13\n1,07, 1,20\n&lt;0,001\n    Humidit√©\n1,01\n1,01, 1,01\n&lt;0,001\n    Pluviom√©trie\n1,00\n1,00, 1,00\n&lt;0,001\n    Vitesse du vent\n0,97\n0,97, 0,98\n&lt;0,001\n    Pression atmosph√©rique\n1,00\n1,00, 1,00\n&lt;0,001\n    Phase\n\n\n&lt;0,001\n    ¬†¬†¬†¬†0\n‚Äî\n‚Äî\n\n    ¬†¬†¬†¬†1\n0,41\n0,39, 0,42\n\n    ¬†¬†¬†¬†2\n0,45\n0,43, 0,46\n\n    ¬†¬†¬†¬†3\n0,49\n0,47, 0,51\n\n  \n  \n    \n      Abbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n    \n  \n  \n\n\n\n\n\n√âvaluation du mod√®le de Poisson\n\n¬†¬†¬†¬†¬†¬†Ici le stepAIC permet de fournir une s√©lection de variables qui am√©liore le mod√®le (crit√®re d‚ÄôAIC que j‚Äôaborderai dans une autre publication). L‚Äôobjectif est de minimiser l‚ÄôAIC, donc nous devons conserver les variables dont la suppression entra√Æne une forte augmentation de l‚ÄôAIC.\n\nD√©cision de suppression des variables\n\nLa s√©lection des variables repose sur leur impact sur l‚ÄôAIC (Akaike Information Criterion). Plus l‚ÄôAIC augmente apr√®s suppression d‚Äôune variable, plus cette derni√®re est importante pour le mod√®le. Les variables sont class√©es en deux groupes : celles √† conserver absolument et celles qui ont un impact mod√©r√©. La fonction stepAIC permet de faire automatiquement la s√©lection des variables importante dans le mod√®le.\n\nmod1_poisson &lt;- stepAIC(model) \n\nStart:  AIC=22725,07\n`Cas palustres` ~ Temp√©rature + `Taux de couverture` + Humidit√© + \n    Pluviom√©trie + `Vitesse du vent` + `Pression atmosph√©rique` + \n    Phase\n\n                           Df Deviance   AIC\n&lt;none&gt;                           16104 22725\n- Temp√©rature               1    16114 22733\n- `Taux de couverture`      1    16121 22740\n- `Pression atmosph√©rique`  1    16132 22751\n- `Vitesse du vent`         1    16525 23144\n- Humidit√©                  1    17231 23850\n- Pluviom√©trie              1    18145 24763\n- Phase                     3    19109 25723\n\n\n\n\nA conserver absolument\n\n\nCes variables entra√Ænent une forte augmentation de l‚ÄôAIC si elles sont supprim√©es, ce qui indique qu‚Äôelles contribuent de mani√®re significative √† l‚Äôexplication des cas palustres.\n\nPhase : +2998 d‚ÄôAIC\nPluviom√©trie : +2038 d‚ÄôAIC\nHumidit√© : +1125 d‚ÄôAIC\n\n\n\nVariables mod√©r√©ment importantes\n\n\nCes variables ont un impact plus faible sur l‚ÄôAIC et peuvent potentiellement √™tre supprim√©es sans alt√©rer significativement la qualit√© du mod√®le.\n\nVitesse du vent : +419 d‚ÄôAIC\nPression atmosph√©rique : +26 d‚ÄôAIC\nTaux de couverture : +15 d‚ÄôAIC\nTemp√©rature : +8 d‚ÄôAIC\n\n\n\nD√©cision\n\n\nLes variables Phase, Pluviom√©trie et Humidit√© doivent imp√©rativement √™tre conserv√©es, car leur suppression entra√Æne une augmentation tr√®s importante de l‚ÄôAIC. En revanche, Vitesse du vent, Pression atmosph√©rique, Taux de couverture et Temp√©rature ont un impact plus limit√© et peuvent √™tre envisag√©es pour la suppression si n√©cessaire.\n\ntbl_regression(model, exponentiate = TRUE) %&gt;%\n  add_global_p() %&gt;%\n  modify_header(label = \"**Variables**\") %&gt;%\n  bold_labels() %&gt;%\n  modify_caption(caption = capTab(\"R√©sultats de la r√©gression de Poisson suite au stepAIC : Analyse des facteurs de risque\"))\n\n\n\n\n\n  Tableau 2 : R√©sultats de la r√©gression de Poisson suite au stepAIC : Analyse des facteurs de risque\n  \n    \n      Variables\n      IRR\n      95% CI\n      p-value\n    \n  \n  \n    Temp√©rature\n1,00\n1,00, 1,00\n0,002\n    Taux de couverture\n1,13\n1,07, 1,20\n&lt;0,001\n    Humidit√©\n1,01\n1,01, 1,01\n&lt;0,001\n    Pluviom√©trie\n1,00\n1,00, 1,00\n&lt;0,001\n    Vitesse du vent\n0,97\n0,97, 0,98\n&lt;0,001\n    Pression atmosph√©rique\n1,00\n1,00, 1,00\n&lt;0,001\n    Phase\n\n\n&lt;0,001\n    ¬†¬†¬†¬†0\n‚Äî\n‚Äî\n\n    ¬†¬†¬†¬†1\n0,41\n0,39, 0,42\n\n    ¬†¬†¬†¬†2\n0,45\n0,43, 0,46\n\n    ¬†¬†¬†¬†3\n0,49\n0,47, 0,51\n\n  \n  \n    \n      Abbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n    \n  \n  \n\n\n\n\n\npar(mfrow = c(2,2))\nplot(mod1_poisson)\n\n\n\n\nFigure 3 : Graphiques de diagnostic du mod√®le de poisson ajust√©\n\n\n\n\n¬†¬†¬†¬†¬†¬†L‚Äôanalyse des diagnostics du mod√®le montre que les r√©sidus de Pearson pr√©sentent une r√©partition al√©atoire des points autour de z√©ro, sugg√©rant l‚Äôabsence de structure particuli√®re dans les erreurs.\nDe plus, dans le graphique Q-Q, les points suivent approximativement la ligne diagonale, indiquant que les r√©sidus sont normalement distribu√©s, ce qui est un bon signe pour la validit√© des hypoth√®ses du mod√®le.\nLa structure des erreurs standard de Pearson montre √©galement une r√©partition √©quilibr√©e autour de la ligne rouge de r√©f√©rence, et un motif al√©atoire est observ√© au niveau des √©carts types de Pearson.\nTous ces √©l√©ments sugg√®rent une bonne ad√©quation du mod√®le aux donn√©es et confirment que les hypoth√®ses sous-jacentes sont raisonnablement respect√©es.\n\n\nAnalyse de la surdispersion dans un mod√®le de Poisson\n\n\n\nmod1_poisson %&gt;% \n  performance::check_overdispersion()\n\n# Overdispersion test\n\n       dispersion ratio =    14.991\n  Pearson's Chi-Squared = 15441.190\n                p-value =   &lt; 0.001\n\n\n¬†¬†¬†¬†¬†¬†Ce resultat sugg√®re qu‚Äôil y‚Äôa surdispersion dans les donn√©es (p-values &lt; 0,05). Dans ce cas plusieurs alternatives sont possibles. Nous avons entre autres le mod√®le de regression binomiale n√©gative qui est m√©lange de poisson-gamma et donc prend en compte un param√®tre qui est celui de la dispersion. On a √©galement le mod√®le quasi-poisson qui lui supprime la surdispersion pr√©sente dans les donn√©es √† l‚Äôinverse du mod√®le binomial n√©gatif qui l‚Äôestime.\n\n\nAlternative : Le modele binomial negative\n\n\n¬†¬†¬†¬†¬†¬†En alternative au mod√®le de Poisson en cas de surdispersion, le mod√®le binomial n√©gatif a √©t√© mentionn√© (Cameron and Trivedi 2013). En effet, ce mod√®le int√®gre un param√®tre suppl√©mentaire qui permet de mieux capturer la variabilit√© excessive des donn√©es, offrant ainsi une estimation plus fiable et adapt√©e aux situations o√π la variance des observations est sup√©rieure √† la moyenne.\n\nmodel_nb &lt;- glm.nb(`Cas palustres` ~ Temp√©rature + `Taux de couverture` + Humidit√© + Pluviom√©trie + `Vitesse du vent` + `Pression atmosph√©rique` + Phase, \n                   data = data)\n\nmodel_nb &lt;- stepAIC(model_nb)\n\nStart:  AIC=10479,97\n`Cas palustres` ~ Temp√©rature + `Taux de couverture` + Humidit√© + \n    Pluviom√©trie + `Vitesse du vent` + `Pression atmosph√©rique` + \n    Phase\n\n                           Df   AIC\n- Temp√©rature               1 10478\n- `Pression atmosph√©rique`  1 10478\n- `Taux de couverture`      1 10479\n&lt;none&gt;                        10480\n- `Vitesse du vent`         1 10505\n- Humidit√©                  1 10544\n- Pluviom√©trie              1 10568\n- Phase                     3 10662\n\nStep:  AIC=10478,09\n`Cas palustres` ~ `Taux de couverture` + Humidit√© + Pluviom√©trie + \n    `Vitesse du vent` + `Pression atmosph√©rique` + Phase\n\n                           Df   AIC\n- `Pression atmosph√©rique`  1 10476\n- `Taux de couverture`      1 10477\n&lt;none&gt;                        10478\n- `Vitesse du vent`         1 10503\n- Humidit√©                  1 10547\n- Pluviom√©trie              1 10566\n- Phase                     3 10660\n\nStep:  AIC=10476,24\n`Cas palustres` ~ `Taux de couverture` + Humidit√© + Pluviom√©trie + \n    `Vitesse du vent` + Phase\n\n                       Df   AIC\n- `Taux de couverture`  1 10476\n&lt;none&gt;                    10476\n- `Vitesse du vent`     1 10502\n- Humidit√©              1 10545\n- Pluviom√©trie          1 10564\n- Phase                 3 10658\n\nStep:  AIC=10475,49\n`Cas palustres` ~ Humidit√© + Pluviom√©trie + `Vitesse du vent` + \n    Phase\n\n                    Df   AIC\n&lt;none&gt;                 10476\n- `Vitesse du vent`  1 10501\n- Humidit√©           1 10544\n- Pluviom√©trie       1 10563\n- Phase              3 11113\n\n\n\ntbl_regression(model_nb, exponentiate = TRUE) %&gt;%\n  add_global_p() %&gt;%\n  modify_header(label = \"**Variables**\") %&gt;%\n  bold_labels() %&gt;%\n  modify_caption(caption = capTab(\"R√©sultats de la r√©gression de Binomial n√©gative : Analyse des facteurs de risque\"))\n\n\n\n\n\n  Tableau 3 : R√©sultats de la r√©gression de Binomial n√©gative : Analyse des facteurs de risque\n  \n    \n      Variables\n      IRR\n      95% CI\n      p-value\n    \n  \n  \n    Humidit√©\n1,01\n1,01, 1,01\n&lt;0,001\n    Pluviom√©trie\n1,00\n1,00, 1,00\n&lt;0,001\n    Vitesse du vent\n0,97\n0,96, 0,98\n&lt;0,001\n    Phase\n\n\n&lt;0,001\n    ¬†¬†¬†¬†0\n‚Äî\n‚Äî\n\n    ¬†¬†¬†¬†1\n0,44\n0,40, 0,47\n\n    ¬†¬†¬†¬†2\n0,47\n0,45, 0,51\n\n    ¬†¬†¬†¬†3\n0,51\n0,48, 0,55\n\n  \n  \n    \n      Abbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n    \n  \n  \n\n\n\n\n\n\nInterpretation des r√©sultats\n\n\n\n\n\n\n\n\nIntervalles de confiances des variables m√©t√©orologiques\n\n\n\nLes intervalles de confiance des variables m√©t√©orologiques sont aussi petits car les donn√©es ont √©t√© g√©n√©r√©es. Et donc du coup avec de vraies donn√©es, il est possible de se retrouver avec des intervalles de confiance qui pourraient ne pas ressembler √† ceux-ci.\n\n\n\nL‚Äôhumidit√© augmente le nombre de cas de paludisme de 1% tandis que la vitesse de vent diminue le nombre de cas de paludisme de 3% (IC =[2% ; 4%]) toute chose √©tant √©gale par ailleur (l‚Äôinfluence des autres variables √©tant retir√©e).\nLa premi√®re phase d‚Äôinterventions a permis de reduire le nombre de cas de paludisme de 56% (IC = [53% ; 60%]) par rapport √† la phase 0 pendant laquelle il n‚Äôy avait pas encore d‚Äôintervention toute chose etant √©gale par ailleurs.\nLa seconde phase d‚Äôinterventions a permis de reduire le nombre de cas de paludisme de 53% (IC = [49% ; 55%]) par rapport √† la phase 0 pendant laquelle il n‚Äôy avait pas encore d‚Äôintervention toute chose etant √©gale par ailleurs.\nLa troisi√®me phase d‚Äôinterventions a permis de reduire le nombre de cas de paludisme de 49% (IC = [45% ; 52%]) par rapport √† la phase 0 pendant laquelle il n‚Äôy avait pas encore d‚Äôintervention toute chose etant √©gale par ailleurs."
  },
  {
    "objectID": "FORMATIONS/poisson_paludisme.html#annexes",
    "href": "FORMATIONS/poisson_paludisme.html#annexes",
    "title": "Djamaldbz - Mod√©lisation des donn√©es de comptage",
    "section": "Annexes",
    "text": "Annexes\n\nDiagnostic du mod√®le binomial n√©gatif\n\n\nAnalyse des r√©sidus\n\n\n\npar(mfrow = c(2,2))\nplot(model_nb)\n\n\n\n\nFigure 4 : Graphiques de diagnostic du mod√®le binomial n√©gatif ajust√©\n\n\n\n\n\n\nMulticolin√©arit√© du mod√®le binomial n√©gatif\n\n\n\nplot(performance::check_collinearity(model_nb))\n\n\n\n\nFigure 5 : VIF du mod√®le binomial n√©gatif\n\n\n\n\n¬†¬†¬†¬†¬†¬†On remarque que toutes les variables ont un faible VIF &lt; 5. Cela sugg√®re qu‚Äôil n‚Äôy a pas de multicolin√©arit√© entre les variables utilis√©es dans le mod√®le.\n\n\nTest de Mann-Kendall\n¬†¬†¬†¬†¬†¬†Ce test a √©t√© utilis√© avec les alternatives unilat√©rales droite et gauche pour tester la pr√©sence de tendances strictement croissantes ou strictement d√©croissantes de la serie nombre de cas hebdomadire de paludisme dans chaque r√©gion d‚Äôetudes.\nHypoth√®ses du test\n\\[\n\\begin{cases}\nH_0 : \\text{La s√©rie ne pr√©sente pas de tendance monotone (croissante ou d√©croissante).} \\\\\nH_1 : \\text{La s√©rie pr√©sente une tendance monotone (croissante ou d√©croissante).}\n\\end{cases}\n\\] Interpr√©tation\n\nSi la p-value est inf√©rieure au seuil de signification choisi (g√©n√©ralement 0,05),\nalors il y a suffisamment de preuves pour conclure que la s√©rie (nombre de cas de paludisme\nou incidences cumul√©es durant une phase) pr√©sente une tendance monotone.\n\nDans le cas contraire, on conclut que la s√©rie ne pr√©sente aucune tendance significative.\n\n\n\nDescription du mod√®le de Poisson\n¬†¬†¬†¬†¬†¬†Soit (\\(Y\\)) le nombre de cas de paludisme hebdomadire Il s‚Äôagit d‚Äôune variable quantitative discr√®te prenant ses valeurs dans un intervalle d√©fini. Supposons en outre que ces √©v√©nements sont ind√©pendants, c‚Äôest-√†-dire que l‚Äôoccurrence d‚Äôun premier cas n‚Äôaffecte pas la probabilit√© d‚Äôen observer un autre.\nDans ce contexte, la variable (\\(Y\\)) suit une distribution de Poisson, avec un param√®tre () repr√©sentant le taux moyen d‚Äôapparition d‚Äôun cas de paludisme. La probabilit√© d‚Äôobserver une valeur donn√©e de (\\(Y\\)), en fonction de (), est exprim√©e par la formule suivante :\n\\[ P(Y = y) = \\frac{\\lambda^y}{y!} e^{-\\lambda} \\]\nLa distribution de Poisson n‚Äôa qu‚Äôun param√®tre: () correspond √† la fois √† sa moyenne et √† sa variance.\n\\[E(\\lambda) = V(\\lambda)\\] Le mod√®le de Poisson a √©t√© utilis√© pour identifier les facteurs associ√©s √† la survenue du cas de paludisme, principalement en raison de la nature discr√®te de notre variable d√©pendante.\nLa r√©gression de Poisson s‚Äôinscrit dans le cadre des mod√®les lin√©aires g√©n√©ralis√©s, o√π la variable r√©ponse (\\(Y\\)) suit une distribution de Poisson :\n\\[ y \\sim \\text{Poisson}(\\lambda) \\]\nPuisque () doit √™tre un nombre positif, nous utiliserons la fonction de logarithme comme lien avec le pr√©dicteur lin√©aire.\n\\[ \\log{\\lambda} = \\eta = \\beta_0 + \\sum_{i = 1}^m \\beta_i x_i \\]\n\n\nEstimation des parametres\nL‚Äôestimation des param√®tres d‚Äôun mod√®le de Poisson repose sur la m√©thode du maximum de vraisemblance (MV). Voici les √©tapes essentielles de l‚Äôestimation :\n. Fonction de Vraisemblance\nLa fonction de vraisemblance pour (n) observations est donn√©e par :\n\\[L(\\beta) = \\prod_{i=1}^{n} \\frac{\\lambda_i^{y_i} e^{-\\lambda_i}}{y_i!}\\]\nEn prenant le logarithme, on obtient la log-vraisemblance :\n\\[\\ell(\\beta) = \\sum_{i=1}^{n} \\left[ y_i \\log(\\lambda_i) - \\lambda_i - \\log(y_i!) \\right]\\]\nEn rempla√ßant ( _i ) par ( e^{X_i } ), on obtient :\n\\[\\ell(\\beta) = \\sum_{i=1}^{n} \\left[ y_i (X_i \\beta) - e^{X_i \\beta} - \\log(y_i!) \\right]\\]\nEstimation par Maximum de Vraisemblance\nL‚Äôestimation des param√®tres ( ) se fait en maximisant la log-vraisemblance. Comme il n‚Äôexiste pas de solution analytique simple, on utilise des m√©thodes num√©riques telles que l‚Äôalgorithme de Newton-Raphson ou la descente de gradient.\n\n\nAnalyse de la presence de surdispersion dans les donn√©es\nTel que mentionn√© plus haut, l‚Äôind√©pendance des observations est un pr√©requis du mod√®le de Poisson. Sa non-v√©rification peut entra√Æner une surdispersion des donn√©es. Cette surdispersion est quantifi√©e par un param√®tre ( ) qui multiplie la variance attendue : pour une moyenne ( ), la variance devient donc ( ).\nPlus rarement, il peut arriver que ( &lt; 1 ), ce qui correspond √† une sous-dispersion des observations. Contrairement √† la surdispersion, o√π les observations ont tendance √† √™tre regroup√©es, la sous-dispersion traduit une r√©partition plus r√©guli√®re que pr√©vu.\nAfin de s‚Äôassurer de la pertinence du mod√®le choisi, une analyse de la surdispersion a √©t√© r√©alis√©e √† l‚Äôaide du **test de surdispersion*. Les hypoth√®ses du test √©taient les suivantes :\n\nHypoth√®se nulle ((H_0)) : absence de surdispersion (le mod√®le de Poisson est appropri√©).\nHypoth√®se alternative ((H_1)) : pr√©sence de surdispersion (le mod√®le de Poisson n‚Äôest pas adapt√©).\n\nCrit√®re de d√©cision : Une p-value inf√©rieure √† 0,05 conduit au rejet de ( H_0), indiquant la pr√©sence d‚Äôune surdispersion et la n√©cessit√© d‚Äôenvisager un mod√®le alternatif (comme le quasi-Poisson ou le Poisson n√©gatif)."
  },
  {
    "objectID": "FORMATIONS/poisson_paludisme.html#r√©f√©rence",
    "href": "FORMATIONS/poisson_paludisme.html#r√©f√©rence",
    "title": "Djamaldbz - Mod√©lisation des donn√©es de comptage",
    "section": "R√©f√©rence",
    "text": "R√©f√©rence\n\n\nCameron, A. Colin, and Pravin K. Trivedi. 2013. Regression Analysis of Count Data. 2nd ed. Econometric Society Monographs. Cambridge: Cambridge University Press. https://doi.org/10.1017/CBO9781139013567.\n\n\nMondiale de la Sant√©), OMS (Organisation. 2023. ‚ÄúWorld Malaria-report 2023-briefing-kit-fre.pdf.‚Äù https://cdn.who.int/media/docs/default-source/malaria/world-malaria-reports/wmr2022-regional-briefing-kit-fre.pdf?sfvrsn=7cb400ed_6&download=true.\n\n\n(OMS), Organisation MOndiale de la sant√©. 2023. ‚ÄúGlobal technical strategy for malaria 2016-2030.‚Äù https://iris.who.int/handle/10665/176712."
  },
  {
    "objectID": "FORMATIONS/presentations.html",
    "href": "FORMATIONS/presentations.html",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "",
    "text": "packages &lt;- c(\"ggplot2\",\"haven\", \"gtsummary\", \"corrr\", \"MASS\",\n              \"dplyr\",\"haven\", \"rstatix\", \"tidyverse\", \"ggpubr\",\n              \"glue\", \"dplyr\",\"ggspatial\", \"ggrepel\",\n              \"readxl\", \"stringr\", \"colorspace\") \n            \nfor (pkg in packages) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}"
  },
  {
    "objectID": "FORMATIONS/presentations.html#faire-ses-pr√©sentations-directement-avec-r-et-rstudio",
    "href": "FORMATIONS/presentations.html#faire-ses-pr√©sentations-directement-avec-r-et-rstudio",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Faire ses pr√©sentations directement avec R et Rstudio",
    "text": "Faire ses pr√©sentations directement avec R et Rstudio\n\nPourquoi utiliser R et Rstudio pour ses pr√©sentations ?\n\n¬†¬†¬†¬†¬†¬†R et RStudio offrent des outils puissants pour cr√©er des pr√©sentations dynamiques, reproductibles et int√©gr√©es √† vos analyses de donn√©es. Voici quelques raisons :\n\nInt√©gration parfaite des analyses et des pr√©sentations :\n\nNous pouvons combiner code, graphiques, tableaux et explications textuelles dans un seul document. Cela garantit une reproductibilit√© totale : les r√©sultats sont automatiquement mis √† jour si vos donn√©es changent.\n\nFlexibilit√© avec RMarkdown :\n\nCr√©ez des pr√©sentations dans divers formats : HTML (slidy, reveal.js), PDF (Beamer), ou powerpoint ppt. Les formats sont hautement personnalisables pour r√©pondre √† vos besoins esth√©tiques et fonctionnels.\n\nSimplification du travail collaboratif :\n\nIl y‚Äôa une possibilit√© de garder un fichier .tex pour ceux qui sont √† l‚Äôaise avec latex.\n\n\nMaintenant allons-y !!!\n\n\n\n\n\nCommen√ßons par une pr√©sentation revaljs\n\n\n\n\nInstaller les packages n√©cessaires\n\nAssurez-vous d‚Äôavoir le package revealjs install√©. Si ce n‚Äôest pas le cas, installez-le avec :\ninstall.packages(\"revealjs\")\n\nCr√©er un fichier RMarkdown pour une pr√©sentation\n\nCr√©er un nouveau fichier RMarkdown :\n\nAllez dans : File &gt; New File &gt; Quarto presentation\nDans la fen√™tre qui s‚Äôouvre : Entrez un titre et un auteur. Dans l‚Äôoption Default Output Format, choisissez From Template &gt; Revealjs Presentation.\n\n\nChanger l‚Äôen-t√™te YAML\n\nEn image voici, un descriptif visuel des 04 petites √©tapes pour la cr√©ation du fichier avec des images :\n\n\n\n\n\n\nEtape 1\n\n\n\n\n\n\n\nEtape 2\n\n\n\n\n\n\n\n\n\nEtape 3\n\n\n\n\n\n\n\nEtape 4\n\n\n\n\n\n\n\n\n\nExplication de l‚Äôen-t√™te YAML"
  },
  {
    "objectID": "FORMATIONS/presentations.html#informations-g√©n√©rales",
    "href": "FORMATIONS/presentations.html#informations-g√©n√©rales",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Informations g√©n√©rales",
    "text": "Informations g√©n√©rales\n\ntitle : Titre principal de la pr√©sentation\n\nIci : ‚ÄúANALYSE EXPLORATOIRE DES DONNEES MTCARS‚Äù. C‚Äôest ce qui s‚Äôaffiche en haut de la premi√®re diapositive.\n\nauthor : Nom(s) des pr√©sentateur(s)\n\nIci : ‚ÄúPresented by Djamal Toe‚Äù.\n\ninstitute : Institution ou organisation associ√©e\n\nIci : ‚ÄúNational School for Statistic and Data Analysis‚Äù.\n-date : Date de la pr√©sentation\nIci, elle est g√©n√©r√©e dynamiquement avec : 2025-05-19. Cela affichera automatiquement la date du jour o√π le fichier est tricot√©."
  },
  {
    "objectID": "FORMATIONS/presentations.html#format-et-personnalisation-reveal.js",
    "href": "FORMATIONS/presentations.html#format-et-personnalisation-reveal.js",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Format et personnalisation (reveal.js)",
    "text": "Format et personnalisation (reveal.js)\nLa section format: revealjs: contient des options sp√©cifiques √† la biblioth√®que reveal.js, permettant de personnaliser la pr√©sentation.\n\nVitesse de transition:  transition-speed: fast d√©finit la vitesse des transitions entre les diapositives. Options possibles : slow, normal, fast.\nAspect ratio :  aspect_ratio: \"16:9\" sp√©cifie le ratio largeur/hauteur des diapositives. Le ratio ‚Äú16:9‚Äù est id√©al pour les √©crans modernes (√©cran large). Autres options possibles : ‚Äú4:3‚Äù, ‚Äú3:2‚Äù, etc.\nMarges : margin: 0.02 d√©finit l‚Äôespace vide autour du contenu de chaque diapositive. Une valeur faible (comme 0.02) maximise l‚Äôespace utilis√© sur chaque diapositive.\nCentrage : center: true permet de Centrer le contenu verticalement et horizontalement sur chaque diapositive.\nPied de page : footer: ‚ÄúEnglish classes with Milonnet‚Äù : Ajoute un texte en bas de chaque diapositive, comme une signature ou une note de contexte.\nLogo : logo: \"logo_ensai.png\" affiche un logo en haut √† droite de chaque diapositive. L‚Äôimage doit √™tre plac√©e dans le r√©pertoire sp√©cifi√© ou un chemin relatif correct doit √™tre utilis√©.\nCSS personnalis√© : css: style.css permet d‚Äôutiliser un fichier CSS externe pour personnaliser les styles. Exemple : changer les polices, couleurs, tailles, etc. Le fichier style.css doit √™tre dans le m√™me r√©pertoire ou le chemin appropri√© doit √™tre indiqu√©.\nGestion des figure : fig_caption: yes active l‚Äôaffichage des l√©gendes sous les graphiques ins√©r√©s.\nTable des mati√®res (ToC) : toc: true active l‚Äôaffichage d‚Äôune table des mati√®res, toc-expand: false exige que les sections de la table des mati√®res ne soient pas d√©velopp√©es par d√©faut, toc-depth: 1 d√©finit la profondeur de la hi√©rarchie affich√©e dans la table des mati√®res (seulement les titres principaux #)."
  },
  {
    "objectID": "FORMATIONS/presentations.html#pr√©visualition",
    "href": "FORMATIONS/presentations.html#pr√©visualition",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Pr√©visualition",
    "text": "Pr√©visualition\n¬†¬†¬†¬†¬†¬†Pendant que vous faites la pr√©sentations sur Rstudio, vous pouvez la pr√©sualiser. Regardez les images ci-apr√®s :\n\n\n\n\n\n\nPrevisualisation : etape 1\n\n\n\n\n\n\n\nPrevisualisation : etape 2\n\n\n\n\n\n\n\n\n\nCompilation et Previsualisation : etape 3\n\n\n\n\n\n\n\n\n\n\n\nViewer ou Presenation ?\n\n\n\nA l‚Äô√©tape 2 de la pr√©visualisation, il se peut que la pr√©visualisation apparaisse dans la partie Presentation juste √† droite de l‚Äôonglet Viewer encercl√© en rouge sur l‚Äôimage."
  },
  {
    "objectID": "FORMATIONS/presentations.html#mise-en-forme-avec-le-fichier-css",
    "href": "FORMATIONS/presentations.html#mise-en-forme-avec-le-fichier-css",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Mise en forme avec le fichier CSS",
    "text": "Mise en forme avec le fichier CSS\n¬†¬†¬†¬†¬†¬†Pour cette section ne vous inquietez pas si vous n‚Äôavez pas de connaissance en html ou en css, nous utiliserons juste un code css pour la mise en forme du titre."
  },
  {
    "objectID": "FORMATIONS/presentations.html#t√©l√©charger-le-fichier-de-la-pr√©sentation",
    "href": "FORMATIONS/presentations.html#t√©l√©charger-le-fichier-de-la-pr√©sentation",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "T√©l√©charger le fichier de la pr√©sentation",
    "text": "T√©l√©charger le fichier de la pr√©sentation\nAvant de t√©l√©charger le fichier, vous pouvez voir ce qu‚Äôil donne en cliquant sur ce lien\nVous pouvez t√©l√©charger le fichier d‚Äôanalyse exploratoire des donn√©es mtcars au format .qmd ci-dessous.\nT√©l√©charger le fichier .qmd\nSi vous avez des questions, vous pouvez me contacter !!!\nRetour √† la page d‚Äôaccueuil"
  },
  {
    "objectID": "FORMATIONS/SIG.html",
    "href": "FORMATIONS/SIG.html",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "",
    "text": "packages &lt;- c(\"ggplot2\",\"haven\", \"gtsummary\", \"corrr\", \"MASS\",\n              \"dplyr\",\"haven\", \"rstatix\", \"tidyverse\", \"ggpubr\",\n              \"glue\", \"dplyr\",\"ggspatial\", \"ggrepel\",\"marmap\", \n              \"readxl\", \"stringr\", \"colorspace\", \"sf\", \"viridis\",\n              \"tools\",\"ggspatial\",\"readxl\",\"openxlsx\",\"grid\",\n              \"outliers\",\"car\",\"ftExtra\",\"tibble\",\n              \"gtsummary\", \"wesanderson\", \"viridis\",\n              \"RColorBrewer\", \"knitr\", \"kableExtra\") \n            \nfor (pkg in packages) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}"
  },
  {
    "objectID": "FORMATIONS/SIG.html#comment-faire-des-cartes-choropl√®thes-et-des-cartes-de-proportions-avec-r",
    "href": "FORMATIONS/SIG.html#comment-faire-des-cartes-choropl√®thes-et-des-cartes-de-proportions-avec-r",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Comment faire des cartes Choropl√®thes et des cartes de proportions avec R ?",
    "text": "Comment faire des cartes Choropl√®thes et des cartes de proportions avec R ?\n¬†¬†¬†¬†¬†¬†Les cartes choropl√®thes et les cartes de proportions sont des outils puissants pour visualiser des donn√©es g√©ospatiales dans R. Ces cartes permettent de repr√©senter des valeurs quantitatives (par exemple, des taux de population, des moyennes) sur des zones g√©ographiques, souvent des r√©gions administratives comme des d√©partements, des communes, ou des zones g√©ographiques personnalis√©es.\n\nIntroduction aux Cartes Choropl√®thes et Cartes de Proportions\n\nLes cartes choropl√®thes colorient les r√©gions g√©ographiques en fonction de valeurs num√©riques ou de proportions, facilitant l‚Äôanalyse spatiale et la compr√©hension des variations g√©ographiques. Elles sont couramment utilis√©es pour des donn√©es socio-√©conomiques, de sant√© publique, ou des analyses environnementales.\nLes cartes de proportions sont similaires mais mettent davantage l‚Äôaccent sur les ratios ou proportions par rapport √† une valeur totale, comme des pourcentages ou des fractions de populations.\n\nNotions de Base : Polygones, Shapefiles et Coordonn√©es Avant de cr√©er ces cartes, il est important de comprendre quelques notions de base, comme les polygones et les shapefiles :\n\n\n\n\n\n\n\nPolygones\n\n\n\nUne zone g√©ographique est souvent repr√©sent√©e par un polygone, une forme g√©om√©trique ferm√©e qui peut avoir plusieurs c√¥t√©s. Par exemple, une commune ou un d√©partement sur une carte peut √™tre repr√©sent√©e comme un polygone.\n\n\n\n\n\n\n\n\nShapefiles\n\n\n\nCe sont un format de fichier standard pour stocker des informations g√©ospatiales, y compris les coordonn√©es de points, de lignes et de polygones. Ils peuvent contenir les g√©om√©tries des entit√©s g√©ographiques ainsi que leurs attributs (valeurs associ√©es √† chaque r√©gion, comme le revenu moyen ou le taux de ch√¥mage).\n\n\n\n\n\n\n\n\nCoordonn√©es g√©ographiques\n\n\n\nLes coordonn√©es (latitude et longitude) permettent de positionner ces polygones sur une carte. En R, on utilise des syst√®mes de coordonn√©es g√©ographiques et projet√©es pour g√©rer et visualiser ces donn√©es.\n\n\nPlusieurs pakages permettent de visualiser les donn√©es avec les cartes, ici nous interessons aux packages glue et sf.\n\nZone d‚Äô√©tude\n\nSupposons que nous menions une √©tude au Burkina-Faso. Par exemple, nous m√©surer des indicateurs tels que le taux de mortalit√©, la couverture sanitaire etc ‚Ä¶ Le Burkina Faso est un pays qui compte 13 regions, mais notre etude s‚Äô√©tend seulement sur 8 regions. Il convient de montrer toutes les regions, puis de mettre en ex√®gue celles qui nous concernent.\n\nPlace au code\n\n\n\nvoir/cacher le code\n\n\n###---- Chargement des shapefiles src = GADM\nroot &lt;- getwd() ##-- la racine du repertoire\n\n##- La carte du pays sans les polygones des regions, communes et/ou departements\npath0 &lt;- paste0(root,\"/DATA_SIG/BFA2/gadm41_BFA_0.shp\")\n\n##- La carte du pays avec le polygone des regions, sans ceux des communes et/ou departements\npath1 &lt;- paste0(root,\"/DATA_SIG/BFA2/gadm41_BFA_1.shp\")\n\n##- La carte du pays avec le polygone des regions, sans ceux des communes et/ou departements\npath2 &lt;- paste0(\"/DATA_SIG/BFA2/gadm41_BFA_2.shp\")\n\n##- La carte du pays avec le polygone des regions, sans ceux des communes et/ou departements\npath3 &lt;- paste0(root,\"/DATA_SIG/BFA2/gadm41_BFA_3.shp\")\n\n\n##-- selection des regions concern√©es\n\nstudy.area &lt;-  c(\"Boucle du Mouhoun\", \"Centre-Est\", \"Centre-Nord\",\n             \"Centre-Ouest\", \"Nord\", \"Sud-Ouest\",\n             \"Haut-Bassins\", \"Cascades\")\n\n##-- lecture des shapefiles\npays_shp &lt;- read_sf(glue(path0), quiet = T)\nregion_shp &lt;- read_sf(glue(path1), quiet = T)\n#commune_shp &lt;- read_sf(glue(path2), quiet = T)\n#province_shp &lt;- read_sf(glue(path3), quiet = T)\n\n##-- cr√©ation d'une sous base avec les polygones des regions s√©lectionn√©s\n\ndata_region &lt;- region_shp %&gt;% filter(NAME_1 %in% study.area)\n\n\n##-- Study area colors\nstudy_zone_colors &lt;- c(\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\",\n                       \"#3FE1B8\", \"#9467bd\", \"#8c564b\",\n                       \"#00008B\", \"#4B0082\")\n\nstudy_zone_map &lt;- ggplot() +\n  geom_sf(data = pays_shp, aes(linewidth = \"Burkina Faso\"),fill = \"white\", color = \"black\") +\n  geom_sf(data = region_shp, aes(fill = ifelse(\n    NAME_1 %in% study.area,\n    \"Regions d'√©tudes\",\n    \"Autres regions\"\n  ) )) +\n  geom_sf_text(data = region_shp, aes(label = ifelse(\n    NAME_1 %in% study.area,\n    study.area,\n    \"\"\n  )), size = 4)+\n  ggspatial::annotation_scale(\n    location = \"br\",\n    bar_cols = c(\"black\", \"white\")\n  )  +\n  theme_light()+\n  ggspatial::annotation_north_arrow(\n    location = \"tr\", which_north = \"true\",\n    pad_x = unit(0.05, \"in\"), pad_y = unit(0.05, \"in\"),\n    style = ggspatial::north_arrow_nautical(\n      fill = c(\"black\", \"white\"),\n      line_col = \"black\"\n    )\n  )+\n  xlab(\"\")+\n  ylab(\"\")+\n  scale_linewidth_manual(values = c(1.2), name = \"\")+\n  scale_fill_manual(values = c(\"white\",\"#1f77b4\"), name=\"Zone d'√©tude\")+\n  theme_light() + \n  guides(\n    linewidth = guide_legend(order = 1),\n    fill = guide_legend(order = 2),\n    color = guide_legend(order = 3)\n  )\n\n\n\nstudy_zone_map\n\n\n\n\nCartographie de la zone d‚Äô√©tude\n\n\n\n\n\nExpliquons le code √† pr√©sent\n\n\nCharger les fichier shapefiles :\n\nglue : pour preparer la structure du format (optionnel)\nreadsf : pour lire les fichiers shapefiles\n\nDefinir la zone d‚Äô√©tude : les fichier shapefile devient comme un dataframe, donc est manipulable au m√™me titre que les fichiers excel, csv etc ‚Ä¶\nOn trace d‚Äôabord la carte du pays, ensuite on ajoute la couche des regions (c‚Äôest-√†-dire le shapefile des regions). On pourrait le faire simplement avec le shapefile des regions sans celui du pays.\nEnsuite on ajoute la couleur pour la zone concern√©e et les noms des regions s√©lectionn√©es avec geom_sf_text\nannotation_scale permet d‚Äôajouter une barre d‚Äô√©chelle (scale bar) √† une carte avec la position br pour dire bottom rigth (en bas √† droite)\nannotation_north_arrow est utilis√©e pour ajouter une fl√®che du nord sur une carte cr√©√©e avec ggplot2\nPour le reste il s‚Äôagit des fonctions qu‚Äôon utilise couramment avec ggplot2\n\n\n\nAfficher/Masquer le tableau\n\n\n\n\n\nTableau 1 : Les 10 premi√®res lignes du shapefile\n\n\nGID_1\nGID_0\nCOUNTRY\nNAME_1\nVARNAME_1\nNL_NAME_1\nTYPE_1\nENGTYPE_1\nCC_1\nHASC_1\nISO_1\ngeometry\n\n\n\n\nBFA.1_1\nBFA\nBurkina Faso\nBoucle du Mouhoun\nNA\nNA\nR√©gion\nRegion\nNA\nBF.BO\nNA\nPOLYGON ((-2,73901 11,71249...\n\n\nBFA.2_1\nBFA\nBurkina Faso\nCascades\nNA\nNA\nR√©gion\nRegion\nNA\nBF.CD\nNA\nPOLYGON ((-4,591742 9,70225...\n\n\nBFA.7_1\nBFA\nBurkina Faso\nCentre\nNA\nNA\nR√©gion\nRegion\nNA\nBF.CT\nNA\nPOLYGON ((-1,2786 12,13921,...\n\n\nBFA.3_1\nBFA\nBurkina Faso\nCentre-Est\nNA\nNA\nR√©gion\nRegion\nNA\nBF.CE\nNA\nPOLYGON ((0,4371 11,67655, ...\n\n\nBFA.4_1\nBFA\nBurkina Faso\nCentre-Nord\nNA\nNA\nR√©gion\nRegion\nNA\nBF.CN\nNA\nPOLYGON ((-0,7773 12,66989,...\n\n\nBFA.5_1\nBFA\nBurkina Faso\nCentre-Ouest\nNA\nNA\nR√©gion\nRegion\nNA\nBF.CO\nNA\nPOLYGON ((-2,360162 11,0081...\n\n\nBFA.6_1\nBFA\nBurkina Faso\nCentre-Sud\nNA\nNA\nR√©gion\nRegion\nNA\nBF.CS\nNA\nPOLYGON ((-0,8624911 10,985...\n\n\nBFA.8_1\nBFA\nBurkina Faso\nEst\nNA\nNA\nR√©gion\nRegion\nNA\nBF.ES\nNA\nPOLYGON ((1,384436 11,44223...\n\n\nBFA.9_1\nBFA\nBurkina Faso\nHaut-Bassins\nNA\nNA\nR√©gion\nRegion\nNA\nBF.HB\nNA\nPOLYGON ((-4,08994 10,79044...\n\n\nBFA.10_1\nBFA\nBurkina Faso\nNord\nNA\nNA\nR√©gion\nRegion\nNA\nBF.NO\nNA\nPOLYGON ((-1,96586 12,67774...\n\n\n\na Source des donn√©es : GADM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCartes choropl√®thes\n\n¬†¬†¬†¬†¬†¬†Les cartes choropl√®thes sont des repr√©sentations graphiques qui utilisent des nuances de couleurs pour illustrer des donn√©es quantitatives ou qualitatives sur des zones g√©ographiques. Chaque zone est remplie d‚Äôune couleur qui correspond √† une valeur sp√©cifique ou √† une plage de valeurs, facilitant ainsi l‚Äôanalyse des variations spatiales des donn√©es.\nLes cartes choropl√®thes sont id√©ales pour repr√©senter des indicateurs comme le taux de mortalit√©, le revenu moyen, l‚Äôacc√®s √† l‚Äôeau potable, ou encore la couverture sanitaire par r√©gion.\n\nExemple de carte choropl√®the\nDans cet exemple, nous allons cr√©er une carte choropl√®the montrant la couverture sanitaire par r√©gion au Burkina Faso, en utilisant les donn√©es fictives cr√©√©es plus haut. pour les donn√©es, vous pouvez me contacter par email.\n\nEtape 1 : Charger les shapefiles et les donn√©es\n\nIci nous nous assurons que les shapefiles des r√©gions et les donn√©es sont correctement charg√©s et li√©s entre eux. Pour cela on fait une jointure externe.\n\n##-- Joindre les donn√©es au shapefile\nregion_data &lt;- region_shp %&gt;% \n  left_join(data, by = c(\"NAME_1\" = \"Region\"))\n\nAvant de passer √† l‚Äô√©tape 2, affichons les donn√©es g√©n√©r√©es avant jointure et ceux apr√©s jointures.\n\n\nAfficher/cacher le code\n\n\ntbl.avant.jointure &lt;- kbl(head(data,10)) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n\ntbl.apres.jointure &lt;- kbl(head(data,10)) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des donn√©es :  GADM\")\n\n\n\n\nAfficher/Masquer le tableau\n\n\ntbl.avant.jointure\ntbl.apres.jointure\n\n\nLes 10 premi√®res lignes des tables\n\n\n\n\n\nAvant jointure\n\n\nRegion\nPopulation\nTaux_Mortalite\nCouverture_Sanitaire\nAcces_Eau_Potable\n\n\n\n\nBoucle du Mouhoun\n520405\n14,67\n69,98\n85,47\n\n\nCascades\n1038198\n13,85\n64,76\n76,43\n\n\nCentre\n763161\n10,86\n88,98\n55,18\n\n\nCentre-Est\n1672568\n13,55\n89,40\n64,96\n\n\nCentre-Nord\n936539\n8,63\n72,48\n84,53\n\n\nCentre-Ouest\n2160843\n6,30\n84,91\n56,83\n\n\nCentre-Sud\n1555101\n12,08\n92,12\n75,10\n\n\nEst\n1989351\n9,45\n81,82\n54,95\n\n\nHauts-Bassins\n1644005\n12,92\n85,90\n82,48\n\n\nNord\n933479\n6,98\n71,56\n62,87\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApr√®s jointure\n\n\nRegion\nPopulation\nTaux_Mortalite\nCouverture_Sanitaire\nAcces_Eau_Potable\n\n\n\n\nBoucle du Mouhoun\n520405\n14,67\n69,98\n85,47\n\n\nCascades\n1038198\n13,85\n64,76\n76,43\n\n\nCentre\n763161\n10,86\n88,98\n55,18\n\n\nCentre-Est\n1672568\n13,55\n89,40\n64,96\n\n\nCentre-Nord\n936539\n8,63\n72,48\n84,53\n\n\nCentre-Ouest\n2160843\n6,30\n84,91\n56,83\n\n\nCentre-Sud\n1555101\n12,08\n92,12\n75,10\n\n\nEst\n1989351\n9,45\n81,82\n54,95\n\n\nHauts-Bassins\n1644005\n12,92\n85,90\n82,48\n\n\nNord\n933479\n6,98\n71,56\n62,87\n\n\n\na Source des donn√©es : GADM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEtape 2 : Cr√©er la carte choropl√®the\n\nUtilisez ggplot2 et geom_sf() pour afficher les r√©gions et les colorer en fonction de la couverture sanitaire.\n\n##-  Carte choropl√®the\nchoropleth_map &lt;- ggplot(region_data) +\n  geom_sf(aes(fill = Couverture_Sanitaire), color = \"black\") +\n  scale_fill_viridis_c(\n    option = \"C\",\n    name = \"Couverture Sanitaire (%)\"\n  ) +\n  ggtitle(\"Carte choropl√®the : Couverture sanitaire par r√©gion\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"right\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\")\n  )\n\nchoropleth_map\n\n\n\n\nCouverture sanitaire par r√©gion\n\n\n\n\n\nEtape 3 :  Ajouter des √©l√©ments d√©coratifs\n\nAjoutons une barre d‚Äô√©chelle et une fl√®che du nord pour rendre la carte plus informative.\n\n##- Ajout des √©l√©ments d√©coratifs\nchoropleth_map &lt;- choropleth_map +\n  ggspatial::annotation_scale(location = \"br\") +\n  ggspatial::annotation_north_arrow(\n    location = \"tl\", style = north_arrow_nautical()\n  ) ###-- tl pour top-left (en haut √† gauche)\n\nchoropleth_map\n\n\n\n\n\nInterpr√©ter les r√©sultats\n\nExaminez la carte g√©n√©r√©e et r√©pondez aux questions suivantes : - Quelles r√©gions ont la meilleure couverture sanitaire ? - Quelles r√©gions doivent faire l‚Äôobjet d‚Äôune attention particuli√®re pour am√©liorer les conditions de vie ?\n\nExtensions possibles\n\nR√©alisez une carte choropl√®the pour le taux de mortalit√©.\nAjoutez des annotations pour les r√©gions ayant les valeurs extr√™mes.\nExp√©rimentez avec d‚Äôautres palettes de couleurs en utilisant scale_fill_brewer() ou scale_fill_manual() etc ‚Ä¶.\n\n\n\n\n\n\n\nDonn√©es discr√®tes ?\n\n\n\nIl se peut qu‚Äôil n‚Äôy ait pas une variabilit√© importante dans les donn√©es dans ce cas, au lieu d‚Äôavoir une palette, nous aurons juste des cases de couleurs comme s‚Äôagissait d‚Äôun indicateur discr√®t. Dans ce cas, recoder juste cet indicateur en un indicateur qualitatif (regrouper par classe) et ensuite utiliser scale_fill_manual() pour definir vos couleurs manuellement ou laisser R le faire tout seul. Le graphique ci-dessous en est un exemple.\n\n\n[Exemple de carte avec un indicateur recod√© : Indisponible pour l‚Äôinstant]\n\nCartes de proportions\n\n\n\n\nA suivre\n\n\n\n\nCartes de proportions avanc√©es\n\n\n\n\n\n\nRetour √† la page d‚Äôaccueuil"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Djamaldbz - Explorations en Statistiques et en Informatiques",
    "section": "",
    "text": "Bienvenue sur le site Djamaldbz, d√©di√© √† mes travaux en statistiques et informatique. Explorez mes projets, mes recherches, et mes publications."
  },
  {
    "objectID": "index.html#qui-suis-je",
    "href": "index.html#qui-suis-je",
    "title": "Djamaldbz - Explorations en Statistiques et en Informatiques",
    "section": "Qui suis-je ?",
    "text": "Qui suis-je ?\nJe m‚Äôappelle Djamal Y. TOE, et je suis passionn√© par les statistiques et l‚Äôinformatique. Mon parcours m‚Äôa permis de me concentrer sur l‚Äôanalyse des donn√©es et la r√©solution de probl√®mes avec des m√©thodes quantitatives. Je suis toujours en apprentissage et cherche √† d√©couvrir de nouvelles approches. Mon objectif est d‚Äôapporter des solutions pratiques, tout en restant ouvert √† l‚Äôapprentissage continu et √† l‚Äôam√©lioration dans le domaine des statistiques et de la science des donn√©es.\n\nEn savoir plus sur moi ici"
  },
  {
    "objectID": "index.html#mon-approche",
    "href": "index.html#mon-approche",
    "title": "Djamaldbz - Explorations en Statistiques et en Informatiques",
    "section": "Mon approche",
    "text": "Mon approche\nJ‚Äôaime explorer les statistiques, la programmation, l‚Äôanalyse de donn√©es et le machine learning pour mieux comprendre des probl√©matiques et proposer des solutions adapt√©es. Je m‚Äôint√©resse particuli√®rement aux domaines suivants :\n\nAnalyses factorielles et visualisation\nMod√®les de r√©gression et pr√©visions\nApplications statistiques interactives\nD√©veloppement d‚Äôapplications\nVision par ordinateur"
  },
  {
    "objectID": "index.html#mes-projets-r√©cents",
    "href": "index.html#mes-projets-r√©cents",
    "title": "Djamaldbz - Explorations en Statistiques et en Informatiques",
    "section": "Mes projets r√©cents",
    "text": "Mes projets r√©cents\nVoici quelques-uns de mes projets r√©cents dans le domaine des statistiques et de l‚Äôanalyse de donn√©es :\n\nAnalyse Factorielle et Visualisation Avanc√©e (en cours de publication)\nMod√©lisation de R√©gressions Mixtes pour des donn√©es complexes (en cours de publication)\nD√©veloppement d‚Äôoutils interactifs pour la visualisation de donn√©es\n\n\nVoir tous mes projets [Bient√¥t disponible sur le site]"
  },
  {
    "objectID": "index.html#derni√®res-publications",
    "href": "index.html#derni√®res-publications",
    "title": "Djamaldbz - Explorations en Statistiques et en Informatiques",
    "section": "Derni√®res publications üìö",
    "text": "Derni√®res publications üìö\nVoici les derni√®res publications sur des sujets de statistiques et d‚Äôinformatique que j‚Äôai partag√©es :\n\nüìà Mod√©lisation statistique\n\n√âvaluation de l‚Äôimpact d‚Äôune intervention sur les cas de paludisme\n\nMod√©lisation des donn√©es de comptage par r√©gression de Poisson\n\nPr√©dire le diab√®te chez les femmes √† l‚Äôaide d‚Äôune r√©gression logistique\n\nMod√®le √† variable d√©pendante binaire appliqu√© √† un jeu de donn√©es m√©dical et machine learning\n\nPr√©dire la dur√©e de carri√®re des joueurs NBA\n\nUne approche par r√©gression lin√©aire supervis√©e\n\nClasser les gestes de la main (pierre, feuille, ciseau)\n\nUtilisation du reseau de neurones convolutionnel et de yolov8\n\n\n\n\n\nü§ñ Programmation et projets interactifs\n\nCr√©er un assistant virtuel avec commandes vocales en Python\n\nMini-projet m√™lant reconnaissance vocale, traduction et intelligence artificielle\n\n\n\n\n\nüîç Analyse exploratoire et visualisation\n\nExploration des techniques d‚Äôanalyse factorielle\n\nPCA, AFC, ACM sur des jeux de donn√©es\n\nCr√©ation de cartes th√©matiques avec R (choropl√®thes, proportions)\n\nUtilisation des packages sf, tmap, leaflet\n\n\n\n\n\nüßë‚Äçüè´ Formations et bonnes pratiques\n\nR√©aliser des pr√©sentations dynamiques avec R et RStudio Utilisation de Quarto, Reveal.js et astuces pour pr√©senter efficacement\n\n\nVoir toutes les publications [Bient√¥t disponible]"
  },
  {
    "objectID": "index.html#publications-en-cours",
    "href": "index.html#publications-en-cours",
    "title": "Djamaldbz - Explorations en Statistiques et en Informatiques",
    "section": "Publications en cours",
    "text": "Publications en cours\n\nUtilisation de la SVM pour la classification binaire : Classer des personnes par genre en fonction des images donn√©es en entr√©es avec python (disponible bient√¥t)\nFace attendance system : Faire le pointage automatique avec le CNN et streamlit pour l‚Äôinterface (disponible bient√¥t)"
  },
  {
    "objectID": "index.html#contactez-moi",
    "href": "index.html#contactez-moi",
    "title": "Djamaldbz - Explorations en Statistiques et en Informatiques",
    "section": "Contactez-moi",
    "text": "Contactez-moi\nSi vous avez des questions, des suggestions ou l‚Äôenvie d‚Äô√©changer autour d‚Äôun projet, je serais ravi de vous lire. N‚Äôh√©sitez pas √† me contacter.\n\nEnvoyer un message\n\n\n\n\nA propos de nous\nEl√®ve en Science de donn√©es √† l‚ÄôEcole Nationale de la Statistique et de l‚ÄôAnalyse de l‚ÄôInformation en France, titulaire d‚Äôune licence en Statistiques-informatique.\nR√©seaux sociaux\n\nFacebook\nTwitter\nLinkedIn\n\n\nCoordonn√©es\n\nAdresse : Rennes, 35000, France\nEmail : ******\nT√©l√©phone : +33 ** ** ** ** **\n\nHeures de services\n\n\n\nJour\nHoraire\n\n\n\n\nLundi\n8h30pm - 9:30pm\n\n\nMardi - Vendredi\n7pm - 8pm\n\n\nSamedi\n9:30am - 10:30am\n\n\nEn √©t√©\nTous les jours ouvr√©s de 7h √† 16h\n\n\n\n\n\n\n\nInformations suppl√©mentaires\n¬© 2024 DJAMAL DEV\nContact: ****\nLocalisation: Rennes, France\nT√©l√©phone: +33 ** ** ** ** **"
  },
  {
    "objectID": "INFO_MINI_PROJETS/assistant_virtuel.html",
    "href": "INFO_MINI_PROJETS/assistant_virtuel.html",
    "title": "Djamaldbz - Cr√©e ton assistant virtuel en python !!!",
    "section": "",
    "text": "Comment cela fonctionne\n\n\n\nJe tiens tout d‚Äôabord √† rapperler que je n‚Äôutilise pas de mod√®le NLP pour cr√©er ce petit assistant virtuel. J‚Äôavais √©cris ce progamme en 2021, donc bien evidemment les outils utilis√©s ont √©volu√© et donc vous pourrez l‚Äôajuster √† votre guise. Le code source sera t√©l√©chargeable √† la fin de la page."
  },
  {
    "objectID": "INFO_MINI_PROJETS/assistant_virtuel.html#wolfram-alpha-cest-quoi-et-√†-quoi-√ßa-sert",
    "href": "INFO_MINI_PROJETS/assistant_virtuel.html#wolfram-alpha-cest-quoi-et-√†-quoi-√ßa-sert",
    "title": "Djamaldbz - Cr√©e ton assistant virtuel en python !!!",
    "section": "Wolfram Alpha : C‚Äôest quoi et √† quoi √ßa sert ?",
    "text": "Wolfram Alpha : C‚Äôest quoi et √† quoi √ßa sert ?\nWolfram Alpha est un moteur de calcul et de r√©ponse bas√© sur l‚Äôintelligence artificielle et les algorithmes symboliques. Contrairement √† un moteur de recherche classique comme Google, qui fournit des liens vers des sites web, Wolfram Alpha g√©n√®re directement des r√©ponses pr√©cises bas√©es sur des bases de connaissances et des algorithmes math√©matiques avanc√©s. Il est souvent utilis√© pour des calculs, des questions scientifiques et des recherches bas√©es sur des donn√©es structur√©es.\n\nUtilit√© :\n\nR√©solution d‚Äô√©quations math√©matiques et scientifiques\n\nRecherche et analyse de donn√©es (statistiques, physique, chimie, finance, etc.)\n\nInterpr√©tation de requ√™tes en langage naturel\n\nG√©n√©ration de graphiques et de simulations\n\nüîó Cr√©er un compte Wolfram Alpha :\nSi vous souhaitez utiliser l‚ÄôAPI de Wolfram Alpha dans votre projet, vous devez cr√©er un compte via ce lien :\nüëâ Cr√©er un compte Wolfram Alpha Je posterai une demo sur comment creer son compte et recup√©rer un id pour une application. Car en effet, il existe plusieurs type d‚ÄôID qui servent √† diff√©rentes type d‚Äôapplications. Il fonctionne en Anglais donc nous allons √©crire une fonction pour la traduction du Francais en Anglais afin de poser des questions et une pour la traduction de l‚ÄôAnglais en Fran√ßais pour la reponse trouv√©e. Vous avez bien entendu besoin de connexion pour effectuer les recherches.\nExemple d‚Äôutilisation\n\nimport wolframalpha\nid_ = \"YOUR_WOLFRAMALPHA_ID\"\n##-- J'utliserai le mien que j'ai masqu√©\nid_ = r.id_\nclient = wolframalpha.Client(id_)\nqueries = [\"who is the president of France\",\n        \"2 times 2 times ln(2)\",\n        \"derivate xln(x)\",\n        \"integrate exponential of 2x between 2 and 4\"\n]\n\n\nans1 = client.query(queries[0])\nans1 = next(ans1.results).text\nans1\n\n'Emmanuel Macron (from 14/05/2017 to present)'\n\n\n\nans2 = client.query(queries[1])\nans2 = next(ans2.results).text\nans2\n\n'4 log(2)'\n\n\n\nans3 = client.query(queries[2])\nans3 = next(ans3.results).text\nans3\n\n'd/dx(x log(x)) = log(x) + 1'\n\n\n\nans4 = client.query(queries[3])\nans4 = next(ans4.results).text\nans4\n\n'integral_2^4 exp(2 x) dx = 1/2 e^4 (e^4 - 1)‚âà1463.2'\n\n\n\n\nExplication des parties techniques de votre code\nLe script commence par l‚Äôimportation des biblioth√®ques n√©cessaires :\n\nimport datetime\nimport webbrowser\nimport sys\nimport pywhatkit\nimport speech_recognition as sr\nimport pyttsx3 as ttx\nimport wikipedia\nfrom googletrans import Translator\nimport wolframalpha\n\n\ndatetime : gestion des dates et heures.\nwebbrowser : ouverture des pages web.\nsys : gestion des fonctionnalit√©s syst√®me.\npywhatkit : ex√©cution de commandes interactives comme la recherche YouTube.\nspeech_recognition : reconnaissance vocale.\npyttsx3 : synth√®se vocale.\nwikipedia : r√©cup√©ration d‚Äôinformations depuis Wikip√©dia.\ngoogletrans : traduction de texte.\nwolframalpha : moteur de r√©ponse √† des questions scientifiques et math√©matiques.\n\nIntaller les avec la commande :\n\nmodules = [\n    \"pywhatkit\", \"speechrecognition\", \"pyttsx3\",\n    \"wikipedia\", \"googletrans==4.0.0-rc1\", \"wolframalpha\", \"pyaudio\"\n]\n\nimport subprocess\nimport sys\ndef install_modules():\n    for module in modules:\n        try:\n            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", module])\n        except:\n            print(\"Quelque chose s'est mal pass√©e\")\n            \ninstall_modules()"
  },
  {
    "objectID": "INFO_MINI_PROJETS/assistant_virtuel.html#configuration-du-moteur-de-synth√®se-vocale",
    "href": "INFO_MINI_PROJETS/assistant_virtuel.html#configuration-du-moteur-de-synth√®se-vocale",
    "title": "Djamaldbz - Cr√©e ton assistant virtuel en python !!!",
    "section": "2. Configuration du moteur de synth√®se vocale",
    "text": "2. Configuration du moteur de synth√®se vocale\nLe code initialise pyttsx3 et affiche les voix disponibles :\n\nmoteur = ttx.init()\nvoix_disponibles = moteur.getProperty(\"voices\")\n\nfor index, voix in enumerate(voix_disponibles):\n    print(f\"Index {index} - ID: {voix.id} - Langue: {voix.languages} - Nom: {voix.name}\")\n\nIndex 0 - ID: HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_DAVID_11.0 - Langue: [] - Nom: Microsoft David Desktop - English (United States)\nIndex 1 - ID: HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_ZIRA_11.0 - Langue: [] - Nom: Microsoft Zira Desktop - English (United States)\nIndex 2 - ID: HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_FR-FR_HORTENSE_11.0 - Langue: [] - Nom: Microsoft Hortense Desktop - French\n\n\nEnsuite, une voix sp√©cifique est s√©lectionn√©e et test√©e :\n\nmoteur.setProperty(\"voice\", voix_disponibles[2].id)\nmoteur.say(\"Bonjour, ceci est un test avec une autre voix.\")\nmoteur.runAndWait()"
  },
  {
    "objectID": "INFO_MINI_PROJETS/assistant_virtuel.html#d√©finition-de-la-classe-voxaassistant",
    "href": "INFO_MINI_PROJETS/assistant_virtuel.html#d√©finition-de-la-classe-voxaassistant",
    "title": "Djamaldbz - Cr√©e ton assistant virtuel en python !!!",
    "section": "3. D√©finition de la classe voxaAssistant",
    "text": "3. D√©finition de la classe voxaAssistant\nLa classe voxaAssistant g√®re toutes les fonctionnalit√©s de l‚Äôassistant vocal.\n\n3.1 Initialisation\n\nclass voxaAssistant:\n    def __init__(self):\n        self.ecouteur = sr.Recognizer()\n        self.moteur = ttx.init()\n        self.voix_disponibles = self.moteur.getProperty(\"voices\")\n        self.moteur.setProperty(\"voice\", self.voix_disponibles[2].id)\n        self.moteur.setProperty(\"rate\", 170)\n        self.app_id = r.id_\n        self.client = wolframalpha.Client(self.app_id)\n\nCette m√©thode : - Initialise le moteur de reconnaissance vocale (speech_recognition). - Configure la synth√®se vocale avec pyttsx3. - D√©finit la cl√© API pour Wolfram Alpha.\n\n\n3.2 Fonction parler\nCette fonction g√©n√®re une sortie vocale √† partir d‚Äôun texte donn√©.\n\ndef parler(self, texte):\n    self.moteur.say(texte)\n    self.moteur.runAndWait()\n\n\n\n3.3 Fonction saluer\nCette fonction ajuste le message de salutation en fonction de l‚Äôheure.\n\ndef saluer(self):\n    heure_actuel = int(datetime.datetime.now().hour)\n    if 0 &lt;= heure_actuel &lt;= 12:\n        self.parler(\"Bonjour √† vous Djamal\")\n    else:\n        self.parler(\"Bonsoir √† vous Djamal\")"
  },
  {
    "objectID": "INFO_MINI_PROJETS/assistant_virtuel.html#reconnaissance-et-traitement-des-requ√™tes-vocales",
    "href": "INFO_MINI_PROJETS/assistant_virtuel.html#reconnaissance-et-traitement-des-requ√™tes-vocales",
    "title": "Djamaldbz - Cr√©e ton assistant virtuel en python !!!",
    "section": "4. Reconnaissance et Traitement des Requ√™tes Vocales",
    "text": "4. Reconnaissance et Traitement des Requ√™tes Vocales\n\nFonction voxa_requete\nCette fonction √©coute l‚Äôutilisateur et transcrit la parole en texte.\n\ndef voxa_requete(self):\n    with sr.Microphone() as parole:\n        print(\"Entrain d'√©couter ...\")\n        self.ecouteur.adjust_for_ambient_noise(parole, duration=1)\n        self.ecouteur.pause_threshold = 1.5\n        try:\n            voix = self.ecouteur.listen(parole, timeout=5, phrase_time_limit=5)\n            command = self.ecouteur.recognize_google(voix, language=\"fr\").lower()\n            print(\"Vous avez dit .... : \", command)\n            return command\n        except sr.UnknownValueError:\n            print(\"Je n'ai pas compris, veuillez r√©p√©ter.\")\n            return \"\"\n        except sr.RequestError:\n            print(\"Erreur avec le service de reconnaissance vocale.\")\n            return \"\"\n\n\n\nRecherche Google et YouTube\nSi l‚Äôutilisateur mentionne Google ou YouTube, la recherche est effectu√©e automatiquement.\n\nelif \"google\" in voix:\n    url = voix.split().index(\"google\")\n    elt_rechercher = voix.split()[url + 1:]\n    self.parler(\"D'accord, je lance la recherche\")\n    webbrowser.open(\"https://www.google.com/search?q=\" + \"+\".join(elt_rechercher), new=2)\n\n\nelif \"recherche sur youtube\" in voix or \"recherche sur youtube.com\" in voix:\n                url = voix.split().index(\"youtube\")\n                elt_rechercher = voix.split()[url + 1:]\n                self.parler(\"d'accord  je  lance  la  recherche\")\n                webbrowser.open(\n                    \"http://www.youtube.com/results?search_query=\"\n                    + \"+\".join(elt_rechercher),\n                    new=2,\n                )\n\n\n1Ô∏è‚É£ split() : Pourquoi l‚Äôutiliser ici ?\n\nurl = voix.split().index(\"google\")\nelt_rechercher = voix.split()[url + 1:]\n\n\nsplit() d√©coupe une cha√Æne de caract√®res en une liste de mots.\nIci, on cherche l‚Äôindex du mot ‚Äúgoogle‚Äù pour r√©cup√©rer les mots suivants, qui correspondent √† la requ√™te de l‚Äôutilisateur.\n\nExemple :\n\nEntr√©e : \"cherche sur google c'est quoi la capitale de la France\"\n\nApr√®s split() : [\"cherche\",\"sur\", \"google\", \"c\", \"'\", \"est\", \"quoi\", \"la\", \"capitale\", \"de\", \"la\", \"France\"]\n\nIndex du mot ‚Äúgoogle‚Äù : 3\n\nCe qui est recherch√© : [\"c\", \"'\", \"est\", \"quoi\", \"la\", \"capitale\", \"de\", \"la\", \"France\"] ‚Üí Ici, on devrait prendre les mots apr√®s ‚Äúgoogle‚Äù.\n\n\n\n\n2Ô∏è‚É£ Pourquoi y a-t-il des + dans l‚ÄôURL de Google et YouTube ?\n\nwebbrowser.open(\"https://www.google.com/search?q=\" + \"+\".join(elt_rechercher), new=2)\n\n\nelif \"youtube\" in voix:\n    s = voix.replace(\"youtube\", \"\")\n    self.parler(\"D'accord sans soucis\")\n    pywhatkit.playonyt(s)\n\n\nExplication du +.\n\nDans une URL, un espace est souvent remplac√© par + ou %20.\n\nExemple : Si l‚Äôutilisateur dit ‚Äúrecherche machine learning sur google‚Äù, on doit transformer \"machine learning\" en \"machine+learning\" pour que Google comprenne.\n\nAutre solution : \"%20\".join(elt_rechercher) aurait aussi pu √™tre utilis√©.\n\n\n\n\n\nRecherches Avanc√©es avec Wolfram Alpha et Wikip√©dia\n\nUtilisation de Wolfram Alpha pour r√©pondre aux questions g√©n√©rales\n\n    def question_generale(self, voix):\n        voix = self.translate_eng_fr(voix)\n        try:\n            reponse = self.client.query(voix)\n            res = next(reponse.results).text\n            res = self.translate_fr_eng(res)\n            print(\"Un instant ...\")\n            print(res)\n            self.parler(res)\n        except:\n            self.parler(\"Je n'ai pas trouv√© de r√©ponse.\")\n\n¬†¬†¬†¬†¬†¬†Ici, l‚Äôassistant vocal envoie la requ√™te √† Wolfram Alpha, r√©cup√®re la r√©ponse et la traduit en fran√ßais avant de la prononcer.\nSi aucune r√©ponse n‚Äôest trouv√©e, une recherche est effectu√©e sur Wikip√©dia.\n\n\nUtilisation de wikipedia pour r√©pondre aux questions g√©n√©rales\n\ntry:\n    wikipedia.set_lang(\"fr\")\n    info = wikipedia.summary(voix, 1)\n    self.parler(str(info))\nexcept:\n    self.parler(\"Je n'ai pas bien compris\")\n\n\n\n3Ô∏è‚É£ query : √Ä quoi √ßa sert dans Wolfram Alpha*\n\nreponse = self.client.query(voix)\nres = next(reponse.results).text\n\n\n.query(voix) : envoie la question de l‚Äôutilisateur √† Wolfram Alpha.\n\nnext(reponse.results).text : r√©cup√®re la premi√®re r√©ponse retourn√©e et extrait le texte.\n\nSi Wolfram Alpha trouve une r√©ponse pertinente, elle est lue √† haute voix.\n\n\n\n\nR√©sum√© des concepts cl√©s :\n\n\n\n\n\n\n\n√âl√©ment\nExplication\n\n\n\n\nWolfram Alpha\nMoteur de calcul intelligent r√©pondant √† des requ√™tes scientifiques et analytiques\n\n\nsplit()\nD√©coupe une phrase en liste de mots\n\n\nquery()\nEnvoie une requ√™te √† Wolfram Alpha\n\n\njoin(‚Äú+‚Äù)\nTransforme une liste de mots en requ√™te lisible par un moteur de recherche"
  },
  {
    "objectID": "INFO_MINI_PROJETS/assistant_virtuel.html#test-du-code",
    "href": "INFO_MINI_PROJETS/assistant_virtuel.html#test-du-code",
    "title": "Djamaldbz - Cr√©e ton assistant virtuel en python !!!",
    "section": "Test du code",
    "text": "Test du code"
  },
  {
    "objectID": "INFO_MINI_PROJETS/assistant_virtuel.html#conclusion",
    "href": "INFO_MINI_PROJETS/assistant_virtuel.html#conclusion",
    "title": "Djamaldbz - Cr√©e ton assistant virtuel en python !!!",
    "section": "Conclusion",
    "text": "Conclusion\nCe code met en place un assistant vocal capable de reconna√Ætre et d‚Äôex√©cuter des commandes vocales en fran√ßais, d‚Äôeffectuer des recherches sur le web, et de r√©pondre aux questions gr√¢ce √† Wolfram Alpha et Wikip√©dia. Il constitue une base quelque peu solide pour un assistant personnel plus ou moins intelligent.\nT√©l√©charger le fichier .python\nT√©l√©charger la vid√©o\nSi vous avez des questions, vous pouvez me contacter !!!\nRetour √† la page d‚Äôaccueuil"
  },
  {
    "objectID": "INFO_MINI_PROJETS/classification_binaire_svm.html",
    "href": "INFO_MINI_PROJETS/classification_binaire_svm.html",
    "title": "Djamaldbz - Classification binaire en utilisant la SVM !!!",
    "section": "",
    "text": "Comment cela fonctionne\n\n\n\nJe tiens tout d‚Äôabord √† rapperler que je n‚Äôutilise pas de mod√®le NLP pour cr√©er ce petit assistant virtuel. J‚Äôavais √©cris ce progamme en 2021, donc bien evidemment les outils utilis√©s ont √©volu√© et donc vous pourrez l‚Äôajuster √† votre guise. Le code source sera t√©l√©chargeable √† la fin de la page."
  },
  {
    "objectID": "INFO_MINI_PROJETS/classification_binaire_svm.html#la-svm-cest-quoi-et-√†-quoi-√ßa-sert",
    "href": "INFO_MINI_PROJETS/classification_binaire_svm.html#la-svm-cest-quoi-et-√†-quoi-√ßa-sert",
    "title": "Djamaldbz - Classification binaire en utilisant la SVM !!!",
    "section": "LA SVM : C‚Äôest quoi et √† quoi √ßa sert ?",
    "text": "LA SVM : C‚Äôest quoi et √† quoi √ßa sert ?\n\nUtilit√© :\n\n\nPrincipe de la SVM pour la classification binaire"
  },
  {
    "objectID": "INFO_MINI_PROJETS/classification_binaire_svm.html#test-du-code",
    "href": "INFO_MINI_PROJETS/classification_binaire_svm.html#test-du-code",
    "title": "Djamaldbz - Classification binaire en utilisant la SVM !!!",
    "section": "Test du code",
    "text": "Test du code"
  },
  {
    "objectID": "INFO_MINI_PROJETS/classification_binaire_svm.html#conclusion",
    "href": "INFO_MINI_PROJETS/classification_binaire_svm.html#conclusion",
    "title": "Djamaldbz - Classification binaire en utilisant la SVM !!!",
    "section": "Conclusion",
    "text": "Conclusion\nCe code met en place un assistant vocal capable de reconna√Ætre et d‚Äôex√©cuter des commandes vocales en fran√ßais, d‚Äôeffectuer des recherches sur le web, et de r√©pondre aux questions gr√¢ce √† Wolfram Alpha et Wikip√©dia. Il constitue une base quelque peu solide pour un assistant personnel plus ou moins intelligent.\nT√©l√©charger le fichier .python\nT√©l√©charger la vid√©o\nSi vous avez des questions, vous pouvez me contacter !!!\nRetour √† la page d‚Äôaccueuil"
  },
  {
    "objectID": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html",
    "href": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html",
    "title": "ShiFuMi IA ‚Äì Reconnaissance de gestes",
    "section": "",
    "text": "Ce projet vise √† cr√©er une intelligence artificielle capable de jouer au jeu ShiFuMi (pierre-papier-ciseaux) contre un humain. L‚Äôobjectif est de reconna√Ætre automatiquement les gestes d‚Äôune main via une webcam, et de r√©pondre en temps r√©el. Ce prototype est d√©velopp√© seul, en utilisant les outils suivants :\n\nCNN pr√©-entra√Æn√© (MobileNetV2) pour classifier les images de mains,\nTensorFlow/Keras pour l‚Äôentra√Ænement,\nYOLOv8 (en pr√©paration) pour la d√©tection en direct via webcam,"
  },
  {
    "objectID": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html#pourquoi-entra√Æner-yolov8",
    "href": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html#pourquoi-entra√Æner-yolov8",
    "title": "ShiFuMi IA ‚Äì Reconnaissance de gestes",
    "section": "5.1 ü§î Pourquoi entra√Æner YOLOv8 ?",
    "text": "5.1 ü§î Pourquoi entra√Æner YOLOv8 ?\n¬†¬†¬†¬†¬†¬†L‚Äôobjectif principal de l‚Äôentra√Ænement de ce mod√®le est de d√©tecter les mains dans des images issues d‚Äôune webcam ou d‚Äôune vid√©o. Cette d√©tection constitue une premi√®re √©tape essentielle avant de transmettre la r√©gion d‚Äôint√©r√™t (ROI), c‚Äôest-√†-dire la main d√©tect√©e√† un mod√®le CNN pour effectuer la classification du geste (pierre, feuille, ciseaux).\nCette strat√©gie en deux √©tapes permet de :\n\nR√©duire le bruit visuel autour de la main (fond, visage, objets parasites)\nAugmenter la pr√©cision du classifieur CNN en se concentrant uniquement sur la main"
  },
  {
    "objectID": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html#structure-des-donn√©es-yolo",
    "href": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html#structure-des-donn√©es-yolo",
    "title": "ShiFuMi IA ‚Äì Reconnaissance de gestes",
    "section": "5.2 üìö Structure des donn√©es YOLO",
    "text": "5.2 üìö Structure des donn√©es YOLO\nLe format d‚Äôattente de YOLO est sp√©cifique : chaque image d‚Äôentra√Ænement doit √™tre accompagn√©e d‚Äôun fichier d‚Äôannotation .txt contenant les informations de localisation des objets (ici, la main).\nL‚Äôorganisation des donn√©es se pr√©sente g√©n√©ralement ainsi :\ndatasets/yolo_hand/\n‚îú‚îÄ‚îÄ images/\n‚îÇ   ‚îú‚îÄ‚îÄ train/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img_001.jpg\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img_002.jpg\n‚îÇ   ‚îî‚îÄ‚îÄ val/\n‚îÇ       ‚îú‚îÄ‚îÄ img_101.jpg\n‚îÇ       ‚îú‚îÄ‚îÄ img_102.jpg\n‚îú‚îÄ‚îÄ labels/\n‚îÇ   ‚îú‚îÄ‚îÄ train/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img_001.txt\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img_002.txt\n‚îÇ   ‚îî‚îÄ‚îÄ val/\n‚îÇ       ‚îú‚îÄ‚îÄ img_101.txt\n‚îÇ       ‚îú‚îÄ‚îÄ img_102.txt\nChaque fichier .txt contient une ou plusieurs lignes correspondant aux objets d√©tect√©s dans l‚Äôimage, selon le format suivant :\n&lt;class_id&gt; &lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;\n\nToutes les valeurs sont normalis√©es entre 0 et 1 relativement √† la taille de l‚Äôimage.\nclass_id correspond ici √† la main, donc souvent 0 dans le cadre d‚Äôun probl√®me mono-classe."
  },
  {
    "objectID": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html#entra√Ænement-avec-ultralytics-exemple",
    "href": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html#entra√Ænement-avec-ultralytics-exemple",
    "title": "ShiFuMi IA ‚Äì Reconnaissance de gestes",
    "section": "5.3 üöÄ Entra√Ænement avec Ultralytics (Exemple)",
    "text": "5.3 üöÄ Entra√Ænement avec Ultralytics (Exemple)\nPour entra√Æner le mod√®le YOLOv8, on utilise la commande suivante :\nyolo task=detect mode=train \\\n  model=yolov8n.pt \\\n  data=config.yaml \\\n  epochs=50 \\\n  imgsz=640\nO√π le fichier config.yaml contient :\npath: datasets/yolo_hand\ntrain: images/train\nval: images/val\n\nnames:\n  0: main\n\n\n\n\n\n\nPourquoi le notebook n‚Äôest pas publi√© ?\n\n\n\nL‚Äôoutil de d√©v√©loppement du site ne supporte pas la biblioth√®que tensorflow, du coup cela rend impossible le d√©ploiement du site car l‚Äôex√©cution des code du notebook ne passe pas. Toutefois, une fois les notebooks et scripts enti√®rement mis au propres, je les mettrai √† disposition sur un d√©pot public github"
  },
  {
    "objectID": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html#entra√Ænement-du-mod√®le-yolo-epochs33100",
    "href": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html#entra√Ænement-du-mod√®le-yolo-epochs33100",
    "title": "ShiFuMi IA ‚Äì Reconnaissance de gestes",
    "section": "6.1 Entra√Ænement du mod√®le YOLO (Epochs=33/100)",
    "text": "6.1 Entra√Ænement du mod√®le YOLO (Epochs=33/100)\n¬†¬†¬†¬†¬†¬†Etant donn√© que le mod√®le √©tait entrain√© local et du fait qu‚Äôil mettait du temps, j‚Äôai volontairement stopp√© l‚Äôentra√Ænement √† la 33-i√®me it√©ration. Car √† ce stade les r√©sultats de la d√©tections des mains √©taient satisfaisants (MAP2 environ √©gale √† 0,94). Voici un extrait du r√©sultat :"
  },
  {
    "objectID": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html#entra√Ænement-du-mod√®le-cnn",
    "href": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html#entra√Ænement-du-mod√®le-cnn",
    "title": "ShiFuMi IA ‚Äì Reconnaissance de gestes",
    "section": "6.2 Entra√Ænement du mod√®le CNN",
    "text": "6.2 Entra√Ænement du mod√®le CNN\n¬†¬†¬†¬†¬†¬†Une fois le mod√®le YOLO pr√™t √† detecter les mains dans une image, le boxe (pour dire le cadre/rectangle contenant la main) est envoy√© au mod√®le CNN afin qu‚Äôil puisse classer la main parmis les trois gestes : paper pour papier, rock pour pierre et scissors pour ciseau. Le mod√®le\nLa vid√©o ci-apr√®s illustre le r√©sultat."
  },
  {
    "objectID": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html#footnotes",
    "href": "INFO_MINI_PROJETS/shifumi-cnn-yolov8.html#footnotes",
    "title": "ShiFuMi IA ‚Äì Reconnaissance de gestes",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLe fine-tuning est une technique d‚Äôapprentissage supervis√© qui consiste √† prendre un mod√®le pr√©entra√Æn√© sur un grand jeu de donn√©es g√©n√©ral (comme ImageNet) et √† le r√©entra√Æner sur un jeu de donn√©es sp√©cifique √† un probl√®me particulier.‚Ü©Ô∏é\nMean Average Precision : C‚Äôest la m√©trique principale utilis√©e pour √©valuer les performances d‚Äôun mod√®le de d√©tection comme YOLO. Pr√©cision (Precision)‚Ü©Ô∏é"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#la-national-basketball-association",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#la-national-basketball-association",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "La National Basketball Association ?",
    "text": "La National Basketball Association ?\n\nLigue professionnelle de basketball la plus comp√©titive au monde\n30 √©quipes (Est et Ouest), 82 matchs de saison r√©guli√®re\nDonn√©es riches et vari√©es sur l‚Äôensemble de la ligue :\n\nsuivi tr√®s d√©taill√© des performances\ndes archives compl√®tes depuis plus de 75 ans\n\n\n\nProbl√©matique : Pr√©dire la dur√©e de carri√®re des joueurs nouvellement draft√©s"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#objectifs",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#objectifs",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Objectifs",
    "text": "Objectifs\n\nObjectif 1 : identifier des questions d√©crivant le jeu de donn√©es\n\nAnalyse exploratoire des donn√©es afin de r√©pondre √† 10 interrogations\nQuestions explorant diff√©rentes dimensions du basketball (√©quipes, les joueurs, les matchs, les play-offs ou encore la draft)\n\n\n\n\nObjectif 2 : pr√©dire la dur√©e de carri√®re des joueurs NBA\n\nSp√©cification et ajustement d‚Äôun mod√®le d‚Äôapprentissage automatique\n\n\n\n\n\nObjectif 3 : d√©velopper et d√©ployer une application\n\nCr√©ation d‚Äô interfaces interactives pour afficher les r√©ponses aux questions et d‚Äôautres informations sur la NBA"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#pr√©sentation-du-jeu-de-donn√©es-source-kaggle",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#pr√©sentation-du-jeu-de-donn√©es-source-kaggle",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Pr√©sentation du jeu de donn√©es (Source Kaggle)",
    "text": "Pr√©sentation du jeu de donn√©es (Source Kaggle)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTravail de pr√©paration des donn√©es : \n\nInt√©gration manuelle des vainqueurs NBA manquants;\nharmonisation des noms de franchises :\n\n\nPhiladelphia Warriors ¬†‚áí¬† San Francisco Warriors ¬†‚áí¬† Golden State Warriors"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#pourquoi-avons-nous-utilis√©-des-classes",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#pourquoi-avons-nous-utilis√©-des-classes",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Pourquoi avons-nous utilis√© des classes ?",
    "text": "Pourquoi avons-nous utilis√© des classes ?"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#pr√©sentation-de-la-classe-reponse",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#pr√©sentation-de-la-classe-reponse",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Pr√©sentation de la classe Reponse",
    "text": "Pr√©sentation de la classe Reponse\n\n\n\nclass Reponse:\n    def __init__(self, data: dict[pd.DataFrame]):\n        # R√©alisons les tests n√©cessaire sur l'objet data\n\n        if (\n            not isinstance(data, dict)\n        ):\n            raise TypeError(\"L'argument data doit √™tre un dictionnaire.\")\n\n        if (\n            any(not isinstance(data[key], pd.DataFrame) for key in data.keys())\n        ):\n            raise TypeError(\"Toutes les valeurs des cl√©s doivents √™tre des \"\n                            \"pandas.DataFrame.\")\n\n        # Testons qu'on a bien la cl√© common_player_info dans le dictionnaire\n        if (\"draft_history\" not in data.keys()):\n            raise KeyError(\"La cl√© 'draft_history' ne fait pas parti du dictionnaire\")\n        if (\"common_player_info\" not in data.keys()):\n            raise KeyError(\"La cl√© 'common_player_info' ne fait pas parti du \"\n                           \"dictionnaire\")\n        if (\"game\" not in data.keys()):\n            raise KeyError(\"La cl√© 'game' ne fait pas parti du dictionnaire\")\n\n        self.data = copy.deepcopy(data)\n\n\n\n\nEntr√©e :\n\nDictionnaire de tables\n\nV√©rification des entr√©es :\n\nLe type des entr√©es est v√©rifi√©\n\nPr√©sence des tables d‚Äôint√©r√™t dans le dictionnaire\n\nExceptions lev√©es : TypError, KeyError"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#les-m√©thodes-de-la-classe-reponse",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#les-m√©thodes-de-la-classe-reponse",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Les m√©thodes de la classe Reponse",
    "text": "Les m√©thodes de la classe Reponse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†‚áê¬† Les m√©thodes index√©es :\n\n(1) retourne une table contenant le nombre de victoires ou de d√©faites pour chaque √©quipe entre les saisons donn√©es.\n(2) retourne une table listant les √©quipes ayant remport√© au moins le nombre de titres requis.\n(3) retourne un dictionnaire contenant deux tables, un pour chaque conf√©rence (Est et Ouest)."
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#la-m√©thode-equip_victoires_defaites_saison-et-ses-usages",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#la-m√©thode-equip_victoires_defaites_saison-et-ses-usages",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "La m√©thode equip_victoires_defaites_saison et ses usages",
    "text": "La m√©thode equip_victoires_defaites_saison et ses usages\n\ndef equip_victoires_defaites_saison(self, annee_debut: int, annee_fin: int,\n                                        season_type: str = 'Regular Season',\n                                        defaite: bool = False) -&gt; pd.DataFrame:\n\nEntr√©es : p√©riode ‚Äì type de saison ‚Äì l‚Äôissue du match\nTraitement pour l‚Äôobtention du nombre de victoires ou de d√©faites :\n\n# D√©termination des √©quipes en fonction du r√©sultat souhait√©\n        game_chosen_season['Equipes'] = np.where(\n            ((game_chosen_season['wl_home'] == \"W\") & (not defaite)) |\n            ((game_chosen_season['wl_home'] == \"L\") & defaite),\n            game_chosen_season['team_name_home'],\n            game_chosen_season['team_name_away']\n        )\n\n        # Agr√©gation des r√©sultats\n        results = game_chosen_season.groupby([\"season_years\", \"Equipes\"]).aggregate({\n            'wl_home': 'count',\n            'Equipes': 'first',\n            'season_years': 'first'\n        }).reset_index(drop=True)"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#la-m√©thode-equipe_remporte_au_moins_n_fois_le_titre",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#la-m√©thode-equipe_remporte_au_moins_n_fois_le_titre",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "La m√©thode equipe_remporte_au_moins_N_fois_le_titre",
    "text": "La m√©thode equipe_remporte_au_moins_N_fois_le_titre\n\ndef equipe_remporte_au_moins_N_fois_le_titre(self, nb_victoire_min: int = 3,\n                                                 debut_periode: int = 1946,\n                                                 fin_periode: int = 2023\n                                                 ) -&gt; pd.DataFrame\n(1) nba_champions_manquant = {\n\"1957-1958\": \"Atlanta Hawks\", \"1958-1959\": \"Boston Celtics\", \"1960-1961\": \"Boston Celtics\", \n\"1964-1965\": \"Boston Celtics\", \"1968-1969\": \"Boston Celtics\", \"1993-1994\": \"Houston Rockets\", \n\"1995-1996\": \"Chicago Bulls\", \"1999-2000\": \"Los Angeles Lakers\", \"2001-2002\": \"Los Angeles Lakers\", \"2005-2006\": \"Miami Heat\"\n}\n\nS√©lection des donn√©es\nIdentification des vainqueurs de chaque saison\nAlimentation des r√©sultats (1)\nEdition de la table avec le nombre de titres gagn√©s sur la p√©riode par √©quipe\nRenvoi de la table avec les √©quipes avec au moins 3 titres NBA"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#la-m√©thode-classement_conferences",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#la-m√©thode-classement_conferences",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "La m√©thode classement_conferences",
    "text": "La m√©thode classement_conferences\n\ndef classement_conferences(self, season: str = '2022-2023',\n                               end: str = None) -&gt; dict[pd.DataFrame]:\n  . . .       \n\n  classement = {\"Conf√©rence Est\": classement_est,\n              \"Conf√©rence Ouest\": classement_ouest}\n\nS√©lection des donn√©es (saison r√©guli√®re)\nIdentification du nombre de victoire par √©quipe\nClassement selon la conf√©rence\nRenvoie les deux tables correspondantes aux conf√©rences Est et Ouest"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#les-√©quipes-ayant-remport√©-au-moins-n-titres-nba-entre-deux-p√©riodes-donn√©es",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#les-√©quipes-ayant-remport√©-au-moins-n-titres-nba-entre-deux-p√©riodes-donn√©es",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Les √©quipes ayant remport√© au moins N titres NBA, entre deux p√©riodes donn√©es",
    "text": "Les √©quipes ayant remport√© au moins N titres NBA, entre deux p√©riodes donn√©es\n\nclass Reponse:\n    def __init__(self, data: dict[pd.DataFrame]):\n      ...\n    ...\n    def equipe_remporte_au_moins_N_fois_le_titre(self, nb_victoire_min: int = 3,\n                                                 debut_periode: int = 1946,\n                                                 fin_periode: int = 2023\n                                                 ) -&gt; pd.DataFrame\n\n\n\n\n\n\n\nParam√®tres de la m√©thode equipe_remporte_au_moins_N_fois_le_titre"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#les-√©quipes-ayant-remport√©-au-moins-3-titres-nba",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#les-√©quipes-ayant-remport√©-au-moins-3-titres-nba",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Les √©quipes ayant remport√© au moins 3 titres NBA",
    "text": "Les √©quipes ayant remport√© au moins 3 titres NBA\n\n\n\n\nEquipes ayant remport√© au moins 3 titres NBA\n\n\nEquipe\nNombre.de.titre.NBA\n\n\n\n\nBoston Celtics\n17\n\n\nLos Angeles Lakers\n17\n\n\nGolden State Warriors\n7\n\n\nChicago Bulls\n6\n\n\nPhiladelphia 76ers\n6\n\n\nSan Antonio Spurs\n5\n\n\nMiami Heat\n3\n\n\nDetroit Pistons\n3\n\n\nHouston Rockets\n3"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#classement-des-conf√©rences-√†-la-fin-dune-saison-donn√©e",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#classement-des-conf√©rences-√†-la-fin-dune-saison-donn√©e",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Classement des conf√©rences √† la fin d‚Äôune saison donn√©e",
    "text": "Classement des conf√©rences √† la fin d‚Äôune saison donn√©e\n\nclass Reponse:\n    def __init__(self, data: dict[pd.DataFrame]):\n      ...\n    ...\n    def classement_conferences(self, season: str = '2022-2023',\n                               end: str = None) -&gt; dict[pd.DataFrame]:\n\n\n\n\n\n\n\nParam√®tres de la m√©thode classement_conferences"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#classement-des-conf√©rences-√†-la-fin-de-la-saison-2022-2023",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#classement-des-conf√©rences-√†-la-fin-de-la-saison-2022-2023",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Classement des conf√©rences √† la fin de la saison 2022-2023",
    "text": "Classement des conf√©rences √† la fin de la saison 2022-2023\n\n\n\n\n\n\nEquipe conf√©rence Est\nVictoires\nPoints\nEquipe conf√©rence Ouest\nVictoires\nPoints\n\n\n\n\nMilwaukee Bucks\n58\n9589\nDenver Nuggets\n53\n9495\n\n\nBoston Celtics\n57\n9671\nMemphis Grizzlies\n51\n9587\n\n\nPhiladelphia 76ers\n54\n9448\nSacramento Kings\n48\n9898\n\n\nCleveland Cavaliers\n51\n9205\nPhoenix Suns\n45\n9319\n\n\nNew York Knicks\n47\n9514\nGolden State Warriors\n44\n9753\n\n\nBrooklyn Nets\n45\n9295\nLA Clippers\n44\n9314\n\n\nMiami Heat\n44\n8977\nLos Angeles Lakers\n43\n9608\n\n\nAtlanta Hawks\n41\n9711\nMinnesota Timberwolves\n42\n9494\n\n\nToronto Raptors\n41\n9254\nNew Orleans Pelicans\n42\n9378\n\n\nChicago Bulls\n40\n9276\nOklahoma City Thunder\n40\n9633\n\n\nIndiana Pacers\n35\n9535\nDallas Mavericks\n38\n9366\n\n\nWashington Wizards\n35\n9279\nUtah Jazz\n37\n9600\n\n\nOrlando Magic\n34\n9136\nPortland Trail Blazers\n33\n9299\n\n\nCharlotte Hornets\n27\n9098\nSan Antonio Spurs\n22\n9269\n\n\nDetroit Pistons\n17\n9045\nHouston Rockets\n22\n9081"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#er-choix-de-la-draft-et-caract√©ristiques-physiques-des-joueurs",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#er-choix-de-la-draft-et-caract√©ristiques-physiques-des-joueurs",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "1er choix de la draft et caract√©ristiques physiques des joueurs",
    "text": "1er choix de la draft et caract√©ristiques physiques des joueurs\n\n\n\n\n\n\n1er choix de la draf NBA (2019-2023) \n\n\nSaison\nNom\nEquipe\nPays\n\n\n\n\n2019\nZion Williamson\nNew Orleans\nUSA\n\n\n2020\nAnthony Edwards\nMinnesota\nUSA\n\n\n2021\nCade Cunningham\nDetroit\nUSA\n\n\n2022\nPaolo Banchero\nOrlando\nUSA\n\n\n2023\nVictor Wembanyama\nSan Antonio\nFrance\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoids et tailles m√©dians par position \n\n\nposition\nTaille.cm\nPoids.Kg\n\n\n\n\nPivot\n210.82\n108.86\n\n\nPivot/Ailier fort\n210.82\n113.40\n\n\nAilier\n200.66\n98.88\n\n\nAilier fort/Pivot\n208.28\n108.86\n\n\nAilier/Meneur\n200.66\n99.79\n\n\nArri√®re/Meneur\n190.50\n86.18\n\n\nArri√®re/Ailier\n198.12\n95.25"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#quel-mod√®le-avons-nous-choisis",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#quel-mod√®le-avons-nous-choisis",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Quel mod√®le avons-nous choisis ?",
    "text": "Quel mod√®le avons-nous choisis ?\n\nParmi les mod√®les de machine, nous avons choisi un mod√®le d‚Äôapprentissage supervis√© et ce fut celui de la regression\n\n\n\n\n\n\nApprentissage supervis√© - Mod√®le de regression"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#mod√®le-de-regression-lin√©aire",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#mod√®le-de-regression-lin√©aire",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Mod√®le de regression lin√©aire",
    "text": "Mod√®le de regression lin√©aire\nPRINCIPE : Pr√©dire une variable quantitative √† l‚Äôaide d‚Äôune ou plusieurs variables explicatives (quantitatives ou qualitatives)\n\\[\\begin{equation}\n  y = \\beta X + \\epsilon\n\\end{equation}\\]\no√π \\(\\beta\\) est le coefficient associ√© aux variables explicatives \\(X\\) et \\(\\epsilon\\) le terme d‚Äôerreur.\n\nLe mod√®le de regression lin√©aire permet de pr√©dire une variable quantitative √† l‚Äôaide de variables explicatves app√©l√©e features. Son √©quation est la suivante : y la variable √† pr√©dire = beta x + epsilon ou x est l‚Äôensemble des features et epsilon les termes d‚Äôerreur"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#choix-des-variables-explicatives",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#choix-des-variables-explicatives",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Choix des variables explicatives",
    "text": "Choix des variables explicatives\n\nNotre regard s‚Äôest d‚Äôabord tourn√© vers les variables age √† la draft, poste occup√© sur le terrain, taille et poids du joueurs.\n\n\n\n\n\n\nVariables pr√©alables"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#choix-des-variables-explicatives-1",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#choix-des-variables-explicatives-1",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Choix des variables explicatives",
    "text": "Choix des variables explicatives\nVariables retenues\n\nLe poste occup√© sur le terrain ayant un lien qvec la taille et le poids du joueur, nous avons seulement gard√© le poste occup√© sur le terrain en plus de l‚Äô√¢ge √† la draft. Cela a permis d‚Äô√©viter √† un probl√®me de multicolin√©arit√© et donc d‚Äô√©viter un mauvais ajustement du mod√®le.\n\n\n\n\n\n\nVariables r√©t√©nues pour l‚Äôajustement du mod√®le"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#entrainement-du-mod√®le",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#entrainement-du-mod√®le",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Entrainement du mod√®le",
    "text": "Entrainement du mod√®le\n\nEntra√Ænement et √©valuation crois√©e\nNous lan√ßons cinq entra√Ænements successifs du mod√®le, chacun sur 80 % des donn√©es, en r√©servant √† chaque fois un pli diff√©rent pour la validation (donn√©es de tests).\n\n\n\n\n\n\nValidation crois√©e K-Fold (k = 5)"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#entrainement-du-mod√®le-1",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#entrainement-du-mod√®le-1",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Entrainement du mod√®le",
    "text": "Entrainement du mod√®le\n\n\n\n\n\nR√©sum√© de l‚Äôapprentissage automatique\n\n\n\n\n\n\nApr√®s avoir valid√© la robustesse du mod√®le via la CV, nous le r√©-entra√Ænons une derni√®re fois sur 100 % des observations disponibles, sans rien r√©server comme jeu de test.\n\nPourquoi ? Pour exploiter au maximum l‚Äôinformation disponible et obtenir un mod√®le final plus performant.\nComment s‚Äôassurer de sa fiabilit√© ? Nous nous appuyons enti√®rement sur la moyenne (4,59) et l‚Äô√©cart-type (¬± 0,12) des RMSE issus de la CV comme mesure de sa capacit√© de g√©n√©ralisation.\n\nPerformance confirm√©e\n\nGr√¢ce √† cette validation crois√©e, nous avons vu que le mod√®le g√©n√©ralise bien : les scores ne varient que de ¬± 0,12 autour de 4,59.\n\nInterpr√©tations et pr√©dictions\n\nForts de cette robustesse, nous pouvons passer sereinement √† l‚Äôanalyse de l‚Äôimportance des variables, √† l‚Äôinterpr√©tation des effets et en dernier lieu √† la production de pr√©dictions fiables sur de nouvelles donn√©es."
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#methode-fit-de-la-classe-linearregression",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#methode-fit-de-la-classe-linearregression",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Methode fit de la classe LinearRegression",
    "text": "Methode fit de la classe LinearRegression\ndef fit(self, X: np.ndarray, y: np.ndarray):\n        \"\"\"\n        Estime les coefficients de r√©gression par OLS.\n\n        Parameters\n        ----------\n        X : np.ndarray\n            Matrice des pr√©dicteurs.\n        y : np.ndarray\n            Vecteur cible.\n\n        Returns\n        -------\n        np.ndarray\n            Coefficients estim√©s.\n        \"\"\"\n        if not isinstance(X, np.ndarray) or not isinstance(y, np.ndarray):\n            raise TypeError(\"X et Y doivent-√™tre de type np.ndarray\")\n\n        cond_number = np.linalg.cond(X.T @ X)\n        if cond_number &gt; 1e10:\n            warnings.warn(\n                \"Matrice X.T @ X mal conditionn√©e (cond &gt; 1e10).\"\n                \"Risque de multicolin√©arit√©.\"\n            )\n\n        X_X_inv = np.linalg.pinv(X.T @ X)\n        Beta = X_X_inv @ X.T @ y\n        return Betas\n\nPour repondre √† la probl√©matique pos√©e, nous avons √©crit une classe linearRegression qui entraine le mod√®le, le valide, et pr√©dit la dur√©e de carri√®re des joueurs. Avant d‚Äôajuster le mod√®le, nous nous assurons que la matrice est bien conditionn√©e. (Sur le code on peut voir qu‚Äôun nombre de condition &gt; 1e10 signifie un probl√®me de multicolin√©arit√©)"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#r√©sultats-de-lentra√Ænement",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#r√©sultats-de-lentra√Ænement",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "R√©sultats de l‚Äôentra√Ænement",
    "text": "R√©sultats de l‚Äôentra√Ænement\n\n\n\n\n\n\nR√©sultats de l‚Äôentra√Ænement du mod√®le \n\n\nVariable\nEstimation\nBorne.inf√©rieure\nBorne.sup√©rieure\n\n\n\n\nintercept\n13.0807938172894\n11.2139999315576\n14.9475877030211\n\n\nage_at_draft\n-0.304520510475786\n-0.385970108084788\n-0.223070912866783\n\n\nPivot-Ailier fort\n4.03469135857516\n2.58019430274557\n5.48918841440475\n\n\nAilier\n-0.723448794163931\n-1.24222365227521\n-0.204673936052656\n\n\nAilier fort-Pivot\n3.00118640834299\n1.80323628965945\n4.19913652702653\n\n\nAilier-Arri√®re\n1.31879081528329\n-0.203041070946694\n2.84062270151327\n\n\nArri√®re\n-0.779850850158738\n-1.30098176750811\n-0.258719932809363\n\n\nArri√®re-Ailier\n1.88960963320118\n0.805602797554438\n2.97361646884792\n\n\n\n\n\n\n\n\n\n\n\n\nAge √† la draft + 1 ¬†‚áí¬† diminution moyenne de la dur√©e de carri√®re de 0.30 ans\nUn pivot/ailier a plus de chance de durer √† la NBA que les joueurs occupant les autres postes\nUn arri√®re a moins de chance de durer √† la NBA que les joueurs occupant les autres postes\n\n\n\nPr√©diction : \\(exp = 13,08 - 0.305*Age_{draft} + \\beta_j*Poste_j\\)\nAge_a_la_draft = 18 ans et Poste = Pivot\n\nDur√©e de carri√®re : 7.6 ans\nIntervalle de confiance [4.3, 10.9]\n\n\n\n\n\n\n\n\nPar exemple pour un joueur qui s‚Äôest pr√©sent√© √† 18 ans la draft, et occupant le poste de pivot, le mod√®le pr√©dit une dur√©e de carri√®re de 7,6 ans avec un IC allant de 4,3 √† 10,9 ans]"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#synth√®se-de-l√©tude",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#synth√®se-de-l√©tude",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Synth√®se de l‚Äô√©tude",
    "text": "Synth√®se de l‚Äô√©tude\n\nCe projet entre pleinement dans le domaine de l‚Äôinformatique appliqu√©e aux donn√©es.\nSuivi du processus : nettoyage, exploration et mod√©lisation\nR√©ponses rigoureuses aux questions pos√©es\nConstruction d‚Äôun mod√®le supervis√© pour pr√©dire la dur√©e de carri√®re des joueurs"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#avantages-et-difficult√©s",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#avantages-et-difficult√©s",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "Avantages et difficult√©s",
    "text": "Avantages et difficult√©s\n\n\n\n\n\n\n\n\nAvantages\n\n\n\nAcquisition de comp√©tences transversales : manipulation de donn√©es, machine learning, visualisation interactive.\nIntervalle de confiance des pr√©dictions\nImpl√©mentation manuelle du mod√®le supervis√©\nModularisation du code facilitant la maintenance et la r√©utilisation.\nPrise d‚Äôinitiatives (cr√©ation d‚Äôune interface, traitement des noms d‚Äô√©quipes changeants, gestion des donn√©es manquantes)\n\n\n\n\n\n\n\n\n\n\n\n\nDifficult√©s\n\n\n\nErreur de pr√©diction plus ou moins √©lev√©e (4,6 ans)\nDes attentes initiales manquaient de clart√©\nQuelques difficult√©s √† identifier et corriger les incoh√©rences dans les donn√©es historiques"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#end",
    "href": "projet-traitement-donnees/report_writing/Presentation/presentation-ptd.html#end",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA",
    "section": "END",
    "text": "END\n\n\n\n\n\n\n\n\n\n\n\n\nSoutenance du projet traitement de donn√©es 1A"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/synthese-des-travaux.html",
    "href": "projet-traitement-donnees/report_writing/synthese-des-travaux.html",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA sur la base de leurs caract√©ristiques et parcours individuels",
    "section": "",
    "text": "La NBA (National Basketball Association) est la ligue professionnelle de basketball la plus comp√©titive au monde. Depuis plus de 75 ans, elle r√©unit les meilleurs talents, entra√Æneurs et infrastructures. Aujourd‚Äôhui, la ligue est compos√©e de 30 √©quipes r√©parties entre deux conf√©rences (Est et Ouest), disputant chacune 82 matchs de saison r√©guli√®re. Les huit meilleures √©quipes de chaque conf√©rence acc√®dent ensuite aux s√©ries √©liminatoires (play-offs), structur√©es en quatre tours successifs en format au meilleur des sept matchs (Guan, Wang, and Yuan 2022; Teramoto and Cross 2010).\n¬†¬†¬†¬†¬†¬†Malgr√© son prestige, la carri√®re moyenne d‚Äôun joueur en NBA reste relativement courte. Plusieurs √©tudes montrent que cette long√©vit√© varie selon l‚Äôorigine des joueurs et leur parcours : par exemple, les joueurs √©trangers sans passage par une universit√© am√©ricaine semblent avoir une carri√®re plus br√®ve que ceux issus du syst√®me universitaire des USA (Groothuis and Hill 2018).\n¬†¬†¬†¬†¬†¬†Du point de vue des donn√©es, la NBA g√©n√®re une volum√©trie importante d‚Äôinformations sur les joueurs : caract√©ristiques physiques, parcours, statistiques de jeu, dur√©e de carri√®re, etc. Ces donn√©es sont une opportunit√© pour mener une analyse exploratoire orient√©e science des donn√©es, dans le but d‚Äôidentifier des patterns significatifs.\nL‚Äôobjectif de cette √©tude est donc d‚Äôutiliser les donn√©es disponibles pour pr√©dire la dur√©e de carri√®re d‚Äôun joueur NBA √† partir d‚Äôattributs personnels (√¢ge, position, parcours acad√©mique, etc.) √† l‚Äôaide de mod√®les de machine learning.\n\n\n\n¬†¬†¬†¬†¬†¬†Dans le prolongement de l‚Äôintroduction, cette section vise √† expliciter la m√©thodologie adopt√©e pour r√©pondre aux diff√©rentes questions pos√©es dans le cadre de ce projet, qu‚Äôil s‚Äôagisse des questions obligatoires ou de celles laiss√©es au choix de l‚Äô√©quipe.\n¬†¬†¬†¬†¬†¬†Nous commencerons par une pr√©sentation claire et synth√©tique de la classe que nous avons d√©velopp√©e pour structurer notre l‚Äôapprentissage automatique. Cette classe, que nous avons construite manuellement, int√®gre des fonctionnalit√©s avanc√©es telles que la gestion des variables cat√©gorielles, la d√©tection de la multicolin√©arit√©, la validation crois√©e, ainsi que la r√©gularisation de type Ridge. Elle se distingue notamment de l‚Äôimpl√©mentation classique LinearRegression de la biblioth√®que scikit-learn, en y ajoutant des m√©thodes personnalis√©es adapt√©es √† nos besoins sp√©cifiques.\n¬†¬†¬†¬†¬†¬†Ensuite, nous d√©taillerons les principales √©tapes du processus de mod√©lisation, en expliquant comment les m√©thodes de cette classe nous permettent de mettre en ≈ìuvre une r√©gression lin√©aire multiple de mani√®re compl√®te et contr√¥l√©e. Nous d√©crirons le r√¥le de chaque m√©thode dans le traitement des donn√©es, l‚Äôentra√Ænement du mod√®le, l‚Äô√©valuation des performances et l‚Äôinterpr√©tation des r√©sultats, notamment √† travers le calcul d‚Äôintervalles de confiance et d‚Äôindicateurs d‚Äôerreur comme le RMSE.\n¬†¬†¬†¬†¬†¬†Par ailleurs, une application web interactive a √©t√© d√©velopp√©e avec Shiny afin de rendre notre travail accessible √† travers une interface utilisateur conviviale. Nous pr√©senterons cette application en d√©tail : son objectif, son fonctionnement, et ses principales fonctionnalit√©s. Nous expliquerons √©galement les choix techniques qui ont guid√© son d√©veloppement, ainsi que la mani√®re dont elle permet de visualiser et d‚Äôinteragir avec les r√©sultats issus de notre mod√®le de r√©gression.\n¬†¬†¬†¬†¬†¬†Enfin, nous proposerons un retour critique sur notre exp√©rience de projet. Cette partie mettra en lumi√®re les d√©fis rencontr√©s tout au long du processus, les solutions que nous avons mises en ≈ìuvre, ainsi que la mani√®re dont nous avons organis√© et coordonn√© notre travail en √©quipe. Nous partagerons les enseignements tir√©s de cette collaboration, tant sur le plan technique que m√©thodologique et humain."
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#introduction",
    "href": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#introduction",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA sur la base de leurs caract√©ristiques et parcours individuels",
    "section": "",
    "text": "La NBA (National Basketball Association) est la ligue professionnelle de basketball la plus comp√©titive au monde. Depuis plus de 75 ans, elle r√©unit les meilleurs talents, entra√Æneurs et infrastructures. Aujourd‚Äôhui, la ligue est compos√©e de 30 √©quipes r√©parties entre deux conf√©rences (Est et Ouest), disputant chacune 82 matchs de saison r√©guli√®re. Les huit meilleures √©quipes de chaque conf√©rence acc√®dent ensuite aux s√©ries √©liminatoires (play-offs), structur√©es en quatre tours successifs en format au meilleur des sept matchs (Guan, Wang, and Yuan 2022; Teramoto and Cross 2010).\n¬†¬†¬†¬†¬†¬†Malgr√© son prestige, la carri√®re moyenne d‚Äôun joueur en NBA reste relativement courte. Plusieurs √©tudes montrent que cette long√©vit√© varie selon l‚Äôorigine des joueurs et leur parcours : par exemple, les joueurs √©trangers sans passage par une universit√© am√©ricaine semblent avoir une carri√®re plus br√®ve que ceux issus du syst√®me universitaire des USA (Groothuis and Hill 2018).\n¬†¬†¬†¬†¬†¬†Du point de vue des donn√©es, la NBA g√©n√®re une volum√©trie importante d‚Äôinformations sur les joueurs : caract√©ristiques physiques, parcours, statistiques de jeu, dur√©e de carri√®re, etc. Ces donn√©es sont une opportunit√© pour mener une analyse exploratoire orient√©e science des donn√©es, dans le but d‚Äôidentifier des patterns significatifs.\nL‚Äôobjectif de cette √©tude est donc d‚Äôutiliser les donn√©es disponibles pour pr√©dire la dur√©e de carri√®re d‚Äôun joueur NBA √† partir d‚Äôattributs personnels (√¢ge, position, parcours acad√©mique, etc.) √† l‚Äôaide de mod√®les de machine learning.\n\n\n\n¬†¬†¬†¬†¬†¬†Dans le prolongement de l‚Äôintroduction, cette section vise √† expliciter la m√©thodologie adopt√©e pour r√©pondre aux diff√©rentes questions pos√©es dans le cadre de ce projet, qu‚Äôil s‚Äôagisse des questions obligatoires ou de celles laiss√©es au choix de l‚Äô√©quipe.\n¬†¬†¬†¬†¬†¬†Nous commencerons par une pr√©sentation claire et synth√©tique de la classe que nous avons d√©velopp√©e pour structurer notre l‚Äôapprentissage automatique. Cette classe, que nous avons construite manuellement, int√®gre des fonctionnalit√©s avanc√©es telles que la gestion des variables cat√©gorielles, la d√©tection de la multicolin√©arit√©, la validation crois√©e, ainsi que la r√©gularisation de type Ridge. Elle se distingue notamment de l‚Äôimpl√©mentation classique LinearRegression de la biblioth√®que scikit-learn, en y ajoutant des m√©thodes personnalis√©es adapt√©es √† nos besoins sp√©cifiques.\n¬†¬†¬†¬†¬†¬†Ensuite, nous d√©taillerons les principales √©tapes du processus de mod√©lisation, en expliquant comment les m√©thodes de cette classe nous permettent de mettre en ≈ìuvre une r√©gression lin√©aire multiple de mani√®re compl√®te et contr√¥l√©e. Nous d√©crirons le r√¥le de chaque m√©thode dans le traitement des donn√©es, l‚Äôentra√Ænement du mod√®le, l‚Äô√©valuation des performances et l‚Äôinterpr√©tation des r√©sultats, notamment √† travers le calcul d‚Äôintervalles de confiance et d‚Äôindicateurs d‚Äôerreur comme le RMSE.\n¬†¬†¬†¬†¬†¬†Par ailleurs, une application web interactive a √©t√© d√©velopp√©e avec Shiny afin de rendre notre travail accessible √† travers une interface utilisateur conviviale. Nous pr√©senterons cette application en d√©tail : son objectif, son fonctionnement, et ses principales fonctionnalit√©s. Nous expliquerons √©galement les choix techniques qui ont guid√© son d√©veloppement, ainsi que la mani√®re dont elle permet de visualiser et d‚Äôinteragir avec les r√©sultats issus de notre mod√®le de r√©gression.\n¬†¬†¬†¬†¬†¬†Enfin, nous proposerons un retour critique sur notre exp√©rience de projet. Cette partie mettra en lumi√®re les d√©fis rencontr√©s tout au long du processus, les solutions que nous avons mises en ≈ìuvre, ainsi que la mani√®re dont nous avons organis√© et coordonn√© notre travail en √©quipe. Nous partagerons les enseignements tir√©s de cette collaboration, tant sur le plan technique que m√©thodologique et humain."
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#cadre-du-projet",
    "href": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#cadre-du-projet",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA sur la base de leurs caract√©ristiques et parcours individuels",
    "section": "Cadre du projet",
    "text": "Cadre du projet\n¬†¬†¬†¬†¬†¬†Ce projet s‚Äôinscrit dans le cadre des travaux de fin d‚Äôann√©e des √©tudiants de premi√®re ann√©e √† l‚Äô√âcole Nationale de la Statistique et de l‚ÄôAnalyse de l‚ÄôInformation (ENSAI).\nIl constitue le volet informatique appliqu√© aux donn√©es du programme acad√©mique.\nL‚Äôobjectif est de mobiliser les comp√©tences acquises en programmation, mod√©lisation et analyse pour r√©soudre une probl√©matique concr√®te √† partir de donn√©es r√©elles.\n‚û°Ô∏è Les slides de la pr√©sentation sont disponibles √† l‚Äôadresse suivante : Acc√©der aux slides"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#aspects-techniques-du-projet",
    "href": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#aspects-techniques-du-projet",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA sur la base de leurs caract√©ristiques et parcours individuels",
    "section": "Aspects techniques du projet",
    "text": "Aspects techniques du projet\n\nPr√©sentation du jeu de donn√©es\n¬†¬†¬†¬†¬†¬†L‚Äô√©tude repose sur un ensemble de donn√©es relatives au basketball, plus pr√©cis√©ment √† la ligue am√©ricaine : la NBA. Ces donn√©es nous ont √©t√© fournies sous forme de plusieurs fichiers CSV, que nous avons convertis en tables pour les besoins du traitement. Chaque fichier contient des informations sp√©cifiques sur les matchs, les √©quipes ou les joueurs de la ligue. Les donn√©es sur les confrontations entre √©quipes couvrent la p√©riode allant de 1946 √† 2023.\n¬†¬†¬†¬†¬†¬†La table common_player_info fournit des caract√©ristiques de certains joueurs telles que leur nom, pr√©nom, date de naissance, ann√©e de draft, statut de ‚Äúgreatest‚Äù ou non, dur√©e de carri√®re, taille, poids, etc. La table draft_combine_history contient quant √† elle des informations int√©ressantes sur la draft des joueurs : universit√© d‚Äôorigine, √©quipe de destination, rang de draft, etc. Enfin, la table game recense les matchs de la NBA de la saison 1946-1947 √† la saison 2022-2023**. On y trouve notamment des variables essentielles pour filtrer les donn√©es et mener nos analyses : saison, date de match, issue de la rencontre (victoire ou d√©faite), et nombre de points marqu√©s par chaque √©quipe lors des confrontations. C‚Äôest sur ces trois tables principalement que nous r√©aliserons notre traitement.\n\n\nExploration et harmonisation des donn√©es\n¬†¬†¬†¬†¬†¬†Lors de la phase exploratoire des donn√©es, nous avons constat√© que les informations de la table game pouvaient √©voluer d‚Äôune saison √† l‚Äôautre. En effet, il n‚Äôest pas rare qu‚Äôune franchise change de nom, notamment lorsqu‚Äôelle d√©m√©nage dans une nouvelle ville. Par exemple, les Seattle SuperSonics sont devenus les Oklahoma City Thunder apr√®s leur relocalisation, et les New Jersey Nets ont √©t√© renomm√©s Brooklyn Nets apr√®s leur installation √† Brooklyn.\nAfin d‚Äô√©viter de biaiser nos r√©sultats en consid√©rant √† tort que deux noms diff√©rents correspondent √† deux √©quipes distinctes, nous avons effectu√© des recherches sur les 30 franchises de la NBA, accompagn√©s par l‚ÄôIA, pour identifier celles ayant chang√© de nom entre 1946 et 2023.\n¬†¬†¬†¬†¬†¬†√Ä l‚Äôaide de manipulations de tables avec pandas et de dictionnaires, nous avons harmonis√© les noms afin d‚Äôattribuer √† chaque franchise son nom actuel. Cette √©tape nous permet ainsi de travailler avec un ensemble coh√©rent de 30 modalit√©s repr√©sentant les franchises existantes.\n¬†¬†¬†¬†¬†¬†De plus, dans la table game, les confrontations des playoffs sont absentes pour les saisons suivantes : 1958-1959, 1960-1961, 1964-1965, 1968-1969, 1993-1994, 1995-1996, 1999-2000, 2001-2002 et 2005-2006. Il est donc impossible de d√©terminer le vainqueur du titre pour ces saisons √† partir des seules donn√©es disponibles. Nous avons donc recherch√© et r√©cup√©r√© sur Internet les vainqueurs du titre NBA pour ces ann√©es. Ainsi, lorsque l‚Äôanalyse porte sur le nombre de titres NBA remport√©s par chaque franchise ou sur l‚Äôidentification du champion lors d‚Äôune saison pr√©cise, ces donn√©es externes sont int√©gr√©es √† l‚Äôanalyse.\n\n\nR√©ponses aux questions\n¬†¬†¬†¬†¬†¬†L‚Äôun des objectifs principaux de ce projet √©tait de mener une premi√®re analyse exploratoire des donn√©es afin de r√©pondre √† un certain nombre d‚Äôinterrogations. Parmi celles-ci, deux questions nous ont √©t√© impos√©es.\n\nPr√©sentation des questions pos√©es\n¬†¬†¬†¬†¬†¬†Les deux questions obligatoires d√©finies dans le cadre du projet sont les suivantes :\n\nQ1. Quelles sont les √©quipes ayant remport√© au moins 3 titres NBA, en pr√©cisant le nombre de titres pour chacune d‚Äôelles ?\nQ2. Quel √©tait le classement des conf√©rences Ouest et Est √† la fin de la saison r√©guli√®re 2022-2023 ?\n\n¬†¬†¬†¬†¬†¬†Les questions ci-dessous sont celles que nous avons jug√©es les plus int√©ressantes √† explorer et auxquelles nous avons choisi d‚Äôapporter des r√©ponses :\n\nQ3. Quelle est la taille et le poids m√©dians des joueurs selon leur poste ?\nQ4. Quelles sont les universit√©s ayant form√© le plus de joueurs √©voluant en NBA ?\nQ5. En dehors des √âtats-Unis, quels sont les pays d‚Äôorigine les plus repr√©sent√©s parmi les joueurs NBA ?\nQ6. Quelle est l‚Äô√©volution du nombre de rencontres sur p√©riodes donn√©es en NBA ?\nQ7. Qui sont les num√©ros 1 de la draft lors des 5 derni√®res saisons ?\nQ8. Quelles sont les √©quipes ayant obtenu le plus de victoires et de d√©faites durant les 5 derni√®res saisons r√©guli√®res ?\nQ9. Quels sont les champions NBA au cours des 8 derni√®res saisons ?\nQ10. Quelles sont les √©quipes ayant remport√© le titre NBA deux ann√©es cons√©cutives ?\n\n\n\nPr√©sentation des r√©ponses apport√©es\n¬†¬†¬†¬†¬†¬†Les r√©ponses aux questions sont toutes dans le notebook jupyter (reponses_aux_questions.ipynb). Dans le pr√©sent document, nous pr√©sentons celles concernant les questions obligatoires, ainsi qu‚Äôune question suppl√©mentaire que nous jugeons particuli√®rement pertinente.\n\nLes √©quipes ayant remport√© au moins 3 titres NBA\n\n¬†¬†¬†¬†¬†¬†Lorsqu‚Äôon observe le nombre de titres remport√©s par chaque franchise en NBA, on constate une grande variabilit√©. Par ailleurs, en se concentrant sur les √©quipes ayant remport√© au moins 3 titres, plusieurs franchises embl√©matiques ressortent, ayant marqu√© l‚Äôhistoire du basketball en NBA (cf.¬†tableau d‚Äôapr√®s). On observe que les Boston Celtics et les Los Angeles Lakers dominent largement le palmar√®s, avec chacun 17 titres sur la p√©riode 1946-2023. Ils sont suivis par les Golden State Warriors, qui en comptent 7.\n\n\n\nR√©capitulatif du nombre de titre gagn√© de chaque franchise\n\n\nEquipe\nNombre de titre NBA\n\n\n\n\nBoston Celtics\n17\n\n\nLos Angeles Lakers\n17\n\n\nGolden State Warriors\n7\n\n\nChicago Bulls\n6\n\n\nPhiladelphia 76ers\n6\n\n\nSan Antonio Spurs\n5\n\n\nMiami Heat\n3\n\n\nDetroit Pistons\n3\n\n\nHouston Rockets\n3\n\n\n\n\n\n\nLe classement des conf√©rences Ouest et Est √† la fin de la saison r√©guli√®re 2022-2023\n\n¬†¬†¬†¬†¬†¬†Pour d√©terminer les meilleures √©quipes de chaque conf√©rence, nous avons analys√© leur nombre de victoires durant la saison r√©guli√®re 2022-2023. Le classement inclut √©galement le total de points marqu√©s par chaque franchise. En cas d‚Äô√©galit√©, ce total permet de d√©partager les √©quipes. Ainsi, les vainqueurs des conf√©rences Est et Ouest sont respectivement les Milwaukee Bucks et les Denver Nuggets (cf.¬†le tableau ci-dessous).\n\n\n\nClassement des conf√©rences Ouest et Est √† la fin de la saison r√©guli√®re 2022-2023\n\n\nEquipe conf√©rence Est\nVictoires\nPoints\nEquipe conf√©rence Ouest\nVictoires\nPoints\n\n\n\n\nMilwaukee Bucks\n58\n9589\nDenver Nuggets\n53\n9495\n\n\nBoston Celtics\n57\n9671\nMemphis Grizzlies\n51\n9587\n\n\nPhiladelphia 76ers\n54\n9448\nSacramento Kings\n48\n9898\n\n\nCleveland Cavaliers\n51\n9205\nPhoenix Suns\n45\n9319\n\n\nNew York Knicks\n47\n9514\nGolden State Warriors\n44\n9753\n\n\nBrooklyn Nets\n45\n9295\nLA Clippers\n44\n9314\n\n\nMiami Heat\n44\n8977\nLos Angeles Lakers\n43\n9608\n\n\nAtlanta Hawks\n41\n9711\nMinnesota Timberwolves\n42\n9494\n\n\nToronto Raptors\n41\n9254\nNew Orleans Pelicans\n42\n9378\n\n\nChicago Bulls\n40\n9276\nOklahoma City Thunder\n40\n9633\n\n\nIndiana Pacers\n35\n9535\nDallas Mavericks\n38\n9366\n\n\nWashington Wizards\n35\n9279\nUtah Jazz\n37\n9600\n\n\nOrlando Magic\n34\n9136\nPortland Trail Blazers\n33\n9299\n\n\nCharlotte Hornets\n27\n9098\nSan Antonio Spurs\n22\n9269\n\n\nDetroit Pistons\n17\n9045\nHouston Rockets\n22\n9081\n\n\n\n\n\n\nLes √©quipes ayant remport√© le titre NBA deux ann√©es cons√©cutives\n\n¬†¬†¬†¬†¬†¬†Remporter le titre NBA deux ann√©es de suite est un exploit rare, compte tenu de la forte comp√©titivit√© entre les franchises. Parmi celles qui y sont parvenues, 8 √©quipes ont r√©ussi √† conserver leur titre deux saisons cons√©cutives : Los Angeles Lakers, Syracuse Nationals, Boston Celtics, Detroit Pistons, Chicago Bulls, Houston Rockets, Miami Heat, Golden State Warriors. Il est √† noter que les Boston Celtics d√©tiennent un record historique avec 8 titres cons√©cutifs entre les saisons 1958-1959 et 1965-1966.\n\n\nPr√©sentation des methodes utilis√©es\n¬†¬†¬†¬†¬†¬†Pour r√©pondre aux diff√©rentes questions, nous avons cr√©√© une classe Reponse dans laquelle chaque question fait l‚Äôobjet d‚Äôune m√©thode d√©di√©e. Ces m√©thodes int√®grent des param√®tres afin de permettre aux utilisateurs d‚Äôafficher les r√©sultats tout en pouvant appliquer des filtres personnalis√©s.\n¬†¬†¬†¬†¬†¬†Concernant la premi√®re question obligatoire, nous avons d√©fini une m√©thode prenant en param√®tres nb_victoire_min (le nombre minimal de titres √† remporter), debut_periode et fin_periode (ann√©es d√©limitant la p√©riode d‚Äô√©tude). Ces deux derniers param√®tres permettent de filtrer les donn√©es sur la p√©riode souhait√©e. Ensuite, nous r√©cup√©rons les vainqueurs de chaque saison et comptons les titres remport√©s par chaque franchise √† l‚Äôaide de manipulations avec pandas. Enfin, nous ne conservons que celles ayant remport√© un nombre de titres sup√©rieur ou √©gal √† celui indiqu√©.\n¬†¬†¬†¬†¬†¬†Pour la deuxi√®me question obligatoire, une autre m√©thode a √©t√© cr√©√©e avec les param√®tres season (saison d‚Äôint√©r√™t) et end (date de fin pour limiter les matchs pris en compte). Si le param√®tre end est fourni, le classement est calcul√© √† cette date pr√©cise ; sinon, le classement √† la fin de la saison r√©guli√®re est affich√©. Ces param√®tres permettent de filtrer les confrontations selon la saison choisie et, le cas √©ch√©ant, selon la date limite.\n¬†¬†¬†¬†¬†¬†Pour r√©pondre √† la dixi√®me question relative aux √©quipes ayant remport√© au moins 2 ann√©es cons√©cutives le titre, une m√©thode prenant les param√®tres N, debut_periode et fin_periode a √©t√© con√ßue. Elle permet d‚Äôidentifier les √©quipes ayant remport√© le titre au moins N ann√©es cons√©cutives dans une p√©riode d√©finie. Apr√®s filtrage des donn√©es, les vainqueurs sont extraits, et un traitement via la manipulation de dictionnaires permet de rep√©rer les franchises ayant remport√© le titre plusieurs ann√©es de suite.\n¬†¬†¬†¬†¬†¬†De fa√ßon g√©n√©rale, les autres m√©thodes de la classe Reponse suivent une logique similaire : elles exploitent des param√®tres pour affiner les r√©sultats et r√©pondre plus pr√©cis√©ment aux besoins de l‚Äôutilisateur, contrairement √† des m√©thodes fixes sans personnalisation. Ces traitements sont rendus possibles gr√¢ce aux fonctionnalit√©s offertes par le package pandas.\n\n\n\n\n\nDiagramme de classes\n\n\n\n\n\n\n\nPr√©sentation de la probl√©matique consid√©r√©e et de la r√©ponse apport√©e\n¬†¬†¬†¬†¬†¬†Comme √©nonc√© et justifi√© dans l‚Äôintroduction, notre probl√©matique est la suivante : Pr√©dire la dur√©e de carri√®re des joueurs en NBA.\n\nComment nous sommes parvenus √† r√©pondre √† cette probl√©matique ?\n¬†¬†¬†¬†¬†¬†Pour r√©pondre √† la probl√©matique, nous avons choisi d‚Äôutiliser un mod√®le de r√©gression lin√©aire multiple. Ce mod√®le permet de pr√©dire la dur√©e de carri√®re des joueurs √† partir de leurs caract√©ristiques individuelles.\nNous avons identifi√© la table common_player_info comme base pertinente pour l‚Äôentra√Ænement. Cette table contient plusieurs informations sur les joueurs. Les variables explicatives que nous avons s√©lectionn√©es sont : la date de naissance, l‚Äôann√©e de draft, le poste occup√© sur le terrain, la taille, le poids. La dur√©e de carri√®re est notre variable cible.\nPlut√¥t que d‚Äôutiliser directement le mod√®le de r√©gression lin√©aire de scikit-learn (LinearRegression), nous avons choisi d‚Äôimpl√©menter notre propre classe, nomm√©e LinearRegression. Cette classe permet :\n\nd‚Äôentra√Æner (ajuster) un mod√®le;\nde r√©aliser des pr√©dictions;\nd‚Äô√©valuer les performances du mod√®le √† l‚Äôaide de k-fold cross-validation 1.\n\nNous avons √©galement :\n\nint√©gr√© une m√©thode de r√©gression Ridge pour traiter d‚Äô√©ventuels probl√®mes de multicolin√©arit√©;\ncalcul√© les intervalles de confiance pour les pr√©dictions.\n\nUn diagramme de flux d√©taillant le fonctionnement de notre classe est pr√©sent√© en annexe.\nFinalement, pour des probl√®mes de multicolin√©arit√© entre certaines variables explicatives et des ajustements peu satisfaisants, nous avons choisi d‚Äôinclure l‚Äô√¢ge √† la draft ( ann√©e de draft - ann√©e de naissance) et la position (poste sur le terrain), ces deux variables s‚Äô√©tant r√©v√©l√©es plus pertinentes que la taille ou le poids.\nNotre mod√®le final avait donc pour formule :\n\\[\\begin{equation}\n  \\text{Dur√©e de carri√®re} = \\beta_0 + \\beta_1 \\cdot \\text{√Çge √† la draft} + \\sum_{j=1}^{k} \\beta_{j+1} \\cdot \\text{Position}_j + \\varepsilon\n(\\#eq:label)\n\\end{equation}\\]\no√π \\(\\beta_0\\) est l‚Äôordonn√©e √† l‚Äôorigine (intercept), \\(\\beta_1\\) est le coefficient associ√© √† l‚Äô√¢ge √† la draft, \\(\\text{Position}_j\\) repr√©sente les variables indicatrices pour les diff√©rentes positions, \\(\\beta_{j+1}\\) sont les coefficients qui leur sont associ√©s et \\(\\varepsilon\\) est le terme d‚Äôerreur. Les variables omises, telles que la taille et le poids, influencent directement la position d‚Äôun joueur. Par exemple, un joueur plus grand est souvent appel√© √† jouer au poste de pivot. De m√™me, un joueur poss√©dant une grande taille, un poids important et une bonne rapidit√© physique sera g√©n√©ralement affect√© aux postes d‚Äôailier fort et de pivot simultan√©ment. En gardant ces variables, il y‚Äôavait une incoh√©rence dans les r√©sultats certainement d√ªe √† la multicolin√©arit√© entre elles et la position. La reponse √† la question 3 confirme le lien entre le poste occup√© sur le terrain, la taille et le poids (cf.¬†figure en annexes).\nLe notebook apprentissage_automatique.ipynb permet de retrouver les r√©sultats dans la section d‚Äôapr√®s.\n\n\nReponse apport√©e √† la probl√©matique\n\nR√©sultats de l‚Äôentra√Ænement et interpr√©tations\nNous avons r√©entra√Æn√© notre mod√®le sur l‚Äôensemble des donn√©es disponibles, sans r√©server de jeu de test.\nPourquoi ? Pour exploiter toute l‚Äôinformation disponible et am√©liorer la pr√©cision du mod√®le final.\nMais comment garantir sa fiabilit√© ?\nNous nous basons enti√®rement sur les r√©sultats issus de la validation crois√©e : la moyenne des erreurs quadratiques moyennes (RMSE) √©tait de 4,59, avec une faible variabilit√© (√©cart-type de 0,12).\nCela indique une bonne capacit√© de g√©n√©ralisation du mod√®le.\n\n\nAnalyse des effets\nLe mod√®le confirme des tendances observ√©es dans la r√©alit√© : - Plus l‚Äô√¢ge √† la draft est √©lev√©, plus la dur√©e de carri√®re est courte. - Les joueurs occupant le poste de pivot ou ailier fort ont en moyenne une carri√®re plus longue, gr√¢ce √† leur polyvalence.\nSur la figure des resultats de l‚Äôentrainement du mod√®le (graphique a)), nous constatons que les performances de notre classe LinearRegression sont comparables √† celles du module linear_model de Scikit-learn.\n\n\nExemple de pr√©diction\nPour un joueur de 18 ans, s√©lectionn√© au poste de pivot, le mod√®le pr√©dit : - Dur√©e de carri√®re estim√©e : 7,6 ans - Intervalle de confiance : [4,3 ; 10,9]\n\n\nLimites\nM√™me si l‚Äôintervalle de confiance renforce la cr√©dibilit√© des r√©sultats, il convient de noter que la RMSE reste √©lev√©e (environ 4,6 ans), ce qui signifie que les erreurs de pr√©diction peuvent √™tre importantes dans certains cas.\n\n\n\n\n\n\nResultat de notre mod√®le VS celui de Sci-kit Learn\n\n\n\n\n\n\n\nMoyennes des erreurs quadratiques moyennes\n\n\n\n\n\n\nR√©sultats de l‚Äôentrainement du mod√®le\n\n\n\n\n\n\n\nLien entre les classe cr√©√©es et l‚Äôapplication\n¬†¬†¬†¬†¬†¬†Dans un souci de modularit√©, nous avons structur√© notre application autour de trois interfaces principales, chacune encapsul√©e dans une classe distincte.\n\nLa premi√®re interface est la page d‚Äôaccueil, qui ne fait pas directement appel aux classes LinearRegression ou Reponse. Elle sert principalement d‚Äôintroduction √† l‚Äôapplication mais est bas√©e sur une classe.\nLa seconde interface, Reponses aux questions, repose sur la classe Reponse (d√©taill√© en annexe) pour r√©pondre aux requ√™tes des utilisateurs. Elle permet √©galement d‚Äôappliquer des filtres sur les r√©sultats, comme l‚Äôaffichage des m√©dianes, moyennes selon le choix de l‚Äôutilisateur, ou encore un filtrage par date.\nEnfin, la page Machine Learning pr√©sente les r√©sultats d‚Äôentra√Ænement du mod√®le ajust√© ainsi que sa validation. Elle offre aussi la possibilit√© √† l‚Äôutilisateur de faire des pr√©dictions en renseignant les caract√©ristiques (features) d‚Äôun joueur de la NBA. Cette page utilise une classe CareerPrediction, laquelle d√©pend elle-m√™me de la classe LinearRegression.\n\n\n\nArchitecture du projet\n¬†¬†¬†¬†¬†¬†La figure ci-dessous pr√©sente l‚Äôarchitecture g√©n√©rale du projet. Chaque dossier a √©t√© con√ßu pour r√©pondre √† une pr√©occupation sp√©cifique. Pour que ces dossiers soient reconnus comme des paquets Python, des fichiers __init__.py y ont √©t√© ajout√©s avec la d√©finition des modules. Un fichier setup.py permet de g√©rer les d√©pendances internes et de faciliter les interactions entre les diff√©rents modules.\nEnfin, tous les packages n√©cessaires √† l‚Äôex√©cution des codes ainsi que leurs versions sont list√©s dans le fichier requirements.txt.\n\n\n\n\n\nArchitecture du projet\n\n\n\n\n\n\nPackages et biblioth√®ques utilis√©s\n¬†¬†¬†¬†¬†¬†Le projet repose sur plusieurs biblioth√®ques Python essentielles, parmi lesquelles :\n\nPandas : utilis√©e pour la manipulation de donn√©es tabulaires, elle facilite le traitement et la transformation des donn√©es structur√©es.\nMatplotlib : permet de cr√©er des visualisations d√©taill√©es et personnalis√©es sous forme de graphiques.\nNumPy : utile pour les op√©rations math√©matiques et la gestion efficace de tableaux multidimensionnels.\nScikit-learn : utilis√©e pour les t√¢ches de machine learning. Elle nous a permis de comparer nos impl√©mentations personnalis√©es avec les mod√®les standards de la biblioth√®que).\nShiny : a √©t√© utilis√©e pour d√©velopper l‚Äôinterface utilisateur de l‚Äôapplication.\n\nCes outils ont √©t√© essentiels pour mener √† bien les √©tapes d‚Äôanalyse, de mod√©lisation et de visualisation du projet.\n\n\nCouverture des tests\n¬†¬†¬†¬†¬†¬†La quasi-totalit√© des classes et fonctions a √©t√© test√©e, y compris celles li√©es aux pages de l‚Äôapplication web d√©velopp√©e.\nAu total, 214 tests ont √©t√© r√©alis√©s, assurant une couverture de plus de 94% du code.\n\n\n\n\n\nTests effectu√©s"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#utilisation-de-lapplication",
    "href": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#utilisation-de-lapplication",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA sur la base de leurs caract√©ristiques et parcours individuels",
    "section": "Utilisation de l‚Äôapplication",
    "text": "Utilisation de l‚Äôapplication\n\nPage d‚ÄôAccueil\nLa page Accueil pr√©sente des statistiques g√©n√©rales sur la NBA :\n\nNombre total de joueurs,\nNombre d‚Äô√©quipes,\nNombre d‚Äôuniversit√©s repr√©sent√©es.\n\nL‚Äôutilisateur peut √©galement explorer avec des filtres :\n\nLe nombre de joueurs Greatest 2,\nL‚Äô√©volution du nombre de matchs par saison,\nLa r√©partition des positions de joueurs entre deux ann√©es d√©finies.\n\nCes √©l√©ments sont illustr√©s en figure ci-dessous.\n\n\n\n\n\nPage d‚Äôaccueuil de l‚Äôapplication\n\n\n\n\n\n\nPage de reponses aux questions\nCette page permet √† l‚Äôutilisateur de :\n\nVisualiser les r√©sultats des analyses,\nInteragir avec la base via des champs de saisie dynamiques.\n\nExemple : pour la question ‚ÄúClasser les universit√©s selon le nombre de joueurs form√©s‚Äù, l‚Äôutilisateur peut :\n\nD√©finir une p√©riode,\nS√©lectionner le Top N universit√©s.\n\nLes r√©ponses sont regroup√©es par cat√©gories (Joueurs, √âquipes, etc.).\nLa figure ci-dessous illustre ce qui a √©t√© dis en ammont.\n\n\n\n\n\nPage de reponses aux questions de l‚Äôapplication\n\n\n\n\n\n\nPage des r√©sultats du mod√®le d‚Äôapprentissage supervis√© et de pr√©diction de la dur√©e de carri√®re : Machine Learning\n¬†¬†¬†¬†¬†¬†Sur cette page nous affichons les r√©sultats du mod√®le √† la suite de son entra√Ænement puis la validation du mod√®le. On voit que l‚Äôerreur quadratique moyenne 3 tourne autour de 4,6 en moyenne (le graphique √† droite sur la juste en bas). Ensuite pour permettre √† l‚Äôutilisateur de pr√©dire la dur√©e de carri√®re d‚Äôun joueur lambda, des champs de saisies sont affich√©s. Il pourra donc entrer la date de naissance du joueur, la date de sa draft et choisir sa position. M√™me s‚Äôil ne connait pas les date exacte, ce n‚Äôest pas grave, c‚Äôest l‚Äôann√©e qui importe. Ensuite en cliquant sur le bouton Predire il obtient la pr√©diction avec un intervalle de confiance.\nL‚Äôapplication a √©t√© d√©ploy√©e sur un server posit (version gratuite) et responsive donc s‚Äôadapte √† diff√©rentes tailles d‚Äô√©cran. Pour acceder √† l‚Äôapplication cliquez ici.\n\n\n\n\n\nPage des r√©sultats du mod√®le d‚Äôapprentissage supervis√© et de pr√©diction de la dur√©e de carri√®re"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#retour-dexp√©rience",
    "href": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#retour-dexp√©rience",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA sur la base de leurs caract√©ristiques et parcours individuels",
    "section": "Retour d‚Äôexp√©rience",
    "text": "Retour d‚Äôexp√©rience\n\nR√©ponse aux attentes\n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†Au cours du projet, nous avons √©t√© confront√©s √† plusieurs d√©fis. En effet, au d√©part, les attentes concernant les questions et le rendu n‚Äô√©taient pas totalement claires. Toutefois, gr√¢ce aux explications de notre tutrice Manon EVAIN, les choses se sont rapidement clarifi√©es. Elle nous a notamment encourag√© √† structurer notre code en classes, √† les tester rigoureusement, et surtout √† impl√©menter nous-m√™mes le mod√®le d‚Äôapprentissage automatique.\nCes recommandations, combin√©es √† nos efforts, nous ont pouss√©s √† aller au-del√† des exigences initiales : nous avons ainsi modularis√© l‚Äôensemble du projet, afin d‚Äôen faciliter la maintenabilit√© et la r√©utilisabilit√©.\nConcernant les r√©ponses aux questions, il a fallu faire preuve de minutie et de rigueur, notamment pour identifier les observations manquantes susceptibles de fausser les r√©sultats par rapport aux donn√©es officielles disponibles en ligne. √Ä la fin du projet, nous avons aussi d√ª g√©rer un probl√®me de changement des noms d‚Äô√©quipes dans le temps. Pour y rem√©dier rapidement, nous avons d√©velopp√© une fonction sp√©cifique, √©vitant ainsi des erreurs dans nos analyses.\nEnfin, la mise en ≈ìuvre manuelle du mod√®le d‚Äôapprentissage automatique a √©t√© particuli√®rement b√©n√©fique. Elle nous a permis non seulement de renforcer nos comp√©tences en statistiques, mais aussi de mieux comprendre leur impl√©mentation informatique.\n\n\nTravail en √©quipe\nD√®s le d√©but, nous avons d√©fini les diff√©rentes questions, puis nous les avons r√©parties √©quitablement, chacun r√©pondant en moyenne √† trois questions. L‚Äôutilisation de GitHub a grandement facilit√© le travail collaboratif, notamment pour surmonter les contraintes de distance g√©ographique.\nPar ailleurs, lors de nos s√©ances de travail en autonomie, nous avons veill√© √† partager nos m√©thodes respectives, afin que chacun puisse comprendre et valider les approches adopt√©es par les autres. Cette coop√©ration constante nous a permis de rester align√©s tout au long du projet.\n\n\nSatisfaction du travail final\n¬†¬†¬†¬†¬†¬†Nous sommes satisfaits du travail accompli, bien que certains aspects puissent √™tre am√©lior√©s. Le projet a demand√© un fort investissement, mais a suscit√© un r√©el int√©r√™t. Nous avons explor√© de nouvelles comp√©tences, notamment en d√©veloppant une interface graphique. Cela nous a pouss√©s √† sortir de notre zone de confort, tout en veillant √† la qualit√© du rendu. En somme, ce fut une belle opportunit√© d‚Äôapprentissage, tant sur le plan technique qu‚Äôen √©quipe."
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#conclusion",
    "href": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#conclusion",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA sur la base de leurs caract√©ristiques et parcours individuels",
    "section": "Conclusion",
    "text": "Conclusion\n¬†¬†¬†¬†¬†¬†Ce projet s‚Äôinscrit pleinement dans le domaine de l‚Äôinformatique appliqu√©e au traitement de donn√©es. √Ä travers l‚Äôanalyse des donn√©es issues de la NBA, nous avons mis en oeuvre une cha√Æne compl√®te de traitement : du nettoyage des donn√©es √† leur exploration statistique, jusqu‚Äô√† la mise en place d‚Äôun mod√®le de machine learning supervis√©.\nNous avons ainsi d√©velopp√© une solution permettant de pr√©dire la dur√©e de carri√®re des joueurs √† partir de variables explicatives pertinentes, en mobilisant des techniques issues de la r√©gression lin√©aire et en appliquant des m√©thodes de validation crois√©e. Ce travail nous a permis de mieux comprendre les enjeux li√©s √† la pr√©paration des donn√©es (feature engineering, gestion des valeurs manquantes, encodage des variables cat√©gorielles), √©tape cruciale en apprentissage automatique. Ces √©tapes nous ont √©galement permis d‚Äôapporter des r√©ponses correctes aux diff√©rentes questions pos√©es.\nPar ailleurs, le projet a donn√© lieu √† la cr√©ation d‚Äôune application interactive en Python (framework Shiny for Python), offrant une visualisation dynamique des donn√©es et des r√©sultats, et illustrant l‚Äôint√©r√™t d‚Äôoutils informatiques modernes pour valoriser les analyses.\nCe projet nous a permis de consolider nos comp√©tences en programmation, en traitement de donn√©es et en machine learning, tout en approfondissant notre capacit√© √† travailler en √©quipe sur un projet structur√©, dans une logique proche des pratiques professionnelles en data science."
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#liste-des-sigles-et-abr√©viations",
    "href": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#liste-des-sigles-et-abr√©viations",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA sur la base de leurs caract√©ristiques et parcours individuels",
    "section": "Liste des sigles et abr√©viations",
    "text": "Liste des sigles et abr√©viations\n\nCSV : Comma-Separated Values\nFormat de fichier texte utilis√© pour stocker des donn√©es tabulaires avec des virgules comme s√©parateurs.\nIA : Intelligence Artificielle\nEnsemble de techniques visant √† simuler l‚Äôintelligence humaine par des machines.\nIMC : Indice de Masse Corporelle\nIndicateur utilis√© pour √©valuer la corpulence d‚Äôune personne √† partir de son poids et de sa taille.\nJPG : Joint Photographic Experts Group\nFormat de fichier image compress√© couramment utilis√©.\nNBA : National Basketball Association\nLigue professionnelle de basketball nord-am√©ricaine.\nOLS : Ordinary Least Squares (Moindres Carr√©s Ordinaires)\nM√©thode d‚Äôestimation en r√©gression lin√©aire consistant √† minimiser la somme des carr√©s des erreurs.\nPNG : Portable Network Graphics\nFormat d‚Äôimage sans perte de qualit√©, adapt√© au web.\nRMSE : Root Mean Squared Error (Erreur Quadratique Moyenne Racine)\nMesure statistique de l‚Äô√©cart type des r√©sidus de pr√©diction.\nUSA : √âtats-Unis d‚ÄôAm√©rique\nPays dont les franchises de la NBA sont majoritairement issues."
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#sec:ml",
    "href": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#sec:ml",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA sur la base de leurs caract√©ristiques et parcours individuels",
    "section": "Annexe 1 : Algorithme utilis√© pour le machine learning Mod√®le de regression lin√©aire",
    "text": "Annexe 1 : Algorithme utilis√© pour le machine learning Mod√®le de regression lin√©aire\n\n\n\n\n\nDiagramme de flux des m√©thodes de la classe LinearRegression"
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#sec:m2",
    "href": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#sec:m2",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA sur la base de leurs caract√©ristiques et parcours individuels",
    "section": "Annexe 2 : Description des classes",
    "text": "Annexe 2 : Description des classes\nClasse Reponse\n¬†¬†¬†¬†¬†¬†La m√©thode init() avant d‚Äôinitialiser la classe Reponse doit :\n\nV√©rifier que l‚Äôargument data est bien un dictionnaire.\nV√©rifier que toutes les valeurs sont des objets de type pandas.DataFrame.\n\n¬†¬†¬†¬†¬†¬†La m√©thode equip_victoires_defaites_saison() retourne une table contenant le nombre de victoires ou de d√©faites pour chaque √©quipe entre les saisons donn√©es.\n¬†¬†¬†¬†¬†¬†La m√©thode prop_joueurs_en_nba_selon_universite_de_formation() retourne une table contenant le Top N des universit√©s selon le nombre de leurs √©tudiants ayant √©volu√© en NBA. Si graph = True, la m√©thode renvoie √©galement un diagramme √† barres.\n¬†¬†¬†¬†¬†¬†La m√©thode stat_sur_taille_et_poids_par_poste() retourne une table contenant la statistique demand√©e sur la taille et le poids des joueurs selon leur poste.\n¬†¬†¬†¬†¬†¬†La m√©thode equipe_remporte_au_moins_N_fois_le_titre() retourne une table listant les √©quipes ayant remport√© au moins le nombre de titres requis.\n¬†¬†¬†¬†¬†¬†La m√©thode premiers_choix_draft_N_derniere_saison() retourne une table contenant les premiers choix de draft sur les N derni√®res saisons.\n¬†¬†¬†¬†¬†¬†La m√©thode vainqueur_titre_NBA_saisons() retourne une table contenant les vainqueurs du titre NBA sur la p√©riode choisie ou sur les saisons d‚Äôune p√©riode d√©finie.\n¬†¬†¬†¬†¬†¬†La m√©thode equipe_qui_remporte_N_fois_daffile_le_titre() retourne une table listant les √©quipes ayant remport√© au moins N titres cons√©cutifs.\n¬†¬†¬†¬†¬†¬†La m√©thode nombre_victoires_ou_defaites_equipe_les_N_dernieres_saisons() retourne une table listant les √©quipes ayant obtenu le plus de victoires ou de d√©faites pour chaque saison d‚Äôune p√©riode donn√©e. Elle renvoie le nombre de d√©faites si defaite = True.\n¬†¬†¬†¬†¬†¬†La m√©thode top_N_nb_joueurs_par_pays() retourne une table indiquant la r√©partition des joueurs NBA selon leur pays d‚Äôorigine. Si graph = True, elle retourne √©galement un diagramme √† barres.\n¬†¬†¬†¬†¬†¬†La m√©thode classement_conferences() retourne un dictionnaire contenant deux tables, un pour chaque conf√©rence (Est et Ouest). Pour chaque table, on retrouve le classement des √©quipes selon leur nombre de victoires obtenues en saison r√©guli√®re.\nClasse HomeFunction\n¬†¬†¬†¬†¬†¬†La m√©thode init() initialise la classe avec un dictionnaire de DataFrames contenant les donn√©es √† visualiser dans l‚Äôinterface.\n¬†¬†¬†¬†¬†¬†La m√©thode create_line_chart_nb_match() retourne un graphique repr√©sentant l‚Äô√©volution du nombre de matchs jou√©s par saison, sur une p√©riode donn√©e.\n¬†¬†¬†¬†¬†¬†La m√©thode return_data_home() retourne les donn√©es principales affich√©es sur la page d‚Äôaccueil dans l‚Äôinterface.\n¬†¬†¬†¬†¬†¬†La m√©thode create_dunut_chart_of_position_distribution() retourne un graphique en forme de donut chart illustrant la r√©partition des joueurs selon leur poste, pour une p√©riode donn√©e.\n¬†¬†¬†¬†¬†¬†La m√©thode nombre_univ() retourne un entier repr√©sentant le nombre total d‚Äôuniversit√©s ayant form√© des joueurs NBA pr√©sent dans la base de donn√©es.\n¬†¬†¬†¬†¬†¬†La m√©thode return_greatest_players() retourne une table des joueurs les plus marquants (statut de greatest) sur une p√©riode donn√©e, ainsi que le nombre de joueurs inclus.\n¬†¬†¬†¬†¬†¬†La m√©thode return_nb_players() retourne un entier repr√©sentant le nombre total de joueurs dans la base.\n¬†¬†¬†¬†¬†¬†La m√©thode return_nb_teams() retourne un entier repr√©sentant le nombre total d‚Äô√©quipes pr√©sentes dans les donn√©es.\nClasse ReponseFunction\n¬†¬†¬†¬†¬†¬†La m√©thode init() initialise la classe avec un dictionnaire de DataFrames contenant les donn√©es n√©cessaires √† l‚Äôaffichage.\n¬†¬†¬†¬†¬†¬†La m√©thode prop_university() retourne un diagramme repr√©sentant les universit√©s ayant form√© le plus de joueurs NBA, selon une p√©riode et un top N d√©finis.\n¬†¬†¬†¬†¬†¬†La m√©thode statistique_taille_poids() retourne une table contenant une statistique (moyenne, m√©diane, etc.) sur la taille ou le poids des joueurs NBA, utilis√©e pour une repr√©sentation tabulaire dans l‚Äôinterface.\n¬†¬†¬†¬†¬†¬†La m√©thode au_moins_N_fois_le_titre() retourne une table listant les √©quipes ayant remport√© au moins un certain nombre de titres NBA sur une p√©riode donn√©e. Les donn√©es sont destin√©es √† un affichage dans l‚Äôinterface.\n¬†¬†¬†¬†¬†¬†La m√©thode remporter_titre() retourne une table avec les √©quipes ayant remport√© le titre NBA au cours de la p√©riode sp√©cifi√©e. Affichage sous de tableau dans l‚Äôinterface.\n¬†¬†¬†¬†¬†¬†La m√©thode nombre_victoires_defaites() retourne une table indiquant l‚Äô√©quipe avec le plus de nombre de victoires ou de d√©faites sur la saison r√©guli√®re, pour une p√©riode donn√©e.\n¬†¬†¬†¬†¬†¬†La m√©thode numero_1_draft() retourne une table listant les joueurs s√©lectionn√©s en premier lors de la draft pour les nb derni√®res ann√©es. Id√©al pour un tableau historique.\n¬†¬†¬†¬†¬†¬†La m√©thode distribution_pays() retourne √† la fois une table et un diagramme illustrant la r√©partition des joueurs NBA par pays d‚Äôorigine, selon un Top N d√©fini.\n¬†¬†¬†¬†¬†¬†La m√©thode recup_min_max_date() retourne deux cha√Ænes de caract√®res repr√©sentant la date de d√©but et de fin d‚Äôune saison. Elle est utilis√©e pour ajuster dynamiquement les filtres temporels dans l‚Äôinterface.\n¬†¬†¬†¬†¬†¬†La m√©thode display_conference() retourne le classement des √©quipes dans les conf√©rences Est et Ouest pour une saison donn√©e.\nClasse LinearRegression\n¬†¬†¬†¬†¬†¬†La m√©thode init() : v√©rifie types, colonnes, seuil et intercept ; nettoie df ; cr√©e X et y\n¬†¬†¬†¬†¬†¬†La m√©thode create_x_y(): dichotomise les variables cat√©gorielles ; ajoute un intercept si demand√©\n¬†¬†¬†¬†¬†¬†La m√©thode get_dummies() : transforme une variable cat√©gorielle en colonnes indicatrices\n¬†¬†¬†¬†¬†¬†La m√©thode fit() : estimation OLS par pseudoinverse ; avertit si multicolin√©arit√©\n¬†¬†¬†¬†¬†¬†La m√©thode fit_ridge() : estimation Ridge avec param√®tre alpha ; intercept non p√©nalis√©\n¬†¬†¬†¬†¬†¬†La m√©thode compute_confidence_interval() : calcule les intervalles de confiance des coefficients\n¬†¬†¬†¬†¬†¬†La m√©thode compute_rmse() : calcule la racine de l‚Äôerreur quadratique moyenne\n¬†¬†¬†¬†¬†¬†La m√©thode predict() : g√©n√®re les pr√©dictions via X %*% Beta\n¬†¬†¬†¬†¬†¬†La m√©thode perfom_linear_reg() : pipeline complet (fit, predict, IC, RMSE) en OLS ou Ridge\n¬†¬†¬†¬†¬†¬†La m√©thode create_k_fold(I) : g√©n√®re al√©atoirement k sous-√©chantillons pour validation crois√©e\n¬†¬†¬†¬†¬†¬†La m√©thode k_fold() : ex√©cute la validation crois√©e k-fold et renvoie les ***RMSE}\nClasse CareerPrediction\n¬†¬†¬†¬†¬†¬†La m√©thode init(data, use_ridge=FALSE, x_vars=list(), alpha=1.0, k=5) v√©rifie que data est un data.frame, initialise les attributs (use_ridge, alpha, k, etc.), clone les donn√©es et appelle prepare_data().\n¬†¬†¬†¬†¬†¬†La m√©thode prepare_data() convertit draft_year et extrait birth_year de birthdate, remplace ‚Äúundrafted‚Äù par 0, filtre les joueurs dont la carri√®re s‚Äôach√®ve \\(\\leq\\) 2022 et garde ceux dont age_at_draft &gt; 0. Elle d√©finit x_vars = c(‚Äúage_at_draft‚Äù, ‚Äúposition‚Äù) et instancie un mod√®le LinearRegression.\n¬†¬†¬†¬†¬†¬†La m√©thode run_regression() reconstruit le mod√®le LinearRegression avec y_var = ‚Äúseason_exp‚Äù et x_vars = c(‚Äúage_at_draft‚Äù,‚Äúposition‚Äù). Elle Lance perfom_linear_reg(use_ridge, alpha), renvoie les r√©sultats (coefficients, IC, RMSE).\n¬†¬†¬†¬†¬†¬†La m√©thode plot_k_fold() ex√©cute k_fold(k) pour obtenir les RMSE} par fold, puis cr√©e un graphique matplotlib*** et retourne l‚Äôobjet figure.\n¬†¬†¬†¬†¬†¬†La m√©thode predict_career_duration(birthdate, draft_year, position, coef_df) calcule age-at-draft, construit le vecteur de features (dont les dummy variables de position), r√©cup√®re l‚Äôintercept et les coefficients estim√©s dans coef_df. Elle agr√®ge contributions de chaque variable pour produire duree_predite et son intervalle_confiance.\nClasse ExportFiles\n¬†¬†¬†¬†¬†¬†La m√©thode init() initialise l‚Äôexporteur (aucun param√®tre requis)\n¬†¬†¬†¬†¬†¬†La m√©thode normalize_path(path) normalise un chemin en rempla√ßant les backslashes par des slashs.\n¬†¬†¬†¬†¬†¬†La m√©thode export_to_csv_format(table, path) v√©rifie que table est un DataFrame ou Series et que path est une cha√Æne, normalise le chemin et exporte la table en ***CSV} (sans index)\n¬†¬†¬†¬†¬†¬†La m√©thode export_to_xlsx_format(table, path) effectue les m√™mes contr√¥les de type que pour le CSV, convertit une Series en DataFrame si n√©cessaire et exporte au format Excel .xlsx\n¬†¬†¬†¬†¬†¬†La m√©thode export_to_jpg(img, path) v√©rifie que img est une matplotlib.figure.Figure et que path est une cha√Æne, normalise le chemin et enregistre la figure au format JPG\n¬†¬†¬†¬†¬†¬†La m√©thode export_to_png(img, path) effectue m√™mes contr√¥les que pour JPG normalise le chemin et enregistre la figure au format PNG\n\nAnnexes 3 : Lien visuel √©ventuel entre le poste occup√© sur le terrain, la taille et le poids des joueurs\n\n\n\n\n\nTaille et poids m√©dians par poste en NBA\n\n\n\n\n¬†¬†¬†¬†¬†¬†Sur cette figure, on peut voir que les ailiers forts/pivots, pivots et les pivots/ailiers forts sont les plus lourds et les plus grands en m√©diane. Ce qui traduirait une corr√©lation intrins√®que entre le poste, la taille et le poids des joueurs."
  },
  {
    "objectID": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#footnotes",
    "href": "projet-traitement-donnees/report_writing/synthese-des-travaux.html#footnotes",
    "title": "Pr√©diction de la dur√©e de carri√®re des joueurs NBA sur la base de leurs caract√©ristiques et parcours individuels",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLa validation crois√©e est une technique permettant d‚Äô√©valuer la performance d‚Äôun mod√®le en le testant sur plusieurs sous-ensembles des donn√©es. Elle permet de mieux estimer la g√©n√©ralisation du mod√®le (Run, C√©va√´r, and Dub√© 2023).‚Ü©Ô∏é\nUn joueur Greatest est un joueur faisant partie de la s√©lection des 75 meilleurs joueurs de l‚Äôhistoire de la NBA, d√©sign√©e √† l‚Äôoccasion du 75e anniversaire de la ligue.‚Ü©Ô∏é\nL‚Äôerreur quadratique moyenne (Root Mean Squared Error ou RMSE) est d√©finie comme la racine carr√©e de la moyenne des carr√©s des √©carts entre les valeurs pr√©dites \\(\\hat{y}_i\\) et les valeurs r√©elles \\(y_i\\) : \\[\n\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2}\n\\] Plus la RMSE est faible, plus le mod√®le est pr√©cis.‚Ü©Ô∏é"
  }
]