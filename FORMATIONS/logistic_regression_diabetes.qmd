---
title: "Djamaldbz - Modélisation des données à variables dépendantes qualitatives : Regression logistique à variable dépendante dichotomique"
bibliography: bib_palu_poisson.bib
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE)
library(reticulate)
use_python("C:/Users/Djamal TOE/AppData/Local/Programs/Python/Python311")
```


```{r, echo = FALSE}
capTabNo = 1; capFigNo = 1;
capTab = function(x){
 
    x = paste0("Tableau ",capTabNo," : ",x)
    capTabNo <<- capTabNo + 1
 x
}

capFig = function(x){
 
    x = paste0("Figure ",capFigNo," : ",x)
    capFigNo <<- capFigNo + 1
    x
}

repeated_capFig = function(x){
  x = paste0(paste0(paste0("Figure ", capFigNo), ""), x)
  x
}
options(OutDec= ",")
```

# Introduction
Le modèle logistique est une technique statistique largement utilisée pour modéliser des variables dépendantes binaires ou des proportions. Il est fondamental en économétrie, en sciences sociales, en biostatistique et dans de nombreux autres domaines.

# Formulation du Modèle Logistique

La régression logistique permet de modéliser la probabilité d’un événement sous la forme :
\begin{equation}
    P(Y=1 | X) = \frac{e^{\beta_0 + \beta_1 X_1 + \dots + \beta_k X_k}}{1 + e^{\beta_0 + \beta_1 X_1 + \dots + \beta_k X_k}}.
\end{equation}

La fonction logistique peut être réécrite sous la forme des cotes (odds) :
\begin{equation}
    \frac{P(Y=1 | X)}{1 - P(Y=1 | X)} = e^{\beta_0 + \beta_1 X_1 + \dots + \beta_k X_k}.
\end{equation}

En prenant le logarithme des deux côtés, nous obtenons le modèle de régression logistique sous sa forme linéarisée :
\begin{equation}
    \log \left( \frac{P(Y=1 | X)}{1 - P(Y=1 | X)} \right) = \beta_0 + \beta_1 X_1 + \dots + \beta_k X_k.
\end{equation}

# Importance en Classification
Le modèle logistique est particulièrement utilisé en classification binaire. Il permet d’attribuer une observation à l’une des deux catégories possibles en fonction d’un seuil de probabilité (souvent fixé à 0.5). 

En apprentissage automatique, il est souvent employé pour des tâches telles que :

- La `détection de spams` dans les emails.

- La `reconnaissance de fraudes` bancaires.

- La `segmentation de clients` en fonction de leur probabilité d'achat.

# Interprétation des Coefficients

Dans un modèle logistique, chaque coefficient $\beta_i$ représente l'effet d'une variation de $X_i$ sur le logarithme des cotes. Cela signifie que pour une variation de $X_i$ d'une unité, la variation relative des cotes est donnée par :

\begin{equation}
    e^{\beta_i}.
\end{equation}

Si $\beta_i > 0$, alors une augmentation de $X_i$ accroît la probabilité de succès ($Y=1$). Si $\beta_i < 0$, alors une augmentation de $X_i$ diminue cette probabilité.

Cependant, si l’on souhaite interpréter directement l’effet de $X_i$ sur $P(Y=1)$, il faut calculer les effets marginaux :
\begin{equation}
    \frac{\partial P(Y=1 | X)}{\partial X_i} = P(Y=1 | X) (1 - P(Y=1 | X)) \beta_i.
\end{equation}

Les effets marginaux permettent d’exprimer l’impact de $X_i$ sur la probabilité directement, sans passer par les cotes.

# Méthodes d'Estimation
Les paramètres sont estimés par la méthode du maximum de vraisemblance. La fonction de vraisemblance pour $n$ observations est donnée par :
\begin{equation}
    L(\beta) = \prod_{i=1}^{n} P(Y_i | X_i)^{Y_i} (1 - P(Y_i | X_i))^{1 - Y_i}.
\end{equation}

En prenant le logarithme, nous obtenons la log-vraisemblance :
\begin{equation}
    \log L(\beta) = \sum_{i=1}^{n} \left[ Y_i \log P(Y_i | X_i) + (1 - Y_i) \log (1 - P(Y_i | X_i)) \right].
\end{equation}

L’estimation des paramètres se fait par :

- La méthode de `Newton-Raphson`.
- L’algorithme de `descente de gradient` (en apprentissage automatique).
- Des `solveurs numériques spécialisés` (comme ceux implémentés dans R ou Python).

# Applications

Le modèle logistique est utilisé dans divers domaines :

- **Médecine** : prédiction de la présence d’une maladie en fonction de facteurs de risque.

- **Marketing** : estimation de la probabilité qu’un client achète un produit donné.

- **Finance** : modélisation du risque de défaut d’un emprunteur.

- **Économie** : analyse des choix binaires comme l’adoption d’une nouvelle technologie.

# Exemple d'Application

Supposons que nous souhaitions modéliser l'effet du revenu ($X$) sur la probabilité qu'un individu possède une assurance santé ($Y$). Nous estimons alors un modèle logistique :
\begin{equation}
    P(Y=1 | X) = \frac{e^{\beta_0 + \beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}}.
\end{equation}

Si l'estimation de $\beta_1$ est positive et significative, cela signifie que plus le revenu est élevé, plus la probabilité de posséder une assurance santé est grande.

# Conclusion

|       Le modèle logistique est un outil puissant pour la modélisation des variables binaires et la classification. Il permet d’assigner des probabilités à des événements et d’interpréter les relations entre variables explicatives et réponse. Son estimation repose sur le maximum de vraisemblance, et son interprétation nécessite souvent le calcul des effets marginaux pour comprendre directement l’impact des variables explicatives sur la probabilité d’occurrence de l’événement étudié.


# Place à la pratique avec des données sur le diabète

## Importation des bibliothèques necessaires

```{python, echo = TRUE, eval= TRUE}
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from IPython.display import display
import numpy as np
```

## Chargement des données et verification suscinte de leur qualité

```{python, echo = TRUE, eval= TRUE}
df = pd.read_csv('diabetes-dataset.csv')
print('\nAffichage des données\n')
display(df.head(5))
print('\nInformations sur les données\n')
display(df.info)
print('\nResumé statistique des données\n')
display(df.describe)
```

## Chargement des données et verification suscinte de leur qualité

### Affichage des informations sur les données

```{python, echo = TRUE, eval= TRUE}
df = pd.read_csv('diabetes-dataset.csv')
print('\nAffichage des données\n')
display(df.head(5))
print('\nInformations sur les données\n')
display(df.info)
print('\nResumé statistique des données\n')
display(df.describe)
```

### Vérification des valeurs manquantes

```{python, echo = TRUE, eval= TRUE}
df.columns.isna().sum()
```

|       Il y' a aucune valeur manquante car les données ont bien été nettoyées avant d'être mise à disposition sur `kaggle`.

### Affichage des statistiques des variables

|       Etant données que les informations sur les variables sont en ce moment ou j'écris indisponibles sur `kaggle`.

```{python, echo = TRUE, eval= TRUE}
print('Affichage des valeurs uniques des variables\n')
for variable in df.columns:
    if variable != "DiabetesPedigreeFunction": # je saute car ça fait beaucoup long à l'affichage
      print(f'\n {variable}\n')
      print(df[variable].unique())
```

Au vu de ces valeurs, on peut dire que (vu qu'il n'y a aucune description des disponible sur kaggle):

- `pregnancies` represente le nombre de grossesses contractées;

- `glucose` represente la quantité de glucose dans le sang;

- `BloodPressure` represente la pression sanguine;

- `SkinThickness` represente l'épaisseur du pli cutané tricipital;

- `BMI` correspond à l'Indice de Masse Corporelle (*_IMC_*)

- `Age` de la patiente

- `Insulin` représente la concentration sérique d'insuline mesurée (généralement en micro-unités par millilitre (μU/ml))

- `DiabetesPedigreeFunction` représente une mesure de la prédisposition génétique au diabète

- `Outcome` represente l'état de la patiente (atteinte ou non du diabète)

## Analyse exploratoire des données

|       Cette analyse est effectuée dans l'optique de mieux comprendre les données afin de pouvoir bien spécifier le modèle logistique.

### Analyse descriptives rapides (Voir la distribution des données)

```{python, echo = TRUE, eval= TRUE}
# Création de la figure avec une grille 3 lignes x 2 colonnes
fig, axes = plt.subplots(3, 2, figsize=(12, 12))

# Premier sous-graphe : Distribution du nombre de grossesses
sns.histplot(data=df['Pregnancies'], ax=axes[0, 0])
axes[0, 0].set_title("Distribution du nombre de grossesses")

# Deuxième sous-graphe : Distribution du niveau de glucose
sns.histplot(data=df['Glucose'], ax=axes[0, 1])
axes[0, 1].set_title("Distribution du niveau de glucose")

# Troisième sous-graphe : Distribution de la pression sanguine
sns.histplot(data=df['BloodPressure'], ax=axes[1, 0])
axes[1, 0].set_title("Distribution de la pression sanguine")

# Quatrième sous-graphe : Distribution de l'épaisseur du pli cutané (SkinThickness)
sns.histplot(data=df['SkinThickness'], ax=axes[1, 1])
axes[1, 1].set_title("Distribution de l'épaisseur du pli cutané")

# Cinquième sous-graphe : Distribution de l'insuline
sns.histplot(data=df['Insulin'], ax=axes[2, 0])
axes[2, 0].set_title("Distribution de l'insuline")

# Sixième sous-graphe : Distribution de l'IMC (BMI)
sns.histplot(data=df['BMI'], ax=axes[2, 1])
axes[2, 1].set_title("Distribution de l'IMC")

# Ajustement automatique des espaces pour
# éviter le chevauchement des titres et labels
plt.tight_layout()

# Affichage de la figure
plt.show()
```

### Verification de la colinéarité

|       En effet avant de spécifier un modèle, il faut s'assurer qu'il n'y a pas multicolinéarité. C'est-à-dire verifier que les variables ne sont pas corrélées entre elles ce qui permettra d'éviter de fausses estimations.


```{python, echo = TRUE, eval= TRUE}
# Sélectionner que les variables numériques des données
df_variables_numeriques = df.select_dtypes(include=[np.number])

plt.figure(figsize=(10, 8))
sns.heatmap(df_variables_numeriques.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Heatmap de correlation des variables numériques du jeu de données')
plt.tight_layout()
plt.show()
```

|       Ce corrélollogramme montre que les variables ne sont pas linéairement corrélées entre elle. Donc on peut ajuster le modèle de regression logistique.

## Spécification et évalution du modèle logistique

|       A ce niveau, j'ai partitionné les données en ammont dans le but de faire du machine learning (ajustement, prediction et validation du modèle) plus tard (dans la section suivante). Nous avons les données d'entrainement qui constituent ***80%*** des données et des données de test qui en constituent ***20***. Ici j'ajuste juste un modèle de regression logistique aux données que j'essaie d'interpreter.

```{python, echo = TRUE, eval= TRUE}
# Les bibliothèques de machine learning
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc
from sklearn.inspection import permutation_importance
```

```{python, echo = TRUE, eval= TRUE}
# Separation des variables explicatives and de la variable dépendante

# X : variable dépendante
X = df.drop('Outcome', axis=1)

# y : matrice des variables explicatives
y = df['Outcome']

# partition des données en données de tests et d'entrainement
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```


```{python, echo = TRUE, eval= TRUE}
import statsmodels.api as sm

# Ajout d'une colonne de 1 pour l'intercept (obligatoire dans statsmodels)
X_train_const = sm.add_constant(X_train)

# Création du modèle logistique
model = sm.Logit(y_train, X_train_const)

# Ajustement du modèle
result = model.fit()

# Affichage du résumé avec les p-values
display(result.summary())
```

## Qualité d'Ajustement

- **Log-Likelihood** : -287.25. Un log-vraisemblance plus élevé (moins négatif) indique un meilleur ajustement.

- **Pseudo R-squared** : 0.2752. Cela signifie que le modèle explique environ 27.52% de la variabilité dans les données, ce qui indique un ajustement modéré. Dans les modèles linéaires généralisés, il est fréquent d'avoir des pseudo-R2 un peu faible.

- **LLR p-value** : 9.311e-43, très faible, indiquant que le modèle est significatif globalement.

## Adéquation du Modèle

- **Convergence** : Le modèle a convergé en 6 itérations, suggérant un bon comportement de l'algorithme d'optimisation.

- **Df Model** : 8, indiquant 8 variables explicatives.

## Interprétation des Coefficients

La probabilité $p$ que $y = 1$ (c'est-à-dire que la patiente ait le diabète) est donnée par la fonction sigmoïde :

$p = \frac{1}{1 + \exp(-\beta)}$

où :
- $\beta$ est le coefficient du modèle de régression logistique.

- $\exp(-\beta)$ représente l'exponentielle de $-\beta$.

Ainsi, cette fonction transforme la valeur linéaire \( \beta \) en une probabilité entre 0 et 1.

- **Intercept (-9.0359)** : Lorsque toutes les variables sont à 0, la probabilité prédite que y=1 est proche de 0.

- **Glucose (0.0341, p<0.001)** : Une augmentation de 1 unité de glucose augmente significativement les odds de l'issue y=1.

- **BMI (0.1026, p<0.001)** : Indique une relation positive forte entre l'IMC et l'issue.

- **BloodPressure (-0.0139, p=0.024)** : Relation négative significative, mais l'effet est faible.

- **DiabetesPedigreeFunction (0.6945, p=0.035)** : Un antécédent familial a un impact positif significatif.

- **Age (0.0371, p=0.001)** : L’âge est un facteur significatif.

- **SkinThickness et Insulin** : Effet non significatif (au seuil de risque $\alpha$ = 0,05).

## Conclusion

Le modèle a une bonne capacité prédictive mais n'explique pas toute la variabilité. Certaines variables sont significatives (Glucose, BMI, Age), alors que d'autres, comme l'Insuline, ne le sont pas.


## Machine learning

### Ajustement du modèle aux données d'apprentissage

```{python, echo = TRUE, eval= TRUE}

# Initialisation et entrainnement du classificateur (Regression Logistique)
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# faire les prediction sur les données de test
y_pred = model.predict(X_test)

# calcul du score de précision
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy Score: {accuracy:.4f}')
```
|       L'`accuracy score` de 0.7468 signifie que le modèle a correctement classé 74.68% des échantillons dans le jeu de test. Cette métrique donne une indication de la proportion des prédictions correctes par rapport au nombre total d'observations. Plus l'accuracy est proche de 1 (ou 100%), plus le modèle est performant.


### Evaluation du modèle

>> Matrice de confusion

```{python, echo = TRUE, eval= TRUE}
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Matrice de confusion')
plt.xlabel('Données prédites')
plt.ylabel('Données observées')
plt.tight_layout()
plt.show()
```

$$
\textbf{Vrais Positifs (VP)} = 37 \quad \text{(Modèle prédit que la patiente a le diabète et c'est correct)}
$$
$$
\textbf{Faux Positifs (FP)} = 21 \quad \text{(Modèle prédit que la patiente a le diabète, mais c'est incorrect)}
$$


$$
\textbf{Faux Négatifs (FN)} = 18 \quad \text{(Modèle prédit que la patiente n'a pas le diabète, mais c'est incorrect)}
$$


$$
\textbf{Vrais Négatifs (VN)} = 78 \quad \text{(Modèle prédit que la patiente n'a pas le diabète et c'est correct)}
$$

>>> Métriques de performance

$$
\text{Précision} = \frac{\text{VP}}{\text{VP} + \text{FP}} = \frac{37}{37 + 21} = \frac{37}{58} \approx 0.6379
$$

$$
\textbf{Rappel} (Recall) :
\text{Rappel} = \frac{\text{VP}}{\text{VP} + \text{FN}} = \frac{37}{37 + 18} = \frac{37}{55} \approx 0.6727
$$

$$
\textbf{Score F1} (F1-Score) :
\text{F1-Score} = 2 \times \frac{\text{Précision} \times \text{Rappel}}{\text{Précision} + \text{Rappel}} = 2 \times \frac{0.6379 \times 0.6727}{0.6379 + 0.6727} \approx 0.6548
$$


$$
\textbf{Exactitude} (Accuracy) :
\text{Exactitude} = \frac{\text{VP} + \text{VN}}{\text{Total}} = \frac{37 + 78}{37 + 78 + 21 + 18} = \frac{115}{154} \approx 0.7468
$$

>> Courbe de ROC

```{python, echo = TRUE, eval= TRUE}
y_prob = model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Courbe ROC (Aire = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('Taux de Faux Positifs')
plt.ylabel('Taux de Vrais Positifs')
plt.title('Caractéristique de Performance du Modèle (Courbe ROC)')
plt.legend(loc='lower right')
plt.show()
```

|       La **courbe ROC** (Receiver Operating Characteristic) est un graphique qui permet d'évaluer la performance d'un modèle de classification binaire. Elle trace la relation entre :

- Le Taux de Vrais Positifs (TPR, True Positive Rate) : La proportion des vrais positifs parmi les cas positifs réels.

- Le Taux de Faux Positifs (FPR, False Positive Rate) : La proportion des faux positifs parmi les cas négatifs réels.

|       La **courbe ROC** montre comment le modèle se comporte pour différents seuils de décision. Un modèle parfait aura une courbe qui monte rapidement vers le coin supérieur gauche (haute TPR et faible FPR), tandis qu'un modèle aléatoire suivra la diagonale du graphique (FPR = TPR).

|       L'**Aire Sous la Courbe (AUC)** mesure la qualité globale du modèle. Une AUC proche de 1 indique un excellent modèle, tandis qu'une AUC proche de 0.5 indique un modèle équivalent à un choix aléatoire.

Dans notre cas `AUC` vaut 0,81 donc notre modèle tient la route.


>>> Verifions qu'on a les même coefficients que ceux de l'ajustement à la section précédente

```{python, echo = TRUE, eval= TRUE}
model.intercept_
```


```{python, echo = TRUE, eval= TRUE}
# affichage des coefficients estimés du modèle
model.coef_
```

Et oui on a les mêmes coefficients.

Si vous avez des questions, vous pouvez me contacter !!!

[Retour à la page d'accueuil](https://djamal2905.github.io/djamal_website)

